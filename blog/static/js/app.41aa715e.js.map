{"version":3,"sources":["webpack:///webpack/bootstrap","webpack:///./src/commonComponents/Icon.vue?b718","webpack:///./src/commonComponents/Icon.vue?f88b","webpack:///./src/commonComponents/Icon.vue?c889","webpack:///./src/commonComponents/Icon.vue","webpack:///./src/App.vue?a9e7","webpack:///./src/y_system_articles.ts","webpack:///./src/y_system_columns.ts","webpack:///./src/commonComponents/BackTop.vue?ac2f","webpack:///./src/commonComponents/BackTop.vue?9d91","webpack:///./src/commonComponents/BackTop.vue?8bc4","webpack:///./src/commonComponents/BackTop.vue","webpack:///./src/components/AppNav.vue?881a","webpack:///./src/components/AppNav.vue?e754","webpack:///./src/components/AppNav.vue?57e3","webpack:///./src/components/AppNav.vue","webpack:///./src/components/AppFooter.vue?4bbb","webpack:///./src/components/AppFooter.vue?d2b1","webpack:///./src/components/AppFooter.vue?43b9","webpack:///./src/components/AppFooter.vue","webpack:///./src/App.vue?ec60","webpack:///./src/App.vue?640d","webpack:///./src/App.vue","webpack:///./src/router/index.ts","webpack:///./src/plugins/scriptsRegister.ts","webpack:///./src/createApp.ts","webpack:///./src/entry-client.ts","webpack:///./src/components/AppFooter.vue?4db8","webpack:///./src/components/AppNav.vue?5e42","webpack:///./src/App.vue?49f2","webpack:///./src/utils/is.ts","webpack:///./src/utils/index.ts","webpack:///./src/router/routerName.ts","webpack:///./src/commonComponents/BackTop.vue?bccf","webpack:///./src/commonComponents/Icon.vue?4dcc"],"names":["webpackJsonpCallback","data","moduleId","chunkId","chunkIds","moreModules","executeModules","i","resolves","length","Object","prototype","hasOwnProperty","call","installedChunks","push","modules","parentJsonpFunction","shift","deferredModules","apply","checkDeferredModules","result","deferredModule","fulfilled","j","depId","splice","__webpack_require__","s","installedModules","installedCssChunks","jsonpScriptSrc","p","exports","module","l","e","promises","cssChunks","Promise","resolve","reject","href","fullhref","existingLinkTags","document","getElementsByTagName","tag","dataHref","getAttribute","rel","existingStyleTags","linkTag","createElement","type","onload","onerror","event","request","target","src","err","Error","code","parentNode","removeChild","head","appendChild","then","installedChunkData","promise","onScriptComplete","script","charset","timeout","nc","setAttribute","error","clearTimeout","chunk","errorType","realSrc","message","name","undefined","setTimeout","all","m","c","d","getter","o","defineProperty","enumerable","get","r","Symbol","toStringTag","value","t","mode","__esModule","ns","create","key","bind","n","object","property","oe","console","jsonpArray","window","oldJsonpFunction","slice","render","_vm","this","_h","$createElement","_c","_self","staticClass","attrs","icon","staticRenderFns","String","required","component","menu","arr","style","on","backTop","bottom","right","top","documentElement","scrollTop","body","duration","Number","default","components","Icon","_l","menuItem","route","class","currentRoute","_v","_s","title","$route","Array","year","website","footerItem","index","link","label","Date","getFullYear","userInfo","description","avatar","links","articles","categories","columns","footers","HOME","COLUMNS","VUE_APP_INFO_USERINFO","VUE_APP_INFO_WEBSITE","VUE_APP_INFO_FOOTERS","sort","before","after","beforeDate","createTime","afterDate","getTime","from","Set","concat","map","article","category","init","BackTop","AppNav","AppFooter","use","routes","path","meta","context","ARTICLE","COLUMN","NOTFOUND","router","base","scrollBehavior","x","y","scriptsRegister","is","VUE_APP_INFO_SCRIPTS","scriptNames","forEach","scriptInfo","asyncType","config","productionTip","app","h","App","createApp","$mount","isServerRender","isProduction","parse","str","JSON","getType","variable","toString","match","to","endCallback","diff","Math","abs","step","ceil","scroll","start","end","scrollTo","requestAnimationFrame","setLocalStorage","localStorage","setItem","getLocalStorage","getItem","isExist","val","validator","includes","warn","join","RouteName"],"mappings":"aACE,SAASA,EAAqBC,GAQ7B,IAPA,IAMIC,EAAUC,EANVC,EAAWH,EAAK,GAChBI,EAAcJ,EAAK,GACnBK,EAAiBL,EAAK,GAIHM,EAAI,EAAGC,EAAW,GACpCD,EAAIH,EAASK,OAAQF,IACzBJ,EAAUC,EAASG,GAChBG,OAAOC,UAAUC,eAAeC,KAAKC,EAAiBX,IAAYW,EAAgBX,IACpFK,EAASO,KAAKD,EAAgBX,GAAS,IAExCW,EAAgBX,GAAW,EAE5B,IAAID,KAAYG,EACZK,OAAOC,UAAUC,eAAeC,KAAKR,EAAaH,KACpDc,EAAQd,GAAYG,EAAYH,IAG/Be,GAAqBA,EAAoBhB,GAE5C,MAAMO,EAASC,OACdD,EAASU,OAATV,GAOD,OAHAW,EAAgBJ,KAAKK,MAAMD,EAAiBb,GAAkB,IAGvDe,IAER,SAASA,IAER,IADA,IAAIC,EACIf,EAAI,EAAGA,EAAIY,EAAgBV,OAAQF,IAAK,CAG/C,IAFA,IAAIgB,EAAiBJ,EAAgBZ,GACjCiB,GAAY,EACRC,EAAI,EAAGA,EAAIF,EAAed,OAAQgB,IAAK,CAC9C,IAAIC,EAAQH,EAAeE,GACG,IAA3BX,EAAgBY,KAAcF,GAAY,GAE3CA,IACFL,EAAgBQ,OAAOpB,IAAK,GAC5Be,EAASM,EAAoBA,EAAoBC,EAAIN,EAAe,KAItE,OAAOD,EAIR,IAAIQ,EAAmB,GAGnBC,EAAqB,CACxB,IAAO,GAMJjB,EAAkB,CACrB,IAAO,GAGJK,EAAkB,GAGtB,SAASa,EAAe7B,GACvB,OAAOyB,EAAoBK,EAAI,cAAgB,GAAG9B,IAAUA,GAAW,IAAM,CAAC,iBAAiB,WAAW,iBAAiB,WAAW,iBAAiB,WAAW,iBAAiB,WAAW,iBAAiB,WAAW,iBAAiB,YAAYA,GAAW,MAInQ,SAASyB,EAAoB1B,GAG5B,GAAG4B,EAAiB5B,GACnB,OAAO4B,EAAiB5B,GAAUgC,QAGnC,IAAIC,EAASL,EAAiB5B,GAAY,CACzCK,EAAGL,EACHkC,GAAG,EACHF,QAAS,IAUV,OANAlB,EAAQd,GAAUW,KAAKsB,EAAOD,QAASC,EAAQA,EAAOD,QAASN,GAG/DO,EAAOC,GAAI,EAGJD,EAAOD,QAKfN,EAAoBS,EAAI,SAAuBlC,GAC9C,IAAImC,EAAW,GAIXC,EAAY,CAAC,iBAAiB,EAAE,iBAAiB,EAAE,iBAAiB,EAAE,iBAAiB,EAAE,iBAAiB,EAAE,iBAAiB,GAC9HR,EAAmB5B,GAAUmC,EAASvB,KAAKgB,EAAmB5B,IACzB,IAAhC4B,EAAmB5B,IAAkBoC,EAAUpC,IACtDmC,EAASvB,KAAKgB,EAAmB5B,GAAW,IAAIqC,SAAQ,SAASC,EAASC,GAIzE,IAHA,IAAIC,EAAO,eAAiB,GAAGxC,IAAUA,GAAW,IAAM,CAAC,iBAAiB,WAAW,iBAAiB,WAAW,iBAAiB,WAAW,iBAAiB,WAAW,iBAAiB,WAAW,iBAAiB,YAAYA,GAAW,OAC3OyC,EAAWhB,EAAoBK,EAAIU,EACnCE,EAAmBC,SAASC,qBAAqB,QAC7CxC,EAAI,EAAGA,EAAIsC,EAAiBpC,OAAQF,IAAK,CAChD,IAAIyC,EAAMH,EAAiBtC,GACvB0C,EAAWD,EAAIE,aAAa,cAAgBF,EAAIE,aAAa,QACjE,GAAe,eAAZF,EAAIG,MAAyBF,IAAaN,GAAQM,IAAaL,GAAW,OAAOH,IAErF,IAAIW,EAAoBN,SAASC,qBAAqB,SACtD,IAAQxC,EAAI,EAAGA,EAAI6C,EAAkB3C,OAAQF,IAAK,CAC7CyC,EAAMI,EAAkB7C,GACxB0C,EAAWD,EAAIE,aAAa,aAChC,GAAGD,IAAaN,GAAQM,IAAaL,EAAU,OAAOH,IAEvD,IAAIY,EAAUP,SAASQ,cAAc,QACrCD,EAAQF,IAAM,aACdE,EAAQE,KAAO,WACfF,EAAQG,OAASf,EACjBY,EAAQI,QAAU,SAASC,GAC1B,IAAIC,EAAUD,GAASA,EAAME,QAAUF,EAAME,OAAOC,KAAOjB,EACvDkB,EAAM,IAAIC,MAAM,qBAAuB5D,EAAU,cAAgBwD,EAAU,KAC/EG,EAAIE,KAAO,wBACXF,EAAIH,QAAUA,SACP5B,EAAmB5B,GAC1BkD,EAAQY,WAAWC,YAAYb,GAC/BX,EAAOoB,IAERT,EAAQV,KAAOC,EAEf,IAAIuB,EAAOrB,SAASC,qBAAqB,QAAQ,GACjDoB,EAAKC,YAAYf,MACfgB,MAAK,WACPtC,EAAmB5B,GAAW,MAMhC,IAAImE,EAAqBxD,EAAgBX,GACzC,GAA0B,IAAvBmE,EAGF,GAAGA,EACFhC,EAASvB,KAAKuD,EAAmB,QAC3B,CAEN,IAAIC,EAAU,IAAI/B,SAAQ,SAASC,EAASC,GAC3C4B,EAAqBxD,EAAgBX,GAAW,CAACsC,EAASC,MAE3DJ,EAASvB,KAAKuD,EAAmB,GAAKC,GAGtC,IACIC,EADAC,EAAS3B,SAASQ,cAAc,UAGpCmB,EAAOC,QAAU,QACjBD,EAAOE,QAAU,IACb/C,EAAoBgD,IACvBH,EAAOI,aAAa,QAASjD,EAAoBgD,IAElDH,EAAOZ,IAAM7B,EAAe7B,GAG5B,IAAI2E,EAAQ,IAAIf,MAChBS,EAAmB,SAAUd,GAE5Be,EAAOhB,QAAUgB,EAAOjB,OAAS,KACjCuB,aAAaJ,GACb,IAAIK,EAAQlE,EAAgBX,GAC5B,GAAa,IAAV6E,EAAa,CACf,GAAGA,EAAO,CACT,IAAIC,EAAYvB,IAAyB,SAAfA,EAAMH,KAAkB,UAAYG,EAAMH,MAChE2B,EAAUxB,GAASA,EAAME,QAAUF,EAAME,OAAOC,IACpDiB,EAAMK,QAAU,iBAAmBhF,EAAU,cAAgB8E,EAAY,KAAOC,EAAU,IAC1FJ,EAAMM,KAAO,iBACbN,EAAMvB,KAAO0B,EACbH,EAAMnB,QAAUuB,EAChBF,EAAM,GAAGF,GAEVhE,EAAgBX,QAAWkF,IAG7B,IAAIV,EAAUW,YAAW,WACxBd,EAAiB,CAAEjB,KAAM,UAAWK,OAAQa,MAC1C,MACHA,EAAOhB,QAAUgB,EAAOjB,OAASgB,EACjC1B,SAASqB,KAAKC,YAAYK,GAG5B,OAAOjC,QAAQ+C,IAAIjD,IAIpBV,EAAoB4D,EAAIxE,EAGxBY,EAAoB6D,EAAI3D,EAGxBF,EAAoB8D,EAAI,SAASxD,EAASkD,EAAMO,GAC3C/D,EAAoBgE,EAAE1D,EAASkD,IAClC1E,OAAOmF,eAAe3D,EAASkD,EAAM,CAAEU,YAAY,EAAMC,IAAKJ,KAKhE/D,EAAoBoE,EAAI,SAAS9D,GACX,qBAAX+D,QAA0BA,OAAOC,aAC1CxF,OAAOmF,eAAe3D,EAAS+D,OAAOC,YAAa,CAAEC,MAAO,WAE7DzF,OAAOmF,eAAe3D,EAAS,aAAc,CAAEiE,OAAO,KAQvDvE,EAAoBwE,EAAI,SAASD,EAAOE,GAEvC,GADU,EAAPA,IAAUF,EAAQvE,EAAoBuE,IAC/B,EAAPE,EAAU,OAAOF,EACpB,GAAW,EAAPE,GAA8B,kBAAVF,GAAsBA,GAASA,EAAMG,WAAY,OAAOH,EAChF,IAAII,EAAK7F,OAAO8F,OAAO,MAGvB,GAFA5E,EAAoBoE,EAAEO,GACtB7F,OAAOmF,eAAeU,EAAI,UAAW,CAAET,YAAY,EAAMK,MAAOA,IACtD,EAAPE,GAA4B,iBAATF,EAAmB,IAAI,IAAIM,KAAON,EAAOvE,EAAoB8D,EAAEa,EAAIE,EAAK,SAASA,GAAO,OAAON,EAAMM,IAAQC,KAAK,KAAMD,IAC9I,OAAOF,GAIR3E,EAAoB+E,EAAI,SAASxE,GAChC,IAAIwD,EAASxD,GAAUA,EAAOmE,WAC7B,WAAwB,OAAOnE,EAAO,YACtC,WAA8B,OAAOA,GAEtC,OADAP,EAAoB8D,EAAEC,EAAQ,IAAKA,GAC5BA,GAIR/D,EAAoBgE,EAAI,SAASgB,EAAQC,GAAY,OAAOnG,OAAOC,UAAUC,eAAeC,KAAK+F,EAAQC,IAGzGjF,EAAoBK,EAAI,SAGxBL,EAAoBkF,GAAK,SAAShD,GAA2B,MAApBiD,QAAQjC,MAAMhB,GAAYA,GAEnE,IAAIkD,EAAaC,OAAO,gBAAkBA,OAAO,iBAAmB,GAChEC,EAAmBF,EAAWjG,KAAK2F,KAAKM,GAC5CA,EAAWjG,KAAOf,EAClBgH,EAAaA,EAAWG,QACxB,IAAI,IAAI5G,EAAI,EAAGA,EAAIyG,EAAWvG,OAAQF,IAAKP,EAAqBgH,EAAWzG,IAC3E,IAAIU,EAAsBiG,EAI1B/F,EAAgBJ,KAAK,CAAC,OAAO,kBAEtBM,K,6DC1QT,IAAI+F,EAAS,WAAa,IAAIC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,OAAOC,MAAM,CAAC,cAAc,SAAS,CAACH,EAAG,MAAM,CAACG,MAAM,CAAC,aAAc,IAAMP,EAAIQ,WACjMC,EAAkB,G,4DCWtB,uIAA6B,QACa,gBAAvC,eAAK,CAAEvE,KAAMwE,OAAQC,UAAU,K,2BADlC,kBAHC,eAAU,CACT5C,KAAM,UAIP,G,QCd8X,I,wBCQ3X6C,EAAY,eACd,EACAb,EACAU,GACA,EACA,KACA,WACA,MAIa,OAAAG,E,4GCnBX,EAAS,WAAa,IAAIZ,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,MAAMC,MAAM,CAAC,GAAK,QAAQ,CAACH,EAAG,UAAU,CAACG,MAAM,CAAC,KAAOP,EAAIa,QAAQT,EAAG,MAAM,CAACE,YAAY,qBAAqB,CAACF,EAAG,MAAM,CAACE,YAAY,aAAa,CAACF,EAAG,gBAAgB,KAAKA,EAAG,cAAcA,EAAG,WAAW,CAACE,YAAY,WAAWC,MAAM,CAAC,MAAQ,GAAG,OAAS,OAAO,IACtXE,EAAkB,G,0JCAVK,EAAW,CAAC,CAAC,GAAK,gBAAgB,KAAO,2BAA2B,MAAQ,2BAA2B,QAAU,kxGAAgyG,SAAW,SAAS,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,kBAAkB,MAAQ,kBAAkB,QAAU,glJAAomJ,SAAW,SAAS,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,eAAe,MAAQ,eAAe,QAAU,i9GAA69G,SAAW,SAAS,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,eAAe,MAAQ,eAAe,QAAU,4sEAA8sE,SAAW,SAAS,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,qBAAqB,MAAQ,kBAAkB,QAAU,yxOAA+yO,SAAW,SAAS,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,SAAS,MAAQ,OAAO,QAAU,+7gBAA6hiB,SAAW,gBAAgB,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,WAAW,MAAQ,WAAW,QAAU,6uJAA+xJ,SAAW,SAAS,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,aAAa,MAAQ,aAAa,QAAU,0iKAA8iK,SAAW,SAAS,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,SAAS,MAAQ,SAAS,QAAU,4wLAA43L,SAAW,SAAS,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,cAAc,MAAQ,gBAAgB,QAAU,6pEAA6pE,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,UAAU,MAAQ,UAAU,QAAU,m6GAAm6G,SAAW,QAAQ,WAAa,sBAAsB,OAAS,sDAAsD,CAAC,GAAK,gBAAgB,KAAO,MAAM,MAAQ,MAAM,QAAU,2hJAA6kJ,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,aAAa,MAAQ,aAAa,QAAU,w0NAA8kO,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,QAAQ,MAAQ,QAAQ,QAAU,yvEAAyvE,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,aAAa,MAAQ,WAAW,QAAU,g2MAA83M,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,SAAS,MAAQ,SAAS,QAAU,quJAAquJ,SAAW,QAAQ,WAAa,sBAAsB,CAAC,GAAK,gBAAgB,KAAO,OAAO,MAAQ,YAAY,QAAU,sjEAAsjE,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,OAAO,MAAQ,OAAO,QAAU,2/EAA2/E,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,UAAU,MAAQ,UAAU,QAAU,usEAAusE,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,eAAe,MAAQ,cAAc,QAAU,k4GAAo4G,SAAW,QAAQ,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,SAAS,MAAQ,SAAS,QAAU,0wEAA0wE,SAAW,OAAO,WAAa,sBAAsB,OAAS,sDAAsD,CAAC,GAAK,gBAAgB,KAAO,SAAS,MAAQ,SAAS,QAAU,6gFAA6gF,SAAW,OAAO,WAAa,sBAAsB,OAAS,sDAAsD,CAAC,GAAK,gBAAgB,KAAO,OAAO,MAAQ,SAAS,QAAU,0nEAA0nE,SAAW,OAAO,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,QAAQ,MAAQ,YAAY,QAAU,gyDAAgyD,SAAW,OAAO,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,OAAO,MAAQ,OAAO,QAAU,ytIAAytI,SAAW,UAAU,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,WAAW,MAAQ,WAAW,QAAU,u2KAAm4K,SAAW,UAAU,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,aAAa,MAAQ,aAAa,QAAU,8/KAA4gL,SAAW,UAAU,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,SAAS,MAAQ,SAAS,QAAU,wpUAAwqU,SAAW,UAAU,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,WAAW,MAAQ,WAAW,QAAU,w7DAAw7D,SAAW,UAAU,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,SAAS,MAAQ,SAAS,QAAU,w8FAAg9F,SAAW,UAAU,WAAa,uBAAuB,CAAC,GAAK,gBAAgB,KAAO,UAAU,MAAQ,UAAU,QAAU,2kTAAopT,SAAW,OAAO,WAAa,sBAAsB,CAAC,GAAK,gBAAgB,KAAO,UAAU,MAAQ,UAAU,QAAU,miHAAmiH,SAAW,OAAO,WAAa,sBAAsB,OAAS,uDAC32sJ,ICDT,EAAW,CAAC,CAAC,MAAQ,MAAM,SAAW,CAAC,CAAC,MAAQ,OAAO,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,OAAO,QAAU,+4EAA+4E,CAAC,MAAQ,OAAO,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,80EAAg2E,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,yrRAAmxR,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,qmFAA2mF,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,mBAAmB,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,2eAAif,CAAC,MAAQ,UAAU,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,cAAc,QAAU,q4CAAq4C,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,0tEAAwuE,CAAC,GAAK,KAAK,MAAQ,UAAU,QAAU,6hHAAqpH,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,66BAAy7B,CAAC,GAAK,KAAK,MAAQ,UAAU,QAAU,w0HAAw3H,CAAC,MAAQ,YAAY,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,eAAe,QAAU,m0EAAy1E,CAAC,GAAK,KAAK,MAAQ,eAAe,QAAU,gkFAA0lF,CAAC,GAAK,KAAK,MAAQ,eAAe,QAAU,4uDAA8vD,CAAC,GAAK,KAAK,MAAQ,cAAc,QAAU,0qIAAotI,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,kgCAA0gC,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,6sBAAqtB,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,y5EAA47E,CAAC,GAAK,KAAK,MAAQ,iBAAiB,QAAU,+nNAAmqN,CAAC,MAAQ,KAAK,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,OAAO,QAAU,qtCAA+tC,OAAS,qDAAqD,GAAK,iBAAiB,CAAC,MAAQ,UAAU,SAAW,CAAC,CAAC,MAAQ,OAAO,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,OAAO,QAAU,86DAA86D,CAAC,MAAQ,OAAO,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,4/EAA0hF,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,25LAA+8L,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,06BAA86B,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,mBAAmB,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,2eAAif,CAAC,MAAQ,UAAU,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,s1CAAo2C,CAAC,GAAK,KAAK,MAAQ,UAAU,QAAU,81GAAo9G,CAAC,GAAK,KAAK,MAAQ,eAAe,QAAU,mlGAA2nG,CAAC,MAAQ,YAAY,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,eAAe,QAAU,0yEAAg0E,CAAC,GAAK,KAAK,MAAQ,eAAe,QAAU,mhFAA6iF,CAAC,GAAK,KAAK,MAAQ,eAAe,QAAU,0pDAA4qD,CAAC,GAAK,KAAK,MAAQ,cAAc,QAAU,6+EAA6/E,CAAC,GAAK,KAAK,MAAQ,YAAY,QAAU,q8BAAy8B,CAAC,GAAK,KAAK,MAAQ,iBAAiB,QAAU,ukNAA2mN,CAAC,MAAQ,KAAK,SAAW,CAAC,CAAC,GAAK,KAAK,MAAQ,OAAO,QAAU,wIAAwI,OAAS,qDAAqD,GAAK,kBAC39zF,I,YCFjB,EAAS,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,WAAWS,MAAOf,EAAS,MAAEgB,GAAG,CAAC,MAAQhB,EAAIiB,UAAU,CAACb,EAAG,OAAO,CAACG,MAAM,CAAC,KAAO,kBAAkB,IACrN,EAAkB,G,oCCgBtB,uKAKE,WACE,MAAO,CACLW,OAAQ,GAAF,OAAKjB,KAAKiB,OAAV,MACNC,MAAO,GAAF,OAAKlB,KAAKkB,MAAV,SARX,qBAYU,WACN,IAAMC,EAAM3F,SAAS4F,gBAAgBC,WAAa7F,SAAS8F,KAAKD,UAChE,eAAUF,EAAK,EAAGnB,KAAKuB,cAd3B,GAA6B,QACU,gBAApC,eAAK,CAAEtF,KAAMuF,OAAQC,QAAS,M,6BACM,gBAApC,eAAK,CAAExF,KAAMuF,OAAQC,QAAS,M,4BACQ,gBAAtC,eAAK,CAAExF,KAAMuF,OAAQC,QAAS,Q,+BAHjC,kBANC,eAAU,CACT3D,KAAM,UACN4D,WAAY,CACVC,OAAA,SAmBH,G,QCjCiY,I,wBCQ9XhB,EAAY,eACd,EACA,EACA,GACA,EACA,KACA,WACA,MAIa,EAAAA,E,QCnBX,EAAS,WAAa,IAAIZ,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,SAAS,CAACE,YAAY,eAAe,CAACF,EAAG,MAAM,CAACE,YAAY,OAAO,CAACF,EAAG,MAAM,CAACE,YAAY,eAAeN,EAAI6B,GAAI7B,EAAQ,MAAE,SAAS8B,GAAU,OAAO1B,EAAG,cAAc,CAAChB,IAAI0C,EAASC,MAAMzB,YAAY,kBAAkBC,MAAM,CAAC,GAAK,CAC7TxC,KAAM+D,EAASC,SACb,CAAC3B,EAAG,MAAM,CAAC4B,MAAM,CAAC,qBAAsBhC,EAAIiC,eAAiBH,EAASC,OAAS,gCAAgC,CAAC3B,EAAG,OAAO,CAACJ,EAAIkC,GAAGlC,EAAImC,GAAGL,EAASM,iBAAgB,QAC1K,EAAkB,GC4BtB,G,UAAA,4KAIE,WACE,OAAOnC,KAAKoC,OAAOtE,MAAQ,OAL/B,GAA6B,SAE3B,gBADC,eAAK,CAAE7B,KAAMoG,MAAOZ,QAAS,iBAAO,O,2BADvC,kBANC,eAAU,CACT3D,KAAM,SACN4D,WAAY,CACVC,OAAA,SAUH,G,QCtCgY,ICQ7X,G,UAAY,eACd,EACA,EACA,GACA,EACA,KACA,WACA,OAIa,I,QCnBX,EAAS,WAAa,IAAI5B,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,UAAU,CAACF,EAAG,UAAU,CAACE,YAAY,kBAAkB,CAACN,EAAIkC,GAAG,IAAIlC,EAAImC,GAAGnC,EAAIuC,MAAM,IAAIvC,EAAImC,GAAGnC,EAAIwC,QAAQJ,OAAO,2BAA2BpC,EAAI6B,GAAI7B,EAAW,SAAE,SAASyC,EAAWC,GAAO,OAAOtC,EAAG,UAAU,CAAChB,IAAIsD,EAAMpC,YAAY,kBAAkB,CAAwB,kBAAfmC,EAAyBrC,EAAG,OAAO,CAACJ,EAAIkC,GAAGlC,EAAImC,GAAGM,MAAerC,EAAG,IAAI,CAACG,MAAM,CAAC,KAAOkC,EAAWE,KAAK,OAAS,SAAS,IAAM,wBAAwB,CAAC3C,EAAIkC,GAAGlC,EAAImC,GAAGM,EAAWG,gBAAe,IACrjB,EAAkB,GCuBtB,sKAKE,WACE,OAAQ,IAAIC,MAAQC,kBANxB,GAA6B,QACA,gBAA1B,eAAe,Y,8BAEW,gBAA1B,eAAe,Y,8BAHlB,kBAHC,eAAU,CACT/E,KAAM,eAUP,G,QChCmY,ICQhY,G,UAAY,eACd,EACA,EACA,GACA,EACA,KACA,WACA,OAIa,I,QCgBf,2G,0BAEU,EAAAgF,SAAyB,CAC/BhF,KAAM,GACNiF,YAAa,GACbC,OAAQ,GACRC,MAAO,IAID,EAAAC,SAAqB,GAGrB,EAAAC,WAAyB,GAGzB,EAAAC,QAAmB,GAGnB,EAAAC,QAAyB,GAGzB,EAAAd,QAAmB,CACzBJ,MAAO,GACPY,YAAa,IAxBjB,2CA2BE,WAAgB,MACRnC,EAAwB,CAC5B,CAAEuB,MAAO,KAAML,MAAO,OAAUwB,OAOlC,OAJA,UAAItD,KAAKoD,eAAT,OAAI,EAAcjK,QAChByH,EAAKnH,KAAK,CAAE0I,MAAO,KAAML,MAAO,OAAUyB,UAGrC3C,IApCX,kBAuCU,WACN,MAII,8fAHF4C,EADF,EACEA,sBACAC,EAFF,EAEEA,qBACAC,EAHF,EAGEA,qBAIF1D,KAAKuC,QAAU,eAAMvC,KAAKuC,QAASkB,GAEnCzD,KAAK8C,SAAW,eAAM9C,KAAK8C,SAAUU,GAErCxD,KAAKkD,SAAY,EAAsBS,MAAK,SAACC,EAAiBC,GAC5D,IAAMC,EAAa,IAAIlB,KAAKgB,EAAOG,YAC7BC,EAAY,IAAIpB,KAAKiB,EAAME,YAEjC,OAAOC,EAAUC,UAAYH,EAAWG,aAG1CjE,KAAKmD,WAAad,MAAM6B,KAAK,IAAIC,IAAI,CAAC,MAAMC,OAAOpE,KAAKkD,SAASmB,KAAI,SAACC,GAAD,OAAaA,EAAQC,eAE1FvE,KAAKoD,QAAU,EAEfpD,KAAKqD,QAAU,eAAMrD,KAAKqD,QAASK,KA9DvC,qBAiEU,WACN1D,KAAKwE,WAlET,GAA6B,QAE3B,gBADC,eAAgB,a,+BASjB,gBADC,eAAgB,a,+BAIjB,gBADC,eAAgB,e,iCAIjB,gBADC,eAAgB,Y,8BAIjB,gBADC,eAAgB,Y,8BAIjB,gBADC,eAAgB,Y,8BArBnB,kBARC,eAAU,CACT1G,KAAM,MACN4D,WAAY,CACV+C,UACAC,SACAC,gBAuEH,G,QCvG2W,ICQxW,G,UAAY,eACd,EACA,EACAnE,GACA,EACA,KACA,WACA,OAIa,I,oBCff,OAAIoE,IAAI,QAEO,iBACb,IAAMC,EAA6B,CACjC,CACE/G,KAAM,OAAUwF,KAChBwB,KAAM,IACNnE,UAAW,kBAAM,iDACjBoE,KAAM,CACJ5C,MADI,SACE6C,GACJ,OAAQA,EAAgBzC,QAAQJ,SAItC,CACErE,KAAM,OAAUmH,QAChBH,KAAM,eACNnE,UAAW,kBAAM,sFACjBoE,KAAM,CACJ5C,MADI,SACE6C,GACJ,OAAQA,EAAgB7C,SAI9B,CACErE,KAAM,OAAUyF,QAChBuB,KAAM,WACNnE,UAAW,kBAAM,iDACjBoE,KAAM,CACJ5C,MAAO,OAGX,CACErE,KAAM,OAAUoH,OAChBJ,KAAM,oBACNnE,UAAW,kBAAM,sFACjBoE,KAAM,CACJ5C,MADI,SACE6C,GACJ,OAAQA,EAAgB7C,SAI9B,CACErE,KAAM,OAAUqH,SAChBL,KAAM,IACNnE,UAAW,kBAAM,mDAIfyE,EAAS,IAAI,OAAU,CAC3BrG,KAAM,UACNsG,KAAM,SACNR,SACAS,eAJ2B,WAKzB,MAAO,CACLC,EAAG,EACHC,EAAG,MAKT,MAAO,CACLJ,W,kCC9DJ,SAASK,IACP,IAAIC,EAAA,OAAkBA,EAAA,KAAtB,CAIA,MAAwC,KAAhCC,OAAR,MAA+B,KAA/B,EACMC,EAAc,eAAM,GAAID,GAE9BC,EAAYC,SAAQ,SAACC,GACnB,IAAMhB,EAAO,mBAAsB,kBAAfgB,EAAsCA,EAA2BA,EAAWvJ,KAC1FY,EAA4B3B,SAASQ,cAAc,UACzDmB,EAAOZ,IAAMuI,EAEa,kBAAfgB,GAA2BA,EAAWC,YAC/C5I,EAAO2I,EAAWC,YAAa,GAGjCvK,SAAS8F,KAAKxE,YAAYK,OAI9BsI,IClBA,OAAIO,OAAOC,eAAgB,EAEZ,iBAEb,MAAmB,IAAXb,EAAR,EAAQA,OAGFc,EAAM,IAAI,OAAI,CAClBd,SACAtF,OAAQ,SAACqG,GAAD,OAAOA,EAAEC,MAGnB,MAAO,CACLF,MACAd,WCnBJ,EAAgBiB,IAAR,EAAR,EAAQH,IAER,EAAII,OAAO,S,2DCJX,W,oCCAA,W,+GCAA,W,yDCAA,oEAAO,IAAMC,GAAiB,EAEjBC,GAAe,G,gWCFtB,SAAUC,EAASnK,EAAWoK,GAClC,IACE,OAAOC,KAAKF,MAAMC,GAClB,MAAOlK,GACP,OAAOF,GAIL,SAAUsK,EAAQC,GAAa,MACnC,OAAO,UAAAzN,OAAOC,UAAUyN,SAASvN,KAAKsN,GAAUE,MAAM,0BAA/C,eAAoE,KAAM,GAG7E,SAAU1F,IAAwF,IAA9E6C,EAA8E,uDAA/D,EAAG8C,EAA4D,uCAAhDzF,EAAgD,uDAA7B,IAAK0F,EAAwB,uCAChGC,EAAOC,KAAKC,IAAIlD,EAAO8C,GACvBK,EAAOF,KAAKG,KAAKJ,EAAO3F,EAAW,IAEzC,SAASgG,EAAOC,EAAeC,EAAaJ,GAC1C,GAAIG,IAAUC,EAAd,CAQA,IAAIrJ,EAAKoJ,EAAQH,EAAOI,EAAOA,EAAMD,EAAQH,EAEzCG,EAAQC,IACVrJ,EAAKoJ,EAAQH,EAAOI,EAAOA,EAAMD,EAAQH,GAG3C1H,OAAO+H,SAAStJ,EAAGA,GACnBuB,OAAOgI,uBAAsB,kBAAMJ,EAAOnJ,EAAGqJ,EAAKJ,WAd5CJ,GACFA,IAgBNM,EAAOrD,EAAM8C,EAAIK,GAqBb,SAAUO,EAAgBzI,EAAaN,GAAU,MACrD,UAAIc,cAAJ,OAAI,EAAQkI,cACVlI,OAAOkI,aAAaC,QAAQ3I,EAAKN,GAI/B,SAAUkJ,EAAgB5I,GAAW,MACzC,iBAAIQ,cAAJ,OAAI,EAAQkI,cACHlI,OAAOkI,aAAaG,QAAQ7I,IAG9B,GAGH,SAAU8I,EAAQC,GACtB,YAAenK,IAARmK,GAA6B,OAARA,EAGxB,SAAUC,EAAUtH,GACxB,OAAO,SAACqH,GACN,IAAMlO,EAAS6G,EAAIuH,SAASF,GAO5B,OALKlO,GAEHyF,QAAQ4I,KAAR,oBAA0BxH,EAAIyH,KAAK,MAAnC,aAGKtO,K,kCCnFX,IAAKuO,GAAL,SAAKA,GACH,iBACA,uBACA,qBACA,uBACA,0BALF,CAAKA,MAAS,KAQC,U,kCCRf,W,kCCAA","file":"static/js/app.41aa715e.js","sourcesContent":[" \t// install a JSONP callback for chunk loading\n \tfunction webpackJsonpCallback(data) {\n \t\tvar chunkIds = data[0];\n \t\tvar moreModules = data[1];\n \t\tvar executeModules = data[2];\n\n \t\t// add \"moreModules\" to the modules object,\n \t\t// then flag all \"chunkIds\" as loaded and fire callback\n \t\tvar moduleId, chunkId, i = 0, resolves = [];\n \t\tfor(;i < chunkIds.length; i++) {\n \t\t\tchunkId = chunkIds[i];\n \t\t\tif(Object.prototype.hasOwnProperty.call(installedChunks, chunkId) && installedChunks[chunkId]) {\n \t\t\t\tresolves.push(installedChunks[chunkId][0]);\n \t\t\t}\n \t\t\tinstalledChunks[chunkId] = 0;\n \t\t}\n \t\tfor(moduleId in moreModules) {\n \t\t\tif(Object.prototype.hasOwnProperty.call(moreModules, moduleId)) {\n \t\t\t\tmodules[moduleId] = moreModules[moduleId];\n \t\t\t}\n \t\t}\n \t\tif(parentJsonpFunction) parentJsonpFunction(data);\n\n \t\twhile(resolves.length) {\n \t\t\tresolves.shift()();\n \t\t}\n\n \t\t// add entry modules from loaded chunk to deferred list\n \t\tdeferredModules.push.apply(deferredModules, executeModules || []);\n\n \t\t// run deferred modules when all chunks ready\n \t\treturn checkDeferredModules();\n \t};\n \tfunction checkDeferredModules() {\n \t\tvar result;\n \t\tfor(var i = 0; i < deferredModules.length; i++) {\n \t\t\tvar deferredModule = deferredModules[i];\n \t\t\tvar fulfilled = true;\n \t\t\tfor(var j = 1; j < deferredModule.length; j++) {\n \t\t\t\tvar depId = deferredModule[j];\n \t\t\t\tif(installedChunks[depId] !== 0) fulfilled = false;\n \t\t\t}\n \t\t\tif(fulfilled) {\n \t\t\t\tdeferredModules.splice(i--, 1);\n \t\t\t\tresult = __webpack_require__(__webpack_require__.s = deferredModule[0]);\n \t\t\t}\n \t\t}\n\n \t\treturn result;\n \t}\n\n \t// The module cache\n \tvar installedModules = {};\n\n \t// object to store loaded CSS chunks\n \tvar installedCssChunks = {\n \t\t\"app\": 0\n \t}\n\n \t// object to store loaded and loading chunks\n \t// undefined = chunk not loaded, null = chunk preloaded/prefetched\n \t// Promise = chunk loading, 0 = chunk loaded\n \tvar installedChunks = {\n \t\t\"app\": 0\n \t};\n\n \tvar deferredModules = [];\n\n \t// script path function\n \tfunction jsonpScriptSrc(chunkId) {\n \t\treturn __webpack_require__.p + \"static/js/\" + ({}[chunkId]||chunkId) + \".\" + {\"chunk-2e3fbe22\":\"ff12df6f\",\"chunk-3a5a13a3\":\"0cebf565\",\"chunk-b31288f6\":\"bfb70cd4\",\"chunk-d54686c8\":\"5143f685\",\"chunk-4b00a56a\":\"f60616c1\",\"chunk-52bf6e4f\":\"1a087b42\"}[chunkId] + \".js\"\n \t}\n\n \t// The require function\n \tfunction __webpack_require__(moduleId) {\n\n \t\t// Check if module is in cache\n \t\tif(installedModules[moduleId]) {\n \t\t\treturn installedModules[moduleId].exports;\n \t\t}\n \t\t// Create a new module (and put it into the cache)\n \t\tvar module = installedModules[moduleId] = {\n \t\t\ti: moduleId,\n \t\t\tl: false,\n \t\t\texports: {}\n \t\t};\n\n \t\t// Execute the module function\n \t\tmodules[moduleId].call(module.exports, module, module.exports, __webpack_require__);\n\n \t\t// Flag the module as loaded\n \t\tmodule.l = true;\n\n \t\t// Return the exports of the module\n \t\treturn module.exports;\n \t}\n\n \t// This file contains only the entry chunk.\n \t// The chunk loading function for additional chunks\n \t__webpack_require__.e = function requireEnsure(chunkId) {\n \t\tvar promises = [];\n\n\n \t\t// mini-css-extract-plugin CSS loading\n \t\tvar cssChunks = {\"chunk-2e3fbe22\":1,\"chunk-3a5a13a3\":1,\"chunk-b31288f6\":1,\"chunk-d54686c8\":1,\"chunk-4b00a56a\":1,\"chunk-52bf6e4f\":1};\n \t\tif(installedCssChunks[chunkId]) promises.push(installedCssChunks[chunkId]);\n \t\telse if(installedCssChunks[chunkId] !== 0 && cssChunks[chunkId]) {\n \t\t\tpromises.push(installedCssChunks[chunkId] = new Promise(function(resolve, reject) {\n \t\t\t\tvar href = \"static/css/\" + ({}[chunkId]||chunkId) + \".\" + {\"chunk-2e3fbe22\":\"a53d4fc3\",\"chunk-3a5a13a3\":\"2a512b60\",\"chunk-b31288f6\":\"c0879475\",\"chunk-d54686c8\":\"30e0cc7d\",\"chunk-4b00a56a\":\"e2e22ac3\",\"chunk-52bf6e4f\":\"2a374e40\"}[chunkId] + \".css\";\n \t\t\t\tvar fullhref = __webpack_require__.p + href;\n \t\t\t\tvar existingLinkTags = document.getElementsByTagName(\"link\");\n \t\t\t\tfor(var i = 0; i < existingLinkTags.length; i++) {\n \t\t\t\t\tvar tag = existingLinkTags[i];\n \t\t\t\t\tvar dataHref = tag.getAttribute(\"data-href\") || tag.getAttribute(\"href\");\n \t\t\t\t\tif(tag.rel === \"stylesheet\" && (dataHref === href || dataHref === fullhref)) return resolve();\n \t\t\t\t}\n \t\t\t\tvar existingStyleTags = document.getElementsByTagName(\"style\");\n \t\t\t\tfor(var i = 0; i < existingStyleTags.length; i++) {\n \t\t\t\t\tvar tag = existingStyleTags[i];\n \t\t\t\t\tvar dataHref = tag.getAttribute(\"data-href\");\n \t\t\t\t\tif(dataHref === href || dataHref === fullhref) return resolve();\n \t\t\t\t}\n \t\t\t\tvar linkTag = document.createElement(\"link\");\n \t\t\t\tlinkTag.rel = \"stylesheet\";\n \t\t\t\tlinkTag.type = \"text/css\";\n \t\t\t\tlinkTag.onload = resolve;\n \t\t\t\tlinkTag.onerror = function(event) {\n \t\t\t\t\tvar request = event && event.target && event.target.src || fullhref;\n \t\t\t\t\tvar err = new Error(\"Loading CSS chunk \" + chunkId + \" failed.\\n(\" + request + \")\");\n \t\t\t\t\terr.code = \"CSS_CHUNK_LOAD_FAILED\";\n \t\t\t\t\terr.request = request;\n \t\t\t\t\tdelete installedCssChunks[chunkId]\n \t\t\t\t\tlinkTag.parentNode.removeChild(linkTag)\n \t\t\t\t\treject(err);\n \t\t\t\t};\n \t\t\t\tlinkTag.href = fullhref;\n\n \t\t\t\tvar head = document.getElementsByTagName(\"head\")[0];\n \t\t\t\thead.appendChild(linkTag);\n \t\t\t}).then(function() {\n \t\t\t\tinstalledCssChunks[chunkId] = 0;\n \t\t\t}));\n \t\t}\n\n \t\t// JSONP chunk loading for javascript\n\n \t\tvar installedChunkData = installedChunks[chunkId];\n \t\tif(installedChunkData !== 0) { // 0 means \"already installed\".\n\n \t\t\t// a Promise means \"currently loading\".\n \t\t\tif(installedChunkData) {\n \t\t\t\tpromises.push(installedChunkData[2]);\n \t\t\t} else {\n \t\t\t\t// setup Promise in chunk cache\n \t\t\t\tvar promise = new Promise(function(resolve, reject) {\n \t\t\t\t\tinstalledChunkData = installedChunks[chunkId] = [resolve, reject];\n \t\t\t\t});\n \t\t\t\tpromises.push(installedChunkData[2] = promise);\n\n \t\t\t\t// start chunk loading\n \t\t\t\tvar script = document.createElement('script');\n \t\t\t\tvar onScriptComplete;\n\n \t\t\t\tscript.charset = 'utf-8';\n \t\t\t\tscript.timeout = 120;\n \t\t\t\tif (__webpack_require__.nc) {\n \t\t\t\t\tscript.setAttribute(\"nonce\", __webpack_require__.nc);\n \t\t\t\t}\n \t\t\t\tscript.src = jsonpScriptSrc(chunkId);\n\n \t\t\t\t// create error before stack unwound to get useful stacktrace later\n \t\t\t\tvar error = new Error();\n \t\t\t\tonScriptComplete = function (event) {\n \t\t\t\t\t// avoid mem leaks in IE.\n \t\t\t\t\tscript.onerror = script.onload = null;\n \t\t\t\t\tclearTimeout(timeout);\n \t\t\t\t\tvar chunk = installedChunks[chunkId];\n \t\t\t\t\tif(chunk !== 0) {\n \t\t\t\t\t\tif(chunk) {\n \t\t\t\t\t\t\tvar errorType = event && (event.type === 'load' ? 'missing' : event.type);\n \t\t\t\t\t\t\tvar realSrc = event && event.target && event.target.src;\n \t\t\t\t\t\t\terror.message = 'Loading chunk ' + chunkId + ' failed.\\n(' + errorType + ': ' + realSrc + ')';\n \t\t\t\t\t\t\terror.name = 'ChunkLoadError';\n \t\t\t\t\t\t\terror.type = errorType;\n \t\t\t\t\t\t\terror.request = realSrc;\n \t\t\t\t\t\t\tchunk[1](error);\n \t\t\t\t\t\t}\n \t\t\t\t\t\tinstalledChunks[chunkId] = undefined;\n \t\t\t\t\t}\n \t\t\t\t};\n \t\t\t\tvar timeout = setTimeout(function(){\n \t\t\t\t\tonScriptComplete({ type: 'timeout', target: script });\n \t\t\t\t}, 120000);\n \t\t\t\tscript.onerror = script.onload = onScriptComplete;\n \t\t\t\tdocument.head.appendChild(script);\n \t\t\t}\n \t\t}\n \t\treturn Promise.all(promises);\n \t};\n\n \t// expose the modules object (__webpack_modules__)\n \t__webpack_require__.m = modules;\n\n \t// expose the module cache\n \t__webpack_require__.c = installedModules;\n\n \t// define getter function for harmony exports\n \t__webpack_require__.d = function(exports, name, getter) {\n \t\tif(!__webpack_require__.o(exports, name)) {\n \t\t\tObject.defineProperty(exports, name, { enumerable: true, get: getter });\n \t\t}\n \t};\n\n \t// define __esModule on exports\n \t__webpack_require__.r = function(exports) {\n \t\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n \t\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n \t\t}\n \t\tObject.defineProperty(exports, '__esModule', { value: true });\n \t};\n\n \t// create a fake namespace object\n \t// mode & 1: value is a module id, require it\n \t// mode & 2: merge all properties of value into the ns\n \t// mode & 4: return value when already ns object\n \t// mode & 8|1: behave like require\n \t__webpack_require__.t = function(value, mode) {\n \t\tif(mode & 1) value = __webpack_require__(value);\n \t\tif(mode & 8) return value;\n \t\tif((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;\n \t\tvar ns = Object.create(null);\n \t\t__webpack_require__.r(ns);\n \t\tObject.defineProperty(ns, 'default', { enumerable: true, value: value });\n \t\tif(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));\n \t\treturn ns;\n \t};\n\n \t// getDefaultExport function for compatibility with non-harmony modules\n \t__webpack_require__.n = function(module) {\n \t\tvar getter = module && module.__esModule ?\n \t\t\tfunction getDefault() { return module['default']; } :\n \t\t\tfunction getModuleExports() { return module; };\n \t\t__webpack_require__.d(getter, 'a', getter);\n \t\treturn getter;\n \t};\n\n \t// Object.prototype.hasOwnProperty.call\n \t__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };\n\n \t// __webpack_public_path__\n \t__webpack_require__.p = \"/blog/\";\n\n \t// on error function for async loading\n \t__webpack_require__.oe = function(err) { console.error(err); throw err; };\n\n \tvar jsonpArray = window[\"webpackJsonp\"] = window[\"webpackJsonp\"] || [];\n \tvar oldJsonpFunction = jsonpArray.push.bind(jsonpArray);\n \tjsonpArray.push = webpackJsonpCallback;\n \tjsonpArray = jsonpArray.slice();\n \tfor(var i = 0; i < jsonpArray.length; i++) webpackJsonpCallback(jsonpArray[i]);\n \tvar parentJsonpFunction = oldJsonpFunction;\n\n\n \t// add entry module to deferred list\n \tdeferredModules.push([\"1e84\",\"chunk-vendors\"]);\n \t// run deferred modules when ready\n \treturn checkDeferredModules();\n","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('svg',{staticClass:\"icon\",attrs:{\"aria-hidden\":\"true\"}},[_c('use',{attrs:{\"xlink:href\":(\"#\" + _vm.icon)}})])}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","\n\n\n\n\n\n\nimport { Vue, Component, Prop } from 'vue-property-decorator';\n\n@Component({\n  name: 'Icon',\n})\nexport default class extends Vue {\n  @Prop({ type: String, required: true }) private icon!: string;\n}\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/ts-loader/index.js??ref--13-3!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Icon.vue?vue&type=script&lang=ts&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/ts-loader/index.js??ref--13-3!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Icon.vue?vue&type=script&lang=ts&\"","import { render, staticRenderFns } from \"./Icon.vue?vue&type=template&id=ca6c9938&scoped=true&\"\nimport script from \"./Icon.vue?vue&type=script&lang=ts&\"\nexport * from \"./Icon.vue?vue&type=script&lang=ts&\"\nimport style0 from \"./Icon.vue?vue&type=style&index=0&id=ca6c9938&lang=less&scoped=true&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"ca6c9938\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"app\",attrs:{\"id\":\"app\"}},[_c('app-nav',{attrs:{\"menu\":_vm.menu}}),_c('div',{staticClass:\"container-wrapper\"},[_c('div',{staticClass:\"container\"},[_c('router-view')],1)]),_c('app-footer'),_c('back-top',{staticClass:\"back-top\",attrs:{\"right\":60,\"bottom\":60}})],1)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","/* tslint:disable */\n      const arr: any = [{\"id\":\"1633509976297\",\"name\":\"Docker(一) ubuntu安装docker\",\"title\":\"Docker(一) ubuntu安装docker\",\"content\":\"\\n\\n### 1. 条件\\n\\n+ 64位CPU\\n\\n+ 内核：Linux 3.8或更高版本内核\\n\\n  ~~~shell\\n  # 检查linux系统内核\\n  $ uname -a\\n  Linux ...4avy58ig34pcZ 4.15.0-88-generic #88-Ubuntu SMP Tue Feb 11 20:11:34 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux\\n  ~~~\\n\\n+ 检查Device Mapper\\n\\n  任何Ubuntu 12.04或更高版本的宿主机应该都已经安装了Device Mapper，可以通过代码确认是否已经安装\\n\\n  ~~~shell\\n  $ ls -l /sys/class/misc/device-mapper\\n  lrwxrwxrwx 1 root root 0 Mar 17 20:55 /sys/class/misc/device-mapper -> ../../devices/virtual/misc/device-mapper\\n  ~~~\\n\\n### 2. 安装\\n\\n```shell\\n# 安装依赖包\\n$ sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common\\n# 添加 Docker 的官方 GPG 密钥\\n$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\\n# 验证您现在是否拥有带有指纹的密钥\\n$ sudo apt-key fingerprint 0EBFCD88\\n# 设置稳定版仓库\\n# 国内源\\n$ sudo add-apt-repository \\\\\\n    \\\"deb [arch=amd64] https://mirrors.ustc.edu.cn/docker-ce/linux/ubuntu \\\\\\n    $(lsb_release -cs) \\\\\\n    stable\\\"\\n# 官方源\\n$ sudo add-apt-repository \\\\\\n    \\\"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\\\\n    $(lsb_release -cs) \\\\\\n    stable\\\"\\n# 安装 Docker Engine-Community\\n$ sudo apt-get update\\n$ sudo apt-get install docker-ce\\n```\\n\\n### 3. 启动\\n\\n~~~shell\\n# 启动\\n$ sudo systemctl enable docker\\n$ sudo systemctl start docker\\n~~~\\n\\n### 4. 测试\\n\\n~~~shell\\n$ docker run hello-world\\nUnable to find image 'hello-world:latest' locally\\nlatest: Pulling from library/hello-world\\n0e03bdcc26d7: Pull complete\\nDigest: sha256:8e3114318a995a1ee497790535e7b88365222a21771ae7e53687ad76563e8e76\\nStatus: Downloaded newer image for hello-world:latest\\n\\nHello from Docker!\\nThis message shows that your installation appears to be working correctly.\\n\\nTo generate this message, Docker took the following steps:\\n 1. The Docker client contacted the Docker daemon.\\n 2. The Docker daemon pulled the \\\"hello-world\\\" image from the Docker Hub.\\n    (amd64)\\n 3. The Docker daemon created a new container from that image which runs the\\n    executable that produces the output you are currently reading.\\n 4. The Docker daemon streamed that output to the Docker client, which sent it\\n    to your terminal.\\n\\nTo try something more ambitious, you can run an Ubuntu container with:\\n $ docker run -it ubuntu bash\\n\\nShare images, automate workflows, and more with a free Docker ID:\\n https://hub.docker.com/\\n\\nFor more examples and ideas, visit:\\n https://docs.docker.com/get-started/\\n~~~\\n\\n### 5. 镜像加速\\n\\n国内从 Docker Hub 拉取镜像有时会遇到困难，此时可以配置镜像加速器。国内很多云服务商都提供了国内加速器服务\\n\\n对于使用 [systemd](https://www.freedesktop.org/wiki/Software/systemd/) 的系统，请在 `/etc/docker/daemon.json` 中写入如下内容（如果文件不存在请新建该文件）\\n\\n~~~json\\n{\\n  \\\"registry-mirrors\\\": [\\n    \\\"https://hub-mirror.c.163.com\\\"\\n  ]\\n}\\n~~~\\n\\n然后重新启动服务\\n\\n~~~shell\\n$ sudo systemctl daemon-reload\\n$ sudo systemctl restart docker\\n~~~\\n\\n检查是否生效，执行 `$ docker info`，如果从结果中看到了如下内容，说明配置成功\\n\\n```bash\\nRegistry Mirrors:\\n https://hub-mirror.c.163.com/\\n```\\n\\n### 6. 开启实验特性\\n\\n一些 docker 命令或功能仅当 **实验特性** 开启时才能使用，请按照以下方法进行设置。\\n\\n### 7. 实验特性\\n\\n#### 7.1 开启 Docker CLI 的实验特性\\n\\n编辑 `~/.docker/config.json` 文件，新增如下条目\\n\\n```json\\n{\\n  \\\"experimental\\\": \\\"enabled\\\"\\n}\\n```\\n\\n或者通过设置环境变量的方式：\\n\\n**Linux/macOS**\\n\\n```bash\\n$ export DOCKER_CLI_EXPERIMENTAL=enabled\\n```\\n\\n#### 7.2 开启 Dockerd 的实验特性\\n\\n编辑 `/etc/docker/daemon.json`，新增如下条目\\n\\n```json\\n{\\n  \\\"experimental\\\": true\\n}\\n```\",\"category\":\"Docker\",\"createTime\":\"2021/04/01 11:25:00\"},{\"id\":\"1633509976298\",\"name\":\"Docker(三) 镜像和仓库\",\"title\":\"Docker(三) 镜像和仓库\",\"content\":\"\\n\\n### 1. 什么是镜像\\n\\n+ Docker镜像是由文件系统叠加而成，最底层是引导文件系统，即bootfs\\n\\n  + 当一个容器启动时，它会被移到内存中，而引导文件会被卸载\\n\\n+ 第二层是root文件系统rootfs，它位于引导文件之上\\n\\n  + root文件系统永远是只读状态，并且Docker利用**联合加载技术**(union mount)又会在root文件系统层上加载更多得只读文件系统\\n  + 联合加载：一次同时加载多个文件系统，但是在外面看起来只能看到一个文件系统。联合加载会将各层文件系统叠加到一起，这样最终的文件系统会包含所有底层的文件和目录\\n\\n  经过联合加载技术之后形成的文件系统，叫做镜像\\n\\n+ 一个镜像可以放到另一个镜像的顶部\\n\\n  + 位于下面的镜像叫做父镜像\\n  + 最底部的镜像称为**基础镜像**\\n\\n  当从一个镜像启动容器时，Docker会在该镜像的最顶层加载一个读写文件系统，我们想在Docker中运行的程序就是在这个读写层中执行的\\n\\n![](https://static.mittacy.com/blog/20200419164306.jpg)\\n\\n+ 当Docker第一次启动一个容器时，初始的读写层是空的。当文件系统发生变化时，这些变化会应用到这一层上(写时复制机制)\\n  + 比如修改一个文件，这个文件首先会从该读写层下面的只读层复制到该读写层，该文件的只读版本依然存在，但是已经被读写层中的该文件副本所隐藏\\n+ 写时复制机制\\n  + 每个只读镜像层都是只读的，并且以后永远不会变化\\n  + 当创建一个新容器时，Docker会**构建一个镜像栈，并且在最顶端添加一个读写层**\\n  + 读写层 + 其下面的镜像层 + 配置数据 = 容器\\n\\n### 2. 相关操作\\n\\n~~~shell\\n# 查询镜像\\n$ docker images\\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\\nubuntu              latest              4e5021d210f6        4 weeks ago         64.2MB\\ngolang              latest              374d57ff6662        4 weeks ago         809MB\\nredis               latest              f0453552d7f2        5 weeks ago         98.2MB\\nmysql               latest              9b51d9275906        6 weeks ago         547MB\\nnginx               latest              a1523e859360        7 weeks ago         127MB\\nubuntu              18.04               72300a873c2c        8 weeks ago         64.2MB\\n# 查看某个仓库的镜像\\n$ docker images ubuntu\\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\\nubuntu              latest              4e5021d210f6        4 weeks ago         64.2MB\\nubuntu              18.04               72300a873c2c        8 weeks ago         64.2MB\\n# 拉取镜像\\n$ docker pull ubuntu:18.04\\nPulling repository ubuntu\\n......\\n# 查找镜像\\n$ docker search ubuntu\\t# 该命令返回所有名字带有ubuntu的镜像\\n# 删除镜像，只删除本地，如果已经同步到Docker Hub上需要登录Docker Hub去删除\\n$ docker image rm ...\\n$ docker rmi ...\\n~~~\\n\\n为了区分同一仓库中的不同镜像，Docker提供了一种称为标签tag的功能，每个镜像都带有一个标签，比如ubuntu:18.04中的18.04就是标签；我们可以通过在仓库名后面加上一个冒号和标签名来指定该仓库中的某一镜像；如果不加标签，那么Docker会自动下载**latest标签**的镜像\\n\\n### 3. 构建镜像\\n\\n#### 3.1 RUN\\n\\n指定镜像构建时要运行的命令\\n\\n~~~dockerfile\\nFROM ubuntu:18.04\\nRUN apt-get update && apt-get install -y nginx\\n...\\n...\\n~~~\\n\\n#### 3.2 CMD\\n\\n指定容器被启动时要运行的命令，在Dockerfile中只能有一条CMD指令，如果有多条，则最后一条CMD指令会被使用\\n\\n~~~dockerfile\\nFROM ubuntu:18.04\\n...\\n...\\nCMD [\\\"/bin/bash\\\"(, [\\\"参数\\\"])]\\n~~~\\n\\n**切记：`$ docker run命令可以覆盖CMD指令 `**\\n\\n如果我们在Dockerfile里指定了CMD指令，而同时在docker run命令行中也指定了要运行的命令，命令行中指定的命令会覆盖Dockerfile中的CMD指令\\n\\n~~~shell\\n$ docker run -i -t ubuntu:18.04 /bin/ps\\n~~~\\n\\n`/bin/ps`命令将覆盖Dockerfile文件中的CMD指令\\n\\n#### 3.3 ENTRYPOINT\\n\\n实际上，docker run 命令行中指定的任何参数都会被当做参数，再次传递给 entrypoint指令 中指定的命令\\n\\nentrypoint和cmd搭配可以实现类似 函数默认参数 的实现\\n\\nDockerfile文件：\\n\\n~~~dockerfile\\n...\\nENTRYPOINT [\\\"/usr/sbin/nginx\\\"]\\nCMD [\\\"-h\\\"]\\n~~~\\n\\n启动容器命令：\\n\\n+ `$ docker run -t -i mittacy/static_web -g \\\"daemon off;\\\"`\\n\\n  则`-g \\\"daemon off;\\\"`会覆盖CMD [\\\"-h\\\"]传递给EntryPoint指令，最终执行：\\n\\n  `/usr/sbin/nginx -g daemon off;`\\n\\n+\\t`$ docker run -t -i mittacy/static_web`\\n\\n  没有传递参数。，则使用CMD指令，最终执行：\\n\\n  `/usr/sbin/nginx -h`\\n\\n如果想要覆盖EntryPoint，可以：\\n\\n`$ docker run --entrypoint=\\\"\\\"`\\n\\n#### 3.4 WORKDIR\\n\\nWorkDir指令 用来在从镜像创建一个新容器时，在容器内部设置一个工作目录\\n\\nEntryPoint和/或CMD指定的程序会在这个目录下执行\\n\\n新建容器时，可以使用`-w`来覆盖工作目录\\n\\n#### 3.5 ENV\\n\\n在镜像构建过程中设置环境变量\\n\\n#### 3.6 USER\\n\\n该镜像会以什么样的用户去运行\\n\\n如果不通过USER指令指定用户，默认用户为 root\\n\\n#### 3.7 VOLUME\\n\\n用来想基于镜像创建的容器添加卷，一个卷可以存在于一个或者多个容器内的特点的目录，这个目录可以绕过联合文件系统，并提供如下共享数据或者对数据进行持久化的功能\\n\\n+ 卷可以在容器间共享和重用\\n+ 对卷的修改是立即生效的\\n+ 对卷的修改不会对更新镜像产生影响\\n+ 卷会一直存在直到没有任何容器再使用它\\n\\n可以指定多个卷\\n\\n~~~\\nVOLUME [\\\"/opt/project\\\", \\\"/data\\\"]\\n~~~\\n\\n#### 3.8 ADD\\n\\n用来将构建环境下的文件和目录复制到镜像中\\n\\n+ 如果目的地址以 / 结尾，那么Docker就认为源位置指向的是一个目录\\n+ 不是以 / 结尾，那么Docker就认为源位置指向的是文件\\n\\n~~~\\nADD latest.tar.gz /var/www/wordpress\\n~~~\\n\\n如果源位置指向的文件是压缩文件，这条命令会将归档文件 latest.tar.gz 解开到 /var/www/wordpress/ 目录下，Docker 解开归档文件的行为和使用带-x 选项的 tar命令 一样\\n\\n如果目的位置不存在的话，Docker 会创建这个全路径，新创建的文件和目录的模式为0755(- rwx r-x r-x)\\n\\n**ADD指令会使得构建缓存变得无效**\\n\\n#### 3.9 COPY\\n\\nCOPY 和 ADD区别：\\n\\n+ Copy 只复制，不会管文件提取、解压\\n+ 文件源路径必须是一个与当前构建环境相对的文件或者目录，本地文件都放到和Dockerfile同一目录下\\n+ 目的位置必须是容器内部的一个绝对路径\\n\\n#### 3.10 LABEL\\n\\n#### 3.11 STOPSIGNAL\\n\\n#### 3.12 ARG\\n\\n#### 3.13 ONBUILD\\n\\n### 4. 推送镜像到Docker Hub\\n\\n通过`docker push`\\n\\n~~~shell\\n$ docker push mittacy/image_name\\n~~~\\n\\n### 5. 自动构建\\n\\n​\\t为了使用自动构建，只需要将 Github 或 BitBucket 中含有 Dockerfile 文件的仓库连接到 Docker Hub即可。添加完成后，以后每次向这个代码仓库推送代码时，将会出发一次镜像构建活动并创建一个新镜像\\n\\n① 将Github 账号连接到Docker Hub\\n\\n② 选择用来进行自动构建的仓库\\n\\n③ 配置信息，点击 Create Repository 完成连接\\n\\n单击 Build Status 可以查看最近一次构建的状态，包括标椎输出的日志，记录了构建过程已经任何的错误。\\n\\n如果状态为Done，则表示自动构建为最新状态；Error 表示构建过程出现错误\\n\\n**不能通过 docker push 命令推送一个自动构建，只能通过更新GitHub / BitBucket仓库来更新自动构建**\\n\\n\",\"category\":\"Docker\",\"createTime\":\"2021/04/02 12:25:00\"},{\"id\":\"1633509976299\",\"name\":\"Docker(二) 入门\",\"title\":\"Docker(二) 入门\",\"content\":\"\\n\\n### 1. 运行一个ubuntu\\n\\n~~~shell\\n$ sudo docker run -i -t ubuntu:18.04 /bin/bash\\n……\\n……\\nroot@d823d5acadcc:/#\\n~~~\\n\\n解析这个命令：\\n\\n+ -i 保证容器中 STDIN 是开启的，尽管我们并没有附着到容器\\n+ -t 告诉Docker为要创建的容器分配一个为 tty 终端，这样新创建的容器才能提供一个交互式的shell\\n+ ubuntu:18.04  告诉Docker基于什么镜像来创建容器，实例中使用的是ubuntu:18.04镜像(省略18.04则默认使用last版本)\\n+ /bin/bash  这句是运行容器后，在新容器要运行的命令\\n\\n解析这个过程：\\n\\n1. Docker检查本地是否存在ubuntu:18.04镜像，如果本地还没有该镜像的话，那么Docker就会连接Docker Hub Registry，查看 Docker Hub中是否有该镜像。Docker一旦找到该镜像，就会下载该镜像并保存其到本地宿主机中\\n2. 随后，使用这个镜像创建了一个新容器，该容器有自己的网络、IP地址，以及一个用来和宿主进行通信的桥接网络接口。\\n3. 最后我们告诉Docker在新容器中要运行什么命令，例子中的`/bin/bash`命令启动了一个Bash shell\\n\\n现在，我们以root用户登录到了新容器中，容器的Id为：d823d5acadcc，这是一个完整的Ubuntu系统，可以用它来做任何事情\\n\\n### 2. 容器命名\\n\\n~~~shell\\n$ docker container ls -a\\nCONTAINER ID   IMAGE          COMMAND    CREATED      STATUS       PORTS        NAMES\\nc345d5sasdfkj  ubuntu:18.04  \\\"/bin/bash\\\" 4 hours ago  Exited (0) 5 seconds ago  gray_cat\\n~~~\\n\\n如果想为容器指定一个名称，而不是使用自动生成的名称，则可以用--name标志来实现\\n\\n~~~shell\\n$ docker container rm gray_cat\\n$ docker run --name linux -i -t ubuntu:18.04 /bin/bash\\nroot@d823d5acadcc: exit\\n$ docker container ls -a\\nCONTAINER ID   IMAGE          COMMAND    CREATED      STATUS       PORTS        NAMES\\nd823d5acadcc  ubuntu:18.04  \\\"/bin/bash\\\" 4 hours ago  Exited (0) 5 seconds ago    linux\\n~~~\\n\\n### 3. 定位容器\\n\\n有三种方法可以唯一指代容器：\\n\\n+ 短UUID，如：d823d5acadcc\\n+ 长UUID\\n+ 名称\\n\\n**容器的命名必须是唯一的**\\n\\n### 4. 重新启动已经启动的容器\\n\\n启动使用：docker start name\\n\\n附着：docker attach name\\n\\n~~~shell\\n# 重新启动\\n$ docker start linux\\n# linux运行在后台\\n$ docker ps\\nCONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES\\nd823d5acadcc        ubuntu:18.04        \\\"/bin/bash\\\"         4 hours ago         Up 4 seconds                            linux\\n# 进入容器内\\n$ docker exec -it linux /bin/bash\\nroot@d823d5acadcc:/#\\n~~~\\n\\n如果推出容器的shell，容器会再次停止运行\\n\\n### 5. 创建守护式容器\\n\\n~~~shell\\n$ docker run --name daemon_linux -d ubuntu:18.04 /bin/sh -c \\\"while true; do echo hello world; sleep 1; done\\\"\\n5ddff43da9675fe673a010c0df380418cf586b1836711383b38b2c5d5f6fbeb9 # 返回了容器的id\\n$ docker ps\\n~~~\\n\\n使用参数 `-d`，因此Docker会将容器放到后台运行\\n\\n### 6. 查看容器内部在干什么\\n\\n~~~shell\\n# 获取容器日志\\n$ docker logs daemon_linux\\n# -f参数 监控容器日志\\n$ docker logs -f daemon_linux\\t# ctrl+c退出\\n# -t参数 加上时间戳\\n$ docker logs -t -f daemon_linux\\n~~~\\n\\n### 7. 日志驱动\\n\\n`--log-driver=“syslog”`\\n\\n+\\tjson-file，为docker logs命令提供了基础\\n+\\tsyslog，该命令将禁用docker logs命令，并且将所有容器的日志输出都重定向到Syslog\\n  +\\t可以在启动Docker守护进程时指定该选项，将所有容器的日志都输出重定向到Syslog\\n  +\\t或者通过docker run对个别的容器进行日志重定向\\n+\\tnone，会禁用所有容器中的日志，docker logs也禁用\\n\\n### 8. 查看容器内的进程\\n\\n使用docker top命令\\n\\n`docker top name`\\n\\n### 9. 停止守护式进程\\n\\n~~~shell\\n$ docker stop name\\n# 如果想快速停止某个容器，可以使用kill\\n$ docker kill name\\n~~~\\n\\n查看容器\\n\\n~~~shell\\ndocker ps -n x\\t# 会显示最后x个容器，不论这个容器正在运行还是已经停止\\n~~~\\n\\n### 10. 自动重启容器\\n\\n如果由于某种错误而导致容器停止运行，还可以通过--restart 标志，让Docker自动重新启动该容器。--restart会检查容器的退出代码，并据此来决定是否要重启容器，默认是Docker不会重启容器\\n\\n如果想要重启，有两种参数：\\n\\n+ always：无论退出代码是什么，都会重启该容器\\n\\n+ unless-stopped：在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器\\n\\n+ on-failure：只有当容器的退出代码为非0值的时候，才会自动重启\\n\\n  on-failure还接收一个可选的重启次数参数\\n  \\n  ~~~shell\\n  $ docker run --restart=always --name daemon_linux -d ubuntu:18.04 /bin/bash\\n  $ docker run --restart=on-failure:5 --name daemon_linux -d ubuntu:18.04 /bin/bash\\n  ~~~\\n\\n其他：\\n\\n~~~shell\\n# 查看容器重启次数\\n$ docker inspect -f \\\"{{ .RestartCount }}\\\" containerName\\n# 查看容器最后一次的启动时间\\n$ docker inspect -f \\\"{{ .State.StartedAt }}\\\" containerName\\n~~~\\n\\n### 11. 深入容器\\n\\n查看容器详细信息：\\n\\n~~~shell\\n$ docker inspect name\\n~~~\\n\\n\",\"category\":\"Docker\",\"createTime\":\"2021/04/02 11:25:00\"},{\"id\":\"1633509976300\",\"name\":\"Docker常用服务安装\",\"title\":\"Docker常用服务安装\",\"content\":\"\\n\\n安装docker: [Ubuntu安装docker](https://blog.mittacy.com/article/47)\\n\\n### 1. 安装mysql\\n\\n~~~shell\\n# 下载mysql镜像\\n$ docker pull mysql\\n# 查看下载情况\\n$ docker images\\n# 运行mysql容器\\n$ docker run --name mysql -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=password mysql\\n~~~\\n\\n参数说明：\\n\\n+ `--name` 容器的名字\\n+ `-d`：后台运行容器\\n+ `-e`：设置参数\\n+ `-p 3306:3306`  映射容器服务的 3306 端口到宿主机的 3306 端口，外部主机可以直接通过 **宿主机ip:3306** 访问到 MySQL 的服务\\n+ `MYSQL_ROOT_PASSWORD` mysql服务root用户的密码\\n\\n~~~shell\\n# 查看 mysql 运行情况\\n$ docker ps\\n# 使用宿主登录mysql\\n$ mysql -h 127.0.0.1 -u root -p\\n# 进入容器\\n$ docker exec -it mysql /bin/bash\\n~~~\\n\\n**挂载数据**\\n\\n如果没有其他操作，这样的mysql数据库，每次终止运行后将丢失数据，非常糟糕，需要用到挂载数据：将宿主的一个位置挂载到容器内，对数据卷的修改会立马生效\\n\\n~~~shell\\n# 删除原来的容器\\n# 创建宿主目录\\n$ sudo mkdir -p ~/data/mysql/conf\\n$ sudo mkdir -p ~/data/mysql/data\\n# 创建my.cnf配置文件\\n$ cd ~/data/mysql/conf\\n$ sudo vim my.cnf\\n~~~\\n\\n`my.cnf`内容如下\\n\\n~~~shell\\n[mysqld]\\nuser=mysql\\ncharacter-set-server=utf8\\n[client]\\ndefault-character-set=utf8\\n[mysql]\\ndefault-character-set=utf8\\n~~~\\n\\n重新新建容器：\\n\\n~~~shell\\n$ docker run --name=mysql -d -p 3306:3306 -v ~/data/mysql/conf:/etc/mysql/conf.d -v ~/data/mysql/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=password mysql\\n~~~\\n\\n其中：\\n\\n+ `-v ~/data/docker-mysql/conf/my.cnf:/etc/mysql/my.cnf`\\n\\n  将本地`~/data/docker-mysql/conf/my.cnf`挂载到容器`/etc/mysql/my.cnf`，也就是访问`/etc/mysql/my.cnf`的时候其实访问的是`~/data/docker-mysql/conf/my.cnf`\\n\\n+ `-v ~/data/docker-mysql/data:/var/lib/mysql` 同上一样的意思\\n\\n注意：如果出现mysql无法启动mysql或者启动闪退的情况，可以看看是不是没开启swap\\n\\n~~~shell\\n$ free\\n~~~\\n\\n如果发现swap虚拟内存都是0，应该就是swap未启用，启用swap：\\n\\n~~~shell\\n$ dd if=/dev/zero of=/swapfile bs=1M count=1024\\n$ mkswap /swapfile\\n$ swapon /swapfile\\n$ free\\n$ docker start mysql\\n~~~\\n\\n### 2. 安装redis\\n\\n创建redis宿主目录\\n\\n```shell\\n$ mkdir -p ~/data/redis/conf\\n```\\n\\n创建cnf文件\\n\\n```shell\\n$ cd ~/data/redis/conf\\n$ touch redis.conf\\n```\\n\\n启动容器\\n\\n~~~shell\\n$ docker pull redis\\n$ docker run -d --name redis -p 6379:6379 -v ~/data/redis/conf:/usr/local/etc/redis redis redis-server --appendonly yes --requirepass \\\"mypassword\\\"\\n$ redis-cli\\n~~~\\n\\n- `--appendonly`：启用数据持久化保存\\n- `redis-server --appendonly yes`：在容器执行redis-server启动命令，并且启动redis持久化配置\\n- `/data/redis/conf` 需要有配置文件conf\\n- `--requirepass` 密码\\n\\n查看执行情况\\n\\n~~~shell\\n$ docker ps\\n~~~\\n\\n\",\"category\":\"Docker\",\"createTime\":\"2021/04/01 10:25:00\"},{\"id\":\"1633509976301\",\"name\":\"我的博客部署过程(Docker部署)\",\"title\":\"Docker 博客后端部署过程\",\"content\":\"\\n### 1. Docker容器选择\\n\\n#### 1.1 使用golang容器\\n\\n项目使用Go编写的api后台服务，Vue编写了前端编译成静态文件\\n\\n首先Go先用交叉编译出可执行文件\\n\\n~~~shell\\n$ GOOS=linux GOARCH=amd64 go build -o blog main.go\\n~~~\\n\\n生成blog可执行文件，和Vue编译后的文件放一起，结构如下\\n\\n![](https://static.mittacy.com/blog/20200426004218.png)\\n\\n编写Dockerfile文件内容如下\\n\\n~~~dockerfile\\nFROM golang\\nMAINTAINER mittacyChen \\\"mail@mittacy.com\\\"\\n\\nWORKDIR $GOPATH/src/blog-gin\\n\\nCOPY . $GOPATH/src/blog-gin\\n\\nEXPOSE 3824\\n\\nENTRYPOINT [\\\"./blog\\\"]\\n~~~\\n\\n+ `FROM golang` \\n+ `MAINTAINER ...` 标明作者和邮箱\\n+ `WORDKDIR` 在容器内部工作位置\\n+ `COPY . $GOPATH/src/blog-gin` 将当前目录所有文件复制到容器$GOPATH/src/blog-gin\\n+ `EXPOSE 3824` 暴露容器的3824端口(因为我的项目监听了3824端口)\\n+ `ENTRYPOINT [\\\"./blog\\\"]` 建立容器的时候运行的命令\\n\\n~~~shell\\n$ docker build -t mittacy/blog .\\n# 查看所有images\\n$ docker images\\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\\nmittacy/blog        latest              4b79e2595b7e        1 hours ago         828MB\\nredis               latest              f0453552d7f2        6 weeks ago         98.2MB\\nmysql               latest              9b51d9275906        7 weeks ago         547MB\\n# 查看已运行的容器\\n$ docker ps\\ndocker ps\\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                               NAMES\\nb1f9d26dc011        mysql               \\\"docker-entrypoint.s…\\\"   22 minutes ago      Up 22 minutes       0.0.0.0:3306->3306/tcp, 33060/tcp   mysql\\nfabfe12c2b29        redis               \\\"docker-entrypoint.s…\\\"   8 hours ago         Up About an hour    0.0.0.0:6379->6379/tcp              redis\\n~~~\\n\\n建立项目容器并运行在后台：\\n\\n~~~shell\\n$ docker run --name blog -d -p 3824:3824 mittacy/blog\\nd3324c27e0e244d5e2732c800407f8799b03152021e5ec653568d3bbe68aad80\\n$ docker ps\\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                               NAMES\\nd3324c27e0e2        mittacy/blog      \\\"./blog\\\"                 12 minutes ago      Up 12 minutes       0.0.0.0:3824->3824/tcp              blog\\nb1f9d26dc011        mysql               \\\"docker-entrypoint.s…\\\"   22 minutes ago      Up 22 minutes       0.0.0.0:3306->3306/tcp, 33060/tcp   mysql\\nfabfe12c2b29        redis               \\\"docker-entrypoint.s…\\\"   8 hours ago         Up About an hour    0.0.0.0:6379->6379/tcp              redis\\n~~~\\n\\n打开浏览器访问` 0.0.0.0:3824`\\n\\n成功访问，如果`docker ps`发现项目不在运行，说明出错，可以使用`docker logs blog`查看错误提示\\n\\n#### 1.2 使用scratch容器\\n\\n~~~shell\\n$ docker images\\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\\nmittacy/blog        latest              4b79e2595b7e        7 hours ago         828MB\\n~~~\\n\\n可以看到image很大，其实，我们是在本地交叉编译出了blog可执行文件，完全不需要golang的环境，只需要go可执行文件的环境，所以可以使用scratch\\n\\n修改Dockerfile文件为\\n\\n~~~dockerfile\\nFROM scratch\\nMAINTAINER mittacyChen \\\"mail@mittacy.com\\\"\\n\\nCOPY . .\\n\\nEXPOSE 3824\\n\\nENTRYPOINT [\\\"./blog\\\"]\\n~~~\\n\\n建立镜像、容器并运行\\n\\n~~~shell\\n$ docker build -t mittacy/blog:2 .\\n$ docker run --name blog -d -p 3824:3824 mittacy/blog:2\\n20fd62fd6fe765b56a6f5e375bde94042d1c79f1c77c40b738cd87532b4fbbe4\\n$ docker ps\\ndocker ps\\nCONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS                               NAMES\\n20fd62fd6fe7        mittacy/blog:2      \\\"./blog\\\"                 About a minute ago   Up 10 seconds       0.0.0.0:3824->3824/tcp              blog\\n~~~\\n\\n同样打开浏览器运行`0.0.0.0:3824`\\n\\n查看两个image大小差别\\n\\n~~~shell\\n$ docker images\\ndocker images\\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\\nmittacy/blog        2                   61898d44156a        5 minutes ago       18.6MB\\nmittacy/blog        latest              4b79e2595b7e        8 hours ago         828MB\\n~~~\\n\\n### 2. 自动构建\\n\\nimage构建好了，我们需要在服务端或者这个image，就需要上传到Docker Hub上，可以使用直接上传，也可以通过Github获取自动构建，我使用的是Github自动构建\\n\\n将项目添加到github中作为单独的仓库，也就是这个文件夹\\n\\n![](https://static.mittacy.com/blog/20200426004218.png)\\n\\nDocker hub链接github账户，添加该仓库，构建images，以后每次修改github仓库，Docker hub都会自动重新构建该image\\n\\n至此，所有安装了Docker服务的环境都能获取该image项目\\n\\n~~~shell\\n$ docker pull mittacy/blog\\n~~~\\n\\n### 3. 链接数据库\\n\\n我的博客使用到了mysql、redis，所以需要提前部署好数据库\\n\\n#### 3.1 使用Docker安装数据库容器\\n\\n[Docker安装mysql&redis](https://blog.mittacy.com/article/53)\\n\\n如果使用这种建容器方式，会出现一个问题：项目内部连接数据库的时候无法使用127.0.0.1连接数据库\\n\\n**docker是一个虚拟环境,127.0.0.1和localhost指的是虚拟环境内部,而不是外部宿主机,所以如果写127.0.0.1是无法访问的**\\n\\n解决上述问题\\n\\n+ 对于mac和windows,可以使用host.docker.internal替换127.0.0.1,如 mongodb://host.docker.internal:27017\\n\\n+ 对于Linux可以采用如下方案(后续应该也可以用上面的方案,但是当前docker还没有修改此问题):\\n\\n  创建一个桥接网络\\n\\n  ~~~shell\\n  # localNet是网络名字,可自行修改; 192.168.0.0这个子网,也可以自行定义\\n  # 默认按照上面的命令,执行后将可以通过192.168.0.1访问宿主机\\n  $ docker network create -d bridge --subnet 192.168.0.0/24 --gateway 192.168.0.1 localNet\\n  # 使用192.168.0.1替换127.0.0.1,如192.168.0.1:3306\\n  # 运行blog项目image, 3824是项目监听端口\\n  $ docker run --name blog --link mysql:mysql --link redis:redis -d -p 3824:3824 mittacy/blog\\n  ~~~\\n\\n#### 3.2 直接安装数据库到部署系统\\n\\n这种情况需要使用docker host网络模式，该模式将禁用docker容器的网络隔离\\n\\n建容器时加入`--net=host`即可\\n\\n~~~shell\\n$ docker run --name blog --net=host -d mittacy/blog\\n~~~\\n\\n### 4. 奔溃自动重启\\n\\n如果由于某种错误而导致容器停止运行，还可以通过--restart 标志，让Docker自动重新启动该容器。--restart会检查容器的退出代码，并据此来决定是否要重启容器，默认是Docker不会重启容器\\n\\n如果想要重启，有以下参数：\\n\\n- always：无论退出代码是什么，都会重启该容器\\n\\n- unless-stopped：在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器\\n\\n- on-failure：只有当容器的退出代码为非0值的时候，才会自动重启\\n\\n  on-failure还接收一个可选的重启次数参数\\n\\n~~~shell\\n$ docker run --name blog --restart=on-failure --net=host -d mittacy/blog\\n~~~\\n\\n### 5. Nginx监听转发\\n\\n在`/etc/nginx/conf.d/`下新建一个文件夹名为：网址.conf,\\n\\n比如我的博客: `/etc/nginx/conf.d/blog.mittacy.com.conf`\\n\\n+ 项目运行端口为5201\\n\\nblog.mittacy.com.conf 配置文件如下：\\n\\n~~~nginx\\nserver {\\n  server_name blog.mittacy.com;\\n  listen 80;\\t\\t# 监听80端口\\n\\n  location / {\\n    proxy_pass http://localhost:3824;\\n    proxy_set_header Host $host:3824;\\n    proxy_set_header X-Real-IP $remote_addr;\\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n  }\\n}\\n~~~\\n\\n### 6. 使用https & http2\\n\\n#### 6.1 安装Let’s Encrypt\\n\\n~~~shell\\n# 安装\\n$ sudo apt-get update\\n$ sudo apt-get install software-properties-common\\n$ sudo add-apt-repository -y ppa:certbot/certbot\\n$ sudo apt-get update\\n$ sudo apt-get install python-certbot-apache\\n$ sudo apt-get install letsencrypt\\n# 生成证书\\n$ letsencrypt certonly --agree-tos --email mail@mittacy.com -d blog.mittacy.com\\n# 检查/etc/letsencrypt/live/www.xxxxx.com\\n$ cd /etc/letsencrypt/live/blog.mittacy.com\\n$ ls\\ncert.pem  chain.pem  fullchain.pem  privkey.pem  README\\n~~~\\n\\n修改Nginx配置\\n\\n~~~shell\\n$ cd /etc/nginx/conf.d/\\n$ vim blog.mittacy.com.conf\\n## 内容如下\\nserver {\\n  server_name blog.mittacy.com;\\n  listen 443 ssl http2;\\n  ssl_certificate /etc/letsencrypt/live/blog.mittacy.com/fullchain.pem;\\n  ssl_certificate_key /etc/letsencrypt/live/blog.mittacy.com/privkey.pem;\\n  ssl_session_timeout 1d;\\n  ssl_session_cache shared:SSL:50m;\\n  ssl_session_tickets off;\\n\\n  location / {\\n    proxy_pass http://localhost:3824;\\n    proxy_set_header Host $host:3824;\\n    proxy_set_header X-Real-IP $remote_addr;\\n    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\\n  }\\n}\\nserver {\\n    listen 80;\\n    server_name mittacy.com blog.mittacy.com;\\n    return 301 https://$host$request_uri;\\n}\\n~~~\\n\\n其中，以下部分是为了让http重定向到https\\n\\n~~~nginx\\nserver {\\n    listen 80;\\n    server_name mittacy.com blog.mittacy.com;\\n    return 301 https://$host$request_uri;\\n}\\n~~~\\n\\n\\n\\n\\n\\n\",\"category\":\"Docker\",\"createTime\":\"2021/04/02 18:25:00\"},{\"id\":\"1630742750946\",\"name\":\"ES搜索基础\",\"title\":\"ES基础\",\"content\":\"\\n\\n## 一、安装\\n\\n[使用Docker搭建ELK环境](https://juejin.cn/post/6844904147557285895#heading-1)\\n\\n```shell\\n# 下载\\n$ git clone https://github.com/deviantony/docker-elk.git \\n\\n# 启动，过一会儿再访问，启动较慢\\n$ docker-compose up -d\\n\\n# 重建内建用户密码，将输出的密码全部保存一下\\n$ docker-compose exec -T elasticsearch bin/elasticsearch-setup-passwords auto --batch\\nChanged password for user apm_system\\nPASSWORD apm_system = YkELBJGOT6AxqsPqsi7I\\n\\nChanged password for user kibana\\nPASSWORD kibana = FxRwjm5KRYvHhGEnYTM9\\n\\nChanged password for user logstash_system\\nPASSWORD logstash_system = A4f5VOfjVWSdi0KAZWGu\\n\\nChanged password for user beats_system\\nPASSWORD beats_system = QnW8xxhnn7LMlA7vuI7B\\n\\nChanged password for user remote_monitoring_user\\nPASSWORD remote_monitoring_user = OvjEGR13wjkOkIbWqaEM\\n\\nChanged password for user elastic\\nPASSWORD elastic = PGevNMuv7PhVnaYg7vJw\\n```\\n\\n1. 将 `docker-compose.yml>ELASTIC_PASSWORD` 置位空\\n2. 将配置文件内的**elastic** 密码修改为新的密码\\n    + kibana/config/kibana.yml\\n    + logstash/config/logstash.yml\\n    + logstash/pipeline/logstash.conf\\n3. 向 `kibana/config/kibana.yml`  中添加 `i18n.locale: \\\"zh-CN\\\"` 设置中文\\n\\n```shell\\n# 重启\\n$ docker-compose restart\\n```\\n\\n访问kibana：localhost:5601\\n\\n使用 elastic 和 PGevNMuv7PhVnaYg7vJw 登录\\n\\n最后，可以在 kibana 中关闭付费\\n\\n## 二、工具使用\\n\\n### 1. logstash\\n\\n**1.安装**\\n\\n下载ElasticSearch对应版本的logstash后解压\\n\\nhttps://www.elastic.co/cn/downloads/logstash\\n\\n**2.使用**\\n\\n```shell\\n$ cd $logstash_path\\n$ ./bin/logstash -f 配置文件\\n```\\n\\n其中，配置文件需要指向`csv数据文件`以及`csv数据文件的格式`\\n\\n### 2. 安装分词器\\n\\n以安装ik分词器为例\\n\\n```shell\\n# 进入容器\\n$ docker exec -it es容器id /bin/bash\\n\\n# 安装wget\\n$ yum -i install wget\\n\\n# 下载ik，记得替换对应的版本号\\n$ mdkir ik\\n$ cd ik\\n$ wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.12.1/elasticsearch-analysis-ik-7.12.1.zip\\n$ unzip elasticsearch-analysis-ik-7.12.1.zip\\n\\n# 重启服务\\n$ docker restart es容器id\\n```\\n\\n## 三、基础知识\\n\\n| MySQL         | ES            |\\n| ------------- | ------------- |\\n| Table 表      | Index 索引    |\\n| Row 行记录    | Document 记录 |\\n| Column 列     | Field         |\\n| Schema 表定义 | Mapping       |\\n| SQL           | DSL           |\\n\\n### 1. 索引\\n\\n+ 名词\\n\\n    一个 ES 中，可以创建多个不同的索引，类似 Mysql 表\\n\\n+ 动词\\n\\n    保存一个文档到 ES 的过程也叫索引\\n\\n### 2. 文档\\n\\n#### 2.1 概念\\n\\n类似 Mysql 表中的记录，ES是面向文档的，文档是所有可搜索数据的最小单位；\\n\\n文档会被序列化成 JSON 格式保存在 ES 中，每个字段都有对应的字符类型（字符串、数值、布尔、日期、二进制、范围类型）\\n\\n#### 2.2 元数据\\n\\n用于标注文档的相关信息\\n\\n```json\\n{\\n    \\\"_index\\\": \\\"movies\\\",\\n    \\\"_type\\\": \\\"_doc\\\",\\n    \\\"_id\\\": \\\"1\\\",\\n    \\\"_score\\\": 14.23223,\\n    \\\"_source\\\": {\\n        \\\"title\\\": \\\"Toy Story\\\",\\n        \\\"year\\\": 1995,\\n    }\\n}\\n```\\n\\n+ `_index`  - 文档所属的索引名\\n+ `_type`  - 文档所属的类型名\\n+ `_id`  - 文档唯一ID，可以自己指定，一般通过 ES 自动生成\\n+ `_source`  - 文档的原始 JSON 数据\\n+ `_version`  - 文档的版本信息\\n+ `_score`  - 相关性打分\\n+ `_all`  - 整合所有字段内容，已被废除\\n\\n### 3. 倒排索引\\n\\n倒排索引包含两个部分：\\n\\n+ 单词词典\\n\\n    记录所有文档的单词，记录 **单词** 到 **倒排列表** 的关联关系\\n\\n    > 单词词典一般比较大，可以通过 B+树 或 哈希拉链法 实现，加快插入与查询\\n\\n+ 倒排列表\\n\\n    记录了单词对应的文档结合，包含以下内容\\n\\n    + 文档 ID\\n    + 词频 TF - 该单词在文档中出现的次数，用于相关性评分\\n    + 位置(Position) - 单词在文档中分词的位置，用于语句搜索\\n    + 偏移(Offset) - 记录单词的开始、结束位置，实现高亮显示\\n\\n**例子：**\\n\\n| 文档ID | 文档内容                 |\\n| ------ | ------------------------ |\\n| 1      | Mastering Elasticsearch  |\\n| 2      | Elasticsearch Server     |\\n| 3      | Elasticsearch Essentials |\\n\\n上面的文档会有如下的关于 **Elastcisearch** 的倒排列表：\\n\\n| Doc Id | TF   | Position | Offset  |\\n| ------ | ---- | -------- | ------- |\\n| 1      | 1    | 1        | <10,23> |\\n| 2      | 1    | 0        | <0,13>  |\\n| 3      | 1    | 0        | <0,13>  |\\n\\n### 4. 分词\\n\\n+ Analysis：分词，把全文本转换为一系列单词的过程\\n\\n+ Analyzer：分析器，按一定规则进行分词\\n\\n    > 除了在数据写入时使用分析器进行分词，在匹配 Query 语句时也需要用相同的分析器对查询语句进行分析\\n\\n#### 4.1 分析器\\n\\n1. Character Filters：原始文本处理，例如去除html\\n2. Tokenizer：按照规则切分为单词\\n3. Token Filters：将切分的单词进行加工，比如转化为小写等\\n\\n#### 4.2 ES自带分词器\\n\\n+ Standard：默认分词器，按词切分，小写处理\\n+ Simple：按照非字母切分（符号被过滤），小写处理\\n+ Stop：小写处理，停用词过滤（the、a、is）\\n+ Whitespace：安装空格切分，不转小写\\n+ Keyword：不分词，直接将输入当做输出\\n+ Patter：正则表达式，默认 `\\\\W+` （非字符分割）\\n+ Language：提供了30多种常见语言的分词器\\n+ Customer：自定义分词器\\n    + icu_analyzer 中文分词器\\n    + ik，支持自定义词库，支持热更新分词字典\\n    + THULAC，清华大学自然语言处理和社会人文计算机实验室的一套中文分词\\n\\n#### 4.3 分词测试接口\\n\\n如果想要查看一个文本被某个分词器处理的效果，可以使用 `_analyze` 接口\\n\\n```json\\nGET /_analyze\\n{\\n  \\\"analyzer\\\": \\\"standard\\\",\\n  \\\"text\\\": \\\"My name is MingtaoChen\\\"\\n}\\n# 结果如下\\n{\\n  \\\"tokens\\\" : [\\n    {\\n      \\\"token\\\" : \\\"my\\\",\\n      \\\"start_offset\\\" : 0,\\n      \\\"end_offset\\\" : 2,\\n      \\\"type\\\" : \\\"<ALPHANUM>\\\",\\n      \\\"position\\\" : 0\\n    },\\n    {\\n      \\\"token\\\" : \\\"name\\\",\\n      \\\"start_offset\\\" : 3,\\n      \\\"end_offset\\\" : 7,\\n      \\\"type\\\" : \\\"<ALPHANUM>\\\",\\n      \\\"position\\\" : 1\\n    },\\n    {\\n      \\\"token\\\" : \\\"is\\\",\\n      \\\"start_offset\\\" : 8,\\n      \\\"end_offset\\\" : 10,\\n      \\\"type\\\" : \\\"<ALPHANUM>\\\",\\n      \\\"position\\\" : 2\\n    },\\n    {\\n      \\\"token\\\" : \\\"mingtaochen\\\",\\n      \\\"start_offset\\\" : 11,\\n      \\\"end_offset\\\" : 22,\\n      \\\"type\\\" : \\\"<ALPHANUM>\\\",\\n      \\\"position\\\" : 3\\n    }\\n  ]\\n}\\n```\\n\\n可以使用自定义分析器\\n\\n```shell\\n$ GET /_analyze\\n{\\n  \\\"tokenizer\\\": \\\"standard\\\",\\n  \\\"filter\\\": [\\\"lowercase\\\"],\\n  \\\"text\\\": \\\"My name is MingtaoChen\\\"\\n}\\n```\\n\\n也可以使用指定索引字段的分析器进行测试\\n\\n```shell\\n$ GET user/_analyze\\n{\\n  \\\"field\\\": \\\"name\\\",\\n  \\\"text\\\": \\\"My name is MingtaoChen\\\"\\n}\\n```\\n\\n### 5. Mapping\\n\\nMapping是对索引的结构定义，类似 Mysql 表结构定义\\n\\n查看某个索引的Mapping\\n\\n`GET user/_mapping`\\n\\n#### 5.1 字段数据类型\\n\\n+ 简单类型\\n    + Text / Keyword\\n    + Date\\n    + Integer / Floating\\n    + Boolean\\n    + IPv4 & IPv6\\n+ 复杂类型 - 对象和嵌套对象\\n    + 对象类型 / 嵌套类型\\n+ 特殊类型\\n    + geo_point & geo_shape / percolator\\n\\n#### 5.2 Dynamic Mapping\\n\\n在写入文档时，如果索引不存在会自动创建索引并定义Mapping，ES 会自动根据文档信息，推算出字段的类型，但是有时候会推算错误，例如地理位置信息等\\n\\n**配置Dynamic**\\n\\n```shell\\nPUT user\\n{\\n\\t\\\"mappings\\\": {\\n\\t\\t\\\"_doc\\\": {\\n\\t\\t\\t\\\"dynamic\\\": \\\"false\\\"\\n\\t\\t}\\n\\t}\\n}\\n```\\n\\n**dynamic不同设置，插入新文档有新增的字段时影响如下：**\\n\\n|               | true | false | strict |\\n| ------------- | ---- | ----- | ------ |\\n| 文档可索引    | y    | y     | n      |\\n| 字段可索引    | y    | n     | n      |\\n| Mapping被更新 | y    | n     | n      |\\n\\n+ false 情况下，Mapping不会更新，但是数据插入成功\\n+ strict 情况下，直接报错\\n\\n> **使用动态mapping的隐患**\\n>\\n> + 设置成strict，万一有一条数据里带着不存在的字段，写入就会失败\\n> + 设置成true，数据可以写入，还会在mapping中增加那个字段的设置。随着时间的流逝，这类数据会导致mapping设定的膨胀\\n\\n#### 5.3 定义Mapping\\n\\n为减少输入的工作量和出错概率，可以依照一下步骤：\\n\\n1. 使用一些样本数据创建一个临时的 index\\n\\n    ```json\\n    POST /user_demo/_doc\\n    {\\n      \\\"app_id\\\": \\\"appsldfms\\\",\\n      \\\"community_id\\\": \\\"c_5basf9e685_aksdfmlsmf32e\\\",\\n      \\\"user_id\\\": \\\"u_5basdfdsf_asd9wDz3e8\\\",\\n      \\\"nick_name\\\": \\\"不会扎头的小丸子\\\",\\n      \\\"wx_avatar\\\": \\\"https://www.baidu.com\\\",\\n      \\\"wx_unionid\\\": \\\"aosdjf\\\",\\n      \\\"state\\\": 0,\\n      \\\"type\\\": 1,\\n      \\\"is_quit\\\": 0,\\n      \\\"created_at\\\": \\\"2018-10-11 09:27:11\\\",\\n      \\\"updated_at\\\": \\\"2021-06-05 06:03:56\\\",\\n      \\\"need_notify\\\": 1,\\n      \\\"subscribe_from\\\": 1\\n    }\\n    ```\\n\\n2. 获取该 index 的动态 Mapping 定义\\n\\n    ```json\\n    GET /user_demo/_mapping\\n    ```\\n\\n3. 根据需求对该 Mapping 进行修改，使用新的 Mapping 配置创建索引\\n\\n    ```json\\n    PUT /user\\n    {\\n      \\\"mappings\\\": {\\n        \\\"properties\\\" : {\\n          \\\"app_id\\\" : {\\n            \\\"type\\\" : \\\"text\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"community_id\\\" : {\\n            \\\"type\\\" : \\\"text\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"created_at\\\" : {\\n            \\\"type\\\" : \\\"date\\\",\\n            \\\"format\\\": \\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"is_quit\\\" : {\\n            \\\"type\\\" : \\\"long\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"need_notify\\\" : {\\n            \\\"type\\\" : \\\"long\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"nick_name\\\" : {\\n            \\\"type\\\" : \\\"text\\\",\\n            \\\"index_options\\\": \\\"offsets\\\",\\n            \\\"fields\\\" : {\\n              \\\"keyword\\\" : {\\n                \\\"type\\\" : \\\"keyword\\\",\\n                \\\"ignore_above\\\" : 256\\n              }\\n            }\\n          },\\n          \\\"state\\\" : {\\n            \\\"type\\\" : \\\"long\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"subscribe_from\\\" : {\\n            \\\"type\\\" : \\\"long\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"type\\\" : {\\n            \\\"type\\\" : \\\"long\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"updated_at\\\" : {\\n            \\\"type\\\" : \\\"date\\\",\\n            \\\"format\\\": \\\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"user_id\\\" : {\\n            \\\"type\\\" : \\\"text\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"wx_avatar\\\" : {\\n            \\\"type\\\" : \\\"text\\\",\\n            \\\"index\\\": false\\n          },\\n          \\\"wx_unionid\\\" : {\\n            \\\"type\\\" : \\\"text\\\",\\n            \\\"index\\\": false\\n          }\\n        }\\n      }\\n    }\\n    ```\\n\\n4. 删除临时索引\\n\\n    ```shell\\n    DELETE /user_demo\\n    ```\\n\\n> + index：控制字段是否被索引\\n>\\n> + index_options：控制倒排索引记录的内容\\n>\\n>     + docs：记录 doc id\\n>     + freqs：记录 doc id 和 term frequencies\\n>     + position：记录 doc id、term frequencies、term position\\n>     + offsets：doc id、term frequencies、term position、character offects\\n>\\n>\\n> text类型默认记录 positions，其他默认为 docs，记录内容越多，占用存储空间越大\\n\\n## 四、集群\\n\\n### 1. 节点\\n\\n+ 节点是一个 ES 实例，本质上就是一个Java进程，一台机器可以运行多个 ES 实例，但是生产环境一般建议一台机器值运行一个 ES 实例\\n+ 每个节点都有名字，通过配置文件配置，或者启动时 `-E node.name=nodeName` 指定\\n+ 每个节点启动之后，会分配一个 UID，保存在 data 目录下\\n\\n#### 1.1 Master-eligible Node\\n\\n> Master node  主节点，可以有多个 Master 节点，但是只能有一个active\\n>\\n> Master-eligible nodes  可以参加选主流程成为 Master 的节点\\n\\n+ **第一个启动**的节点会将自己选举成 Master 节点，其他节点启动后默认就是 Master eligible 节点，可以设置 `node.master: false` 禁止，禁止的节点将不会参加选主流程\\n+ 每个节点上都保存了集群的状态，**只有 Master 节点才能修改集群的状态信息**\\n+ 集群信息（Cluster State）维护了一个集群中必要的信息：\\n    + 所有的节点信息\\n    + 所有的索引和其相关的 Mapping 与 Setting 信息\\n    + 分片的路由信息\\n\\n#### 1.2 Data Node\\n\\n可以保存数据的节点，叫做 Data Node。负责保存分片数据，在数据扩展上起到了至关重要的作用\\n\\n#### 1.3 Coordinating Node\\n\\n+ 负责接收 Client 的请求，将请求分发到合适的节点，最终把结果汇集到一起\\n+ 每个节点默认都起到了 Coordinating Node 的职责\\n\\n#### 1.4 Hot & Warm Node\\n\\n不同硬件配置的 Data Node，用来实现 Hot & Warm 架构，降低集群部署的成本\\n\\n#### 1.5 Machine Learning Node\\n\\n负责跑机器学习的任务，用来做异常检测\\n\\n#### 总结\\n\\n开发环境中一个可以承担多种角色，但生产环境中，应该设置节点单一的角色\\n\\n节点相关配置参数如下：\\n\\n| 节点类型          | 配置参数    | 默认值                                  |\\n| ----------------- | ----------- | --------------------------------------- |\\n| Master-eligible   | node.master | true                                    |\\n| data              | node.data   | true                                    |\\n| ingest            | node.ingest | true                                    |\\n| coordinating only | 无          | 每个节点默认都是(设置其他类型都为false) |\\n| macheine learning | node.ml     | true(需enable x-pack)                   |\\n\\n### 2. 分片\\n\\n+ 主分片（Primary Shard）\\n\\n    主分片可以将数据分布到集群内的所有节点上，一个分片是一个运行的 Lucene 实例，解决数据水平扩展的问题。**主分片数量在索引创建时指定，后续不允许修改，除非重建索引。**\\n\\n+ 副本（Replica Shard）\\n\\n    是主分片的拷贝，数量可以动态地调整，增加副本数在一定程度上提高服务的可用性、读取的吞吐\\n\\n#### 分片数设置\\n\\n+ 设置数量过少\\n    + 可能导致后续增加节点后分片少于节点数，将无法实现水平扩展\\n    + 单个分片的数据量太大，导致数据重新分配耗时\\n+ 设置数量过多\\n    + 单个节点过多的分片，会导致资源浪费，同时影响性能\\n    + 影响搜索结果的相关性打分，影响统计结果的准确性\\n\\n**从7.0开始，默认主分片数为1**\\n\\n### 3. 获取集群健康状态\\n\\n```json\\nGET _cluster/health\\n{\\n  \\\"cluster_name\\\" : \\\"docker-cluster\\\",\\n  \\\"status\\\" : \\\"yellow\\\",\\n  \\\"timed_out\\\" : false,\\n  \\\"number_of_nodes\\\" : 1,\\n  \\\"number_of_data_nodes\\\" : 1,\\n  \\\"active_primary_shards\\\" : 27,\\n  \\\"active_shards\\\" : 27,\\n  \\\"relocating_shards\\\" : 0,\\n  \\\"initializing_shards\\\" : 0,\\n  \\\"unassigned_shards\\\" : 2,\\n  \\\"delayed_unassigned_shards\\\" : 0,\\n  \\\"number_of_pending_tasks\\\" : 0,\\n  \\\"number_of_in_flight_fetch\\\" : 0,\\n  \\\"task_max_waiting_in_queue_millis\\\" : 0,\\n  \\\"active_shards_percent_as_number\\\" : 93.10344827586206\\n}\\n```\\n\\n+ status\\n    + green 主分片与副本都正常分配\\n    + yellow 主分片正常分配，有副本分配未能正常分配\\n    + red 有主分片未能分配，例如当服务器的磁盘容量超过85%时去创建了一个新的索引\\n+ `active_primary_shards` 集群中的主分片数量，涵盖了所有索引的汇总值\\n+ `active_shards` 集群中的分片数量，涵盖了所有索引的汇总值\\n+ `relocating_shards` 显示当前正在从一个节点迁往其他节点的分片的数量。通常来说应该是 0，不过在 Elasticsearch 发现集群不太均衡时，该值会上涨。比如说：添加了一个新节点，或者下线了一个节点。\\n+ `initializing_shards` 是刚刚创建的分片的个数。比如，当你刚创建第一个索引，分片都会短暂的处于 `initializing` 状态。这通常会是一个临时事件，分片不应该长期停留在 `initializing` 状态。你还可能在节点刚重启的时候看到 `initializing` 分片：当分片从磁盘上加载后，它们会从 `initializing` 状态开始。\\n+ `unassigned_shards` 是已经在集群状态中存在的分片，但是实际在集群里又找不着。通常未分配分片的来源是未分配的副本。比如，一个有 5 分片和 1 副本的索引，在单节点集群上，就会有 5 个未分配副本分片。如果你的集群是 `red` 状态，也会长期保有未分配分片（因为缺少主分片）\\n\\n## 五、基础操作\\n\\n### 1. 索引\\n\\n```shell\\n# 新建索引\\n$ PUT user\\n\\n# 删除索引\\n$ DELETE user\\n\\n# 查看所有索引信息\\n$ GET /_cat/indices?v\\n```\\n\\n### 2. 文档\\n\\n#### 2.1 创建\\n\\n```shell\\n# 使用 PUT 幂等性，需指定id\\n$ PUT /users/_doc/1 \\n{\\n  \\\"name\\\":\\\"wsj\\\",\\n  \\\"age\\\":20\\n}\\n\\n$ POST /users/_doc\\n{\\n  \\\"name\\\":\\\"wsj2\\\",\\n  \\\"age\\\":21\\n}\\n```\\n\\n#### 2.2 删除\\n\\n```shell\\n$ DELETE /users/_doc/1\\n```\\n\\n#### 2.3 更新\\n\\n```shell\\n# 更新,可以增加字段，也可以更新原来字段的值\\n$ POST users/_update/2\\n{\\n    \\\"doc\\\" : {\\n        \\\"name\\\" : \\\"wsj3\\\",\\n        \\\"age\\\":23,\\n        \\\"gender\\\":\\\"male\\\"\\n    }\\n}\\n```\\n\\n#### 2.4 查询\\n\\n```shell\\n# 查询id为1的文档\\n$ GET /users/_doc/1\\n\\n# 只查询部分字段，用逗号隔开\\n$ GET /users/_doc/1?_source=name,gender\\n\\n# 当字段较多时，可以选择包括和排除字段\\n$ GET /users/_doc/1?_source_includes=name&_souce_excludes=age\\n\\n# 如果只想得到 _source 字段，不需要任何元数据，使用 _source 端点\\n$ GET /users/_doc/1/_source\\n\\n\\n```\\n\\n#### 2.5 mget\\n\\n```shell\\n$ GET _mget\\n{\\n  \\\"docs\\\": [\\n    {\\n      \\\"_index\\\": \\\"user\\\",\\n      \\\"_id\\\": 1\\n    },\\n    {\\n      \\\"_index\\\": \\\"user\\\",\\n      \\\"_id\\\": 2\\n    }\\n  ]\\n}\\n```\\n\\n#### 2.6 bulk\\n\\n与 `mget` 可以使我们一次取回多个文档同样的方式， `bulk` API 允许在单个步骤中进行多次 `create` 、 `index` 、 `update` 或 `delete` 请求，多条操作中的单条操作失败并不会影响其他操作\\n\\n```shell\\n{ action: { metadata }}\\n{ request body        }\\n{ action: { metadata }}\\n{ request body        }\\n...\\n```\\n\\n例如：\\n\\n```shell\\nPOST /_bulk\\n{ \\\"delete\\\": { \\\"_index\\\": \\\"website\\\", \\\"_type\\\": \\\"blog\\\", \\\"_id\\\": \\\"123\\\" }} \\n{ \\\"create\\\": { \\\"_index\\\": \\\"website\\\", \\\"_type\\\": \\\"blog\\\", \\\"_id\\\": \\\"123\\\" }}\\n{ \\\"title\\\":    \\\"My first blog post\\\" }\\n{ \\\"index\\\":  { \\\"_index\\\": \\\"website\\\", \\\"_type\\\": \\\"blog\\\" }}\\n{ \\\"title\\\":    \\\"My second blog post\\\" }\\n{ \\\"update\\\": { \\\"_index\\\": \\\"website\\\", \\\"_type\\\": \\\"blog\\\", \\\"_id\\\": \\\"123\\\", \\\"_retry_on_conflict\\\" : 3} }\\n{ \\\"doc\\\" : {\\\"title\\\" : \\\"My updated blog post\\\"} } \\n```\\n\\n+ 请注意 `delete` 动作不能有请求体,它后面跟着的是另外一个操作\\n\\n+ 谨记最后一个换行符不要落下\\n\\n+ 不要一次请求操作过多\\n\\n    > 整个批量请求都需要由接收到请求的节点加载到内存中，因此该请求越大，其他请求所能获得的内存就越少。 批量请求的大小有一个最佳值，大于这个值，性能将不再提升，甚至会下降。 但是最佳值不是一个固定的值。它完全取决于硬件、文档的大小和复杂度、索引和搜索的负载的整体情况。\\n    >\\n    > 幸运的是，很容易找到这个 *最佳点* ：通过批量索引典型文档，并不断增加批量大小进行尝试。 当性能开始下降，那么你的批量大小就太大了。一个好的办法是开始时将 1,000 到 5,000 个文档作为一个批次, 如果你的文档非常大，那么就减少批量的文档个数。\\n    >\\n    > 密切关注你的批量请求的物理大小往往非常有用，一千个 1KB 的文档是完全不同于一千个 1MB 文档所占的物理大小。 一个好的批量大小在开始处理后所占用的物理大小约为 5-15 MB\\n\\n## 六、搜索\\n\\n+ url查询\\n+ Query DSL查询(建议)\\n\\n### 1. 索引\\n\\n```shell\\n# 单个索引\\nGET /movies/_search\\n{\\n  \\\"profile\\\": \\\"true\\\",\\t# 显示es如何搜索的\\n  \\\"query\\\": {\\n    \\\"match_all\\\": {}\\n  }\\n}\\n# 多个个索引\\nGET /movies,user/_search\\n{\\n  \\\"query\\\": {\\n    \\\"match_all\\\": {}\\n  }\\n}\\n```\\n\\n### 2. query语法\\n\\n#### 2.1 Query String\\n\\n```shell\\nGET /user/_search\\n{\\n  \\\"profile\\\": \\\"true\\\", \\n  \\\"query\\\": {\\n    \\\"query_string\\\": {\\n      \\\"default_field\\\": \\\"name\\\", \\n      \\\"query\\\": \\\"!mittacy chen\\\"\\n    }\\n  }\\n}\\n```\\n\\n支持 AND、OR、NOT、&&、||、!\\n\\n```shell\\nGET /user/_search\\n{\\n  \\\"profile\\\": \\\"true\\\", \\n  \\\"query\\\": {\\n    \\\"query_string\\\": {\\n      \\\"fields\\\": [\\\"name\\\", \\\"about\\\"], \\n      \\\"query\\\": \\\"(Ruan AND Yiming) OR (Java AND Elasticsearch)\\\"\\n    }\\n  }\\n}\\n```\\n\\n#### 2.2 Simple Query String\\n\\n```shell\\nGET /user/_search\\n{\\n  \\\"profile\\\": \\\"true\\\", \\n  \\\"query\\\": {\\n    \\\"simple_query_string\\\": {\\n      \\\"query\\\": \\\"mittacy chen\\\",\\n      \\\"fields\\\": [\\\"name\\\"],\\n      \\\"default_operator\\\": \\\"AND\\\"\\n    }\\n  }\\n}\\n```\\n\\n只支持 + / - / |，不支持 AND / NOT / OR，各个词之间的关系默认为 或，可以指定Operator\\n\\n```shell\\nGET /user/_search\\n{\\n  \\\"profile\\\": \\\"true\\\", \\n  \\\"query\\\": {\\n    \\\"simple_query_string\\\": {\\n      \\\"query\\\": \\\"-mittacy +chen\\\",\\n      \\\"fields\\\": [\\\"name\\\"]\\n    }\\n  }\\n}\\n```\\n\\n#### 2.2 短语搜索\\n\\n```shell\\n# 查询包含 \\\"mittacy chen\\\"，要求中间不能有其他字符\\nGET /user/_search\\n{\\n  \\\"query\\\": {\\n    \\\"match_phrase\\\": {\\n      \\\"name\\\": \\\"mittacy chen\\\"\\n    }\\n  }\\n}\\n\\n# 查询包含 \\\"mittacy chen\\\"，中间可以有其他字符\\nGET /user/_search\\n{\\n  \\\"query\\\": {\\n    \\\"match_phrase\\\": {\\n      \\\"name\\\": \\\"mittacy chen\\\",\\n      \\\"slop\\\": 1\\n    }\\n  }\\n}\\n```\\n\\n\\n\\n\\n\\n```shell\\n# 搜索名字包含chen的文档\\nGET /user/_search\\n{\\n  \\\"query\\\": {\\n    \\\"match\\\": {\\n      \\\"name\\\": \\\"chen\\\"\\n    }\\n  }\\n}\\n\\n\\n# 搜索名字包含chen不包含mittacy的文档\\nGET /user/_search\\n{\\n  \\\"profile\\\": \\\"true\\\",\\n  \\\"query\\\": {\\n    \\\"bool\\\": {\\n      \\\"must\\\": [\\n        {\\\"match\\\": {\\\"name\\\": \\\"chen\\\"}}\\n      ],\\n      \\\"must_not\\\": [\\n        {\\\"match\\\": {\\\"name\\\": \\\"mittacy\\\"}}\\n      ]\\n    }\\n  }\\n}\\n```\\n\\n### 3. 分页\\n\\n```shell\\nGET /movies/_search\\n{\\n  \\\"from\\\": 0,\\n  \\\"size\\\": 10,\\n  \\\"query\\\": {\\n    \\\"match_all\\\": {}\\n  }\\n}\\n```\\n\\n越往后的翻页成本越高\\n\\n### 4 选择指定字段\\n\\n```shell\\nGET /movies/_search\\n{\\n  \\\"_source\\\": [\\\"order_date\\\", \\\"_id\\\"],\\n  \\\"from\\\": 0,\\n  \\\"size\\\": 10,\\n  \\\"query\\\": {\\n    \\\"match_all\\\": {}\\n  }\\n}\\n```\\n\\n### 5. 排序\\n\\n```shell\\nGET /movies/_search\\n{\\n  \\\"sort\\\": [\\n  \\t{\\\"order_date\\\": \\\"desc\\\"}\\n  ],\\n  \\\"from\\\": 0,\\n  \\\"size\\\": 10,\\n  \\\"query\\\": {\\n    \\\"match_all\\\": {}\\n  }\\n}\\n```\\n\\n最好在 “数字型” 或 “日期型” 字段上排序，因为对于多值类型或分析过的字段排序，系统会选一个值，无法得知该值\\n\\n### 6. 脚本字段\\n\\n对旧字段进行操作生成新字段名并进行排序返回\\n\\n比如订单中有不同的汇率，需要结合汇率对订单价格进行操作后再进行排序\\n\\n```shell\\nGET user/_search\\n{\\n  \\\"script_fields\\\": {\\n    \\\"new_FIELD\\\": {\\n      \\\"script\\\": {}\\n    }\\n  }, \\n}\\n```\",\"category\":\"ElasticSearch\",\"createTime\":\"2021/04/08 10:25:00\"},{\"id\":\"1632138536483\",\"name\":\"Go功能选项模式\",\"title\":\"Go功能选项模式\",\"content\":\"\\n\\n\\n\\n日常Go编程时，经常会去实现一些带有设置选项的创建型函数，比如创建一个网络通信的客户端，创建客户端实例的函数需要提供某种方式可以让调用者设置客户端的一些行为属性，比如：超时时间、重试次数等等。但有时候提供的可设置选项比较多时，甚至后续还会增加。因此，设计和实现这样的创建型函数时要尤为考虑使用者的体验：不能因选项较多而提供过多参数或者多个API，并且要保证选项持续增加后，已经对外的接口依旧保持稳定。\\n\\n我们来设计和实现一个精装房实例，生活中精装房是有很多不同装修选项的，比如：\\n\\n+ 装修风格：美式/中式/欧式\\n+ 是否安装中央空调系统\\n+ 地面材料：瓷砖/实木地板\\n+ 墙面材料：乳胶漆/壁纸/硅藻泥\\n+ ……\\n\\n\\n\\n### 版本1：通过参数暴露配置选项\\n\\n一个最简单直接的实现方法就是通过函数参数暴露配置选项\\n\\n```go\\ntype FinishedHouse struct {\\n\\tStyle                  int    // 0: Chinese, 1: American, 2: European\\n\\tCentralAirConditioning bool   // true or false\\n\\tFloorMaterial          string // \\\"ground-tile\\\" or ”wood\\\"\\n\\tWallMaterial           string // \\\"latex\\\" or \\\"paper\\\" or \\\"diatom-mud\\\"\\n}\\n\\nfunc NewFinishedHouse(style int, centralAirConditioning bool,\\n\\tfloorMaterial, wallMaterial string) *FinishedHouse {\\n\\n\\t// here: you should do some check to the arguments passed\\n\\n\\th := &FinishedHouse{\\n\\t\\tStyle:                  style,\\n\\t\\tCentralAirConditioning: centralAirConditioning,\\n\\t\\tFloorMaterial:          floorMaterial,\\n\\t\\tWallMaterial:           wallMaterial,\\n\\t}\\n\\n\\treturn h\\n}\\n```\\n\\n+ 优点：\\n    + 快速实现\\n    + 调用者直接调用，成本低\\n+ 缺点：\\n    + 接口没法扩展\\n    + 参数过多时调用者很难操作\\n\\n\\n\\n### 版本2：使用结构体封装配置选项\\n\\n软件设计中的一个比较重要的原则就是“封装变化”，既然我们无法控制将来要加入的配置选项的个数和内容，但还要尽可能保持提供单一接口，我们就把“配置选项”这个变量抽取出来封装到一个结构体中，这也是目前比较常见的作法。\\n\\n```go\\ntype FinishedHouse struct {\\n\\tstyle                  int    // 0: Chinese, 1: American, 2: European\\n\\tcentralAirConditioning bool   // true or false\\n\\tfloorMaterial          string // \\\"ground-tile\\\" or ”wood\\\"\\n\\twallMaterial           string // \\\"latex\\\" or \\\"paper\\\" or \\\"diatom-mud\\\"\\n}\\n\\ntype Options struct {\\n\\tStyle                  int    // 0: Chinese, 1: American, 2: European\\n\\tCentralAirConditioning bool   // true or false\\n\\tFloorMaterial          string // \\\"ground-tile\\\" or ”wood\\\"\\n\\tWallMaterial           string // \\\"latex\\\" or \\\"paper\\\" or \\\"diatom-mud\\\"\\n}\\n\\nfunc NewFinishedHouse(options *Options) *FinishedHouse {\\n\\t// use default style and materials if option is nil\\n\\tvar style int = 0\\n\\tvar centralAirConditioning = true\\n\\tvar floorMaterial = \\\"wood\\\"\\n\\tvar wallMaterial = \\\"paper\\\"\\n\\n\\tif options != nil {\\n\\t\\t// here: you should do some check to the options passed\\n\\n\\t\\tstyle = options.Style\\n\\t\\tcentralAirConditioning = options.CentralAirConditioning\\n\\t\\tfloorMaterial = options.FloorMaterial\\n\\t\\twallMaterial = options.WallMaterial\\n\\t}\\n\\n\\th := &FinishedHouse{\\n\\t\\tstyle:                  style,\\n\\t\\tcentralAirConditioning: centralAirConditioning,\\n\\t\\tfloorMaterial:          floorMaterial,\\n\\t\\twallMaterial:           wallMaterial,\\n\\t}\\n\\n\\treturn h\\n}\\n```\\n\\n+ 优点\\n    + 后续添加新配置选项，Options 结构体可以随着时间变迁而增长，但 FinishedHouse 创建函数本身的 API 签名是保持不变的；\\n    + 调用者可以使用 nil 来表示他们希望使用默认配置选项；\\n    + 这种方法还带来了额外收获：更好的文档记录（文档重点从对 NewFinishedHouse 函数的大段注释描述转移到了对 Options 结构体各字段的说明）\\n+ 缺点\\n    + 调用者可能会有如此疑问：传递 nil 和传递&Options{}之间有区别吗；\\n    + 每次传递 Options 都要将 Options 中的所有字段做正确显式的赋值，即便调用者想使用某个配置项的默认值，赋值动作 1 依然不可少；\\n    + 调用者还可能有如此疑问：如果传递给 NewFinishedHourse 的 options 中的字段值在函数调用后发生了变化会发生什么情况？\\n\\n\\n\\n### 版本3：使用“功能选项”模式\\n\\nGo 语言之父 Rob Pike 早在 2014 年就在其一篇博文[“自引用函数与选项设计”](https://commandcenter.blogspot.com/2014/01/self-referential-functions-and-design.html)中论述了一种被后人称为“功能选项(functional option)”的模式，这种模式应该是目前进行功能选项设计的最佳实践方案。\\n\\n```go\\ntype FinishedHouse struct {\\n\\tstyle                  int    // 0: Chinese, 1: American, 2: European\\n\\tcentralAirConditioning bool   // true or false\\n\\tfloorMaterial          string // \\\"ground-tile\\\" or ”wood\\\"\\n\\twallMaterial           string // \\\"latex\\\" or \\\"paper\\\" or \\\"diatom-mud\\\"\\n}\\n\\ntype Option func(*FinishedHouse)\\n\\nfunc NewFinishedHouse(options ...Option) *FinishedHouse {\\n\\th := &FinishedHouse{\\n\\t\\tstyle:                  0,\\n\\t\\tcentralAirConditioning: true,\\n\\t\\tfloorMaterial:          \\\"wood\\\",\\n\\t\\twallMaterial:           \\\"paper\\\",\\n\\t}\\n\\n\\tfor _, option := range options {\\n\\t\\toption(h)\\n\\t}\\n\\n\\treturn h\\n}\\n\\nfunc WithStyle(style int) Option {\\n\\treturn func(h *FinishedHouse) {\\n\\t\\th.style = style\\n\\t}\\n}\\n\\nfunc WithFloorMaterial(material string) Option {\\n\\treturn func(h *FinishedHouse) {\\n\\t\\th.floorMaterial = material\\n\\t}\\n}\\n\\nfunc WithWallMaterial(material string) Option {\\n\\treturn func(h *FinishedHouse) {\\n\\t\\th.wallMaterial = material\\n\\t}\\n}\\n\\nfunc WithCentralAirConditioning(centralAirConditioning bool) Option {\\n\\treturn func(h *FinishedHouse) {\\n\\t\\th.centralAirConditioning = centralAirConditioning\\n\\t}\\n}\\n\\nfunc main() {\\n\\tfmt.Printf(\\\"%+v\\\\n\\\", NewFinishedHouse()) // use default options\\n\\tfmt.Printf(\\\"%+v\\\\n\\\", NewFinishedHouse(\\n\\t\\tWithStyle(1),\\n\\t\\tWithFloorMaterial(\\\"ground-tile\\\"),\\n\\t\\tWithCentralAirConditioning(false)))\\n}\\n```\\n\\n在该方案中，通过定义函数作为配置选项，用户通过自己需求传入函数选项即可实现配置自定义\\n\\n+ 优点：\\n    + 更漂亮的、不随时间变化的公共 API\\n    + 参数可读性更好\\n    + 配置选项高度可扩展\\n    + 提供使用默认选项的最简单方式\\n    + 使用更安全（不会像版本 2 那样在创建函数被调用后，调用者仍然可以修改 options）\\n\\n\",\"category\":\"Golang\",\"createTime\":\"2021/09/14 16:23:00\"},{\"id\":\"1662002246025\",\"name\":\"errgroup剖析\",\"title\":\"errgroup剖析\",\"content\":\"\\n\\n```go\\nfunc GetUser() {\\n    group := errgroup.WithContext(context.Background())\\n\\tgroup.Go(func(ctx context.Context) error {\\n\\t\\tuserInfo, err = service.User.GetInfo()\\n\\t})\\n\\tgroup.Go(func(ctx context.Context) error {\\n\\t\\trights, err = service.Rights.GetByUserId()\\n\\t})\\n\\tif err := group.Wait(); err != nil {\\n\\t\\t// ……\\n\\t}\\n}\\n```\\n\\n以上是我们使用 [golang.org/x/sync/errgroup](https://pkg.go.dev/golang.org/x/sync/errgroup)进行并发查询的简单使用，源代码也很简单只有几十行\\n\\n### 源码分析\\n\\n首先我们调用 WithContext，会创建一个带有cancel的context\\n\\n```go\\ntype Group struct {\\n\\tcancel func()\\n\\n\\twg sync.WaitGroup\\n\\n\\terrOnce sync.Once\\n\\terr     error\\n}\\n\\nfunc WithContext(ctx context.Context) (*Group, context.Context) {\\n    // 创建一个cancelCtx\\n\\tctx, cancel := context.WithCancel(ctx)\\n\\treturn &Group{cancel: cancel}, ctx\\n}\\n```\\n\\n随后我们使用了Group.Go()并发启动了多个任务：\\n\\n```go\\nfunc (g *Group) Go(f func() error) {\\n    // sync.WaitGroup等待任务+1\\n\\tg.wg.Add(1)\\n\\n\\tgo func() {\\n\\t\\tdefer g.wg.Done()\\t// 任务完成后sync.WaitGroup等待任务\\n\\n\\t\\tif err := f(); err != nil {\\n            // 只执行一次，捕获第一次报错任务错误信息\\n\\t\\t\\tg.errOnce.Do(func() {\\n\\t\\t\\t\\tg.err = err\\n\\t\\t\\t\\tif g.cancel != nil {\\n\\t\\t\\t\\t\\tg.cancel()\\t// 关闭context\\n\\t\\t\\t\\t}\\n\\t\\t\\t})\\n\\t\\t}\\n\\t}()\\n}\\n```\\n\\n我们在最后使用Group.Wait()等待所有并发任务执行完毕：\\n\\n```go\\nfunc (g *Group) Wait() error {\\n\\tg.wg.Wait()\\t// 等待sync.WaitGroup\\n\\tif g.cancel != nil {\\n\\t\\tg.cancel()\\t// 最后关闭context\\n\\t}\\n\\treturn g.err\\t// 返回第一个报错任务的错误信息\\n}\\n```\\n\\n以上就是最原始的errgroup的源码\\n\\n### 处理panic\\n\\n这里有个明显的问题就是我们的任务通过go func()异步执行，如果任务panic，将会导致整个服务挂了，所以我们需要优化一下 Group.Go() 给加上 recovery\\n\\n```go\\nfunc (g *Group) Go(f func() error) {\\n    // sync.WaitGroup等待任务+1\\n\\tg.wg.Add(1)\\n\\n\\tgo func() {\\n        defer func() {\\n            // recover捕获panic\\n            if r := recover(); r != nil {\\n                buf := make([]byte, 64<<10)\\n                buf = buf[:runtime.Stack(buf, false)]\\n                err = fmt.Errorf(\\\"errgroup: panic recovered: %s\\\\n%s\\\", r, buf)\\n            }\\n            g.wg.Done()\\t// 任务完成后sync.WaitGroup等待任务\\n        }\\n\\n\\t\\t// 其他\\n\\t}()\\n}\\n```\\n\\n### 控制并发数\\n\\n源库并没有对并发数进行限制，我们可以加上并发开关，首先是加上\\n\\n```go\\ntype Group struct {\\n\\tch chan func(ctx context.Context) error\\t// 任务管道，控制并发任务数\\n\\tchs []func(ctx context.Context) error\\t// 存储超过数量的并发任务队列\\n}\\n```\\n\\n1. 初始化\\n\\n    ```go\\n    func (g *Group) GOMAXPROCS(n int) {\\n    \\tif n <= 0 {\\n    \\t\\tpanic(\\\"errgroup: GOMAXPROCS must great than 0\\\")\\n    \\t}\\n    \\tg.workerOnce.Do(func() {\\n            // 初始化管道大小\\n    \\t\\tg.ch = make(chan func(context.Context) error, n)\\n            // 启动n个异步服务持续从管道获取任务进行消费\\n    \\t\\tfor i := 0; i < n; i++ {\\n    \\t\\t\\tgo func() {\\n    \\t\\t\\t\\tfor f := range g.ch {\\n    \\t\\t\\t\\t\\tg.do(f)\\n    \\t\\t\\t\\t}\\n    \\t\\t\\t}()\\n    \\t\\t}\\n    \\t})\\n    }\\n    ```\\n\\n2. 任务入管道执行或队列\\n\\n    ```go\\n    func (g *Group) Go(f func(ctx context.Context) error) {\\n    \\tg.wg.Add(1)\\n    \\tif g.ch != nil {\\n    \\t\\tselect {\\n    \\t\\tcase g.ch <- f:\\t// 如果任务管道未满，直接进入管道\\n    \\t\\tdefault:\\n    \\t\\t\\tg.chs = append(g.chs, f)\\t// 加入进入等待队列\\n    \\t\\t}\\n    \\t\\treturn\\n    \\t}\\n    \\tgo g.do(f)\\n    }\\n    ```\\n\\n3. 等待所有任务完成\\n\\n    ```go\\n    func (g *Group) Wait() error {\\n    \\tif g.ch != nil {\\t// 管道不为nil，表示有并发限制\\n    \\t\\tfor _, f := range g.chs {\\t// 遍历等待队列加入管道任务\\n    \\t\\t\\tg.ch <- f\\n    \\t\\t}\\n    \\t}\\n    \\tg.wg.Wait()\\t// 等待所有任务完成\\n    \\tif g.ch != nil {\\n    \\t\\tclose(g.ch) // let all receiver exit\\n    \\t}\\n    \\t\\n    \\treturn g.err\\n    }\\n    ```\\n\\n以上优化点来自B站升级的 [errgroup](https://github.com/go-kratos/kratos/blob/v1.0.0/pkg/sync/errgroup/errgroup.go) 库，需要注意的是该库的 WithContext和官方的 WithContext不一样，官方errgroup的WithContext有一个任务报错就会停止所有任务，而B站errgroup的WithContext是不会终止其他任务的，需要终止其他任务需要使用WithCancel()\\n\\n### 报错关闭所有任务\\n\\n+ 官方errgroup：\\n\\n    ```go\\n    func WithContext(ctx context.Context) (*Group, context.Context) {\\n    \\tctx, cancel := context.WithCancel(ctx)\\n    \\treturn &Group{cancel: cancel}, ctx\\n    }\\n    \\n    func (g *Group) Go(f func() error) {\\n    \\tg.wg.Add(1)\\n    \\tgo func() {\\n    \\t\\tdefer g.done()\\n    \\n    \\t\\tif err := f(); err != nil {\\n    \\t\\t\\tg.errOnce.Do(func() {\\n    \\t\\t\\t\\tg.err = err\\n    \\t\\t\\t\\tif g.cancel != nil {\\n    \\t\\t\\t\\t\\tg.cancel()\\n    \\t\\t\\t\\t}\\n    \\t\\t\\t})\\n    \\t\\t}\\n    \\t}()\\n    }\\n    ```\\n\\n+ B站errgroup库:\\n\\n    ```go\\n    func WithContext(ctx context.Context) *Group {\\n    \\treturn &Group{ctx: ctx}\\n    }\\n    \\n    func WithCancel(ctx context.Context) *Group {\\n    \\tctx, cancel := context.WithCancel(ctx)\\n    \\treturn &Group{ctx: ctx, cancel: cancel}\\n    }\\n    \\n    func (g *Group) do(f func(ctx context.Context) error) {\\n    \\tdefer func() {\\n    \\t\\tif r := recover(); r != nil {\\n    \\t\\t\\t// ……\\n    \\t\\t}\\n    \\t\\tif err != nil {\\n    \\t\\t\\tg.errOnce.Do(func() {\\n    \\t\\t\\t\\tg.err = err\\n                    // 只有用WithCancel时cancel才不会nil，才会执行关闭\\n                    if g.cancel != nil {\\n    \\t\\t\\t\\t\\tg.cancel()\\n    \\t\\t\\t\\t}\\n    \\t\\t\\t})\\n    \\t\\t}\\n    \\t\\tg.wg.Done()\\n    \\t}()\\n    \\terr = f(ctx)\\n    }\\n    ```\\n\\n    \\n\\n___\\n\\n+ 官方errgroup库：https://pkg.go.dev/golang.org/x/sync/errgroup\\n+ B站升级errgroup库：https://github.com/go-kratos/kratos/blob/v1.0.0/pkg/sync/errgroup/errgroup.go\",\"category\":\"Golang\",\"createTime\":\"2022/09/01 11:19:21\"},{\"id\":\"1660643420091\",\"name\":\"go拷贝详解\",\"title\":\"go拷贝详解\",\"content\":\"\\n\\n在编码过程中，我们经常会将一个变量赋值给另一个变量，这个过程可能是深拷贝或者浅拷贝，如果没能确定到底是哪一种拷贝，可能会带来数据不是自己所期望的结果，甚至导致现网事故。\\n\\n### 1. 深拷贝与浅拷贝\\n\\n+ 深拷贝：拷贝的是数据本身，创造一个样的新对象，新对象与被拷贝对象不共享内存， 新旧对象的修改不会相互影响。内存地址不同，释放内存地址时，可分别释放。\\n\\n    在go中，默认是深拷贝的类型有：Array、Int、String、Struct、Float，Bool\\n\\n+ 浅拷贝：拷贝的是数据地址，只复制指向的对象的指针，此时新老对象指向的内存地址是一样的，新对象值修改时老对象也会变化。释放内存地址时，同时释放内存地址。\\n\\n    在go中，默认是浅拷贝的类型有：Slice，Map\\n\\n**需要特别注意的结构体有Struct、Slice、Map**\\n\\n### 2. Struct\\n\\n#### 值拷贝-深拷贝\\n\\n```go\\ntype Student struct {\\n\\tName    string\\n\\tHobbies []string\\n}\\n\\nfunc main() {\\n\\tbreaking := Student{\\n\\t\\tName: \\\"breaking\\\",\\n\\t\\tHobbies: []string{\\\"basketball\\\", \\\"football\\\"},\\n\\t}\\n\\tbreaking2 := breaking\\n\\n\\tbreaking.Name = \\\"breaking1\\\"\\n\\tbreaking2.Name = \\\"breaking2\\\"\\n\\tbreaking2.Hobbies = []string{\\\"basketball\\\", \\\"ping-pong ball\\\"}\\n\\n\\tfmt.Printf(\\\"%p, breaking: %+v\\\\n\\\", &breaking, breaking)\\n\\tfmt.Printf(\\\"%p, breaking2: %+v\\\\n\\\", &breaking2, breaking2)\\n}\\n// 0x14000108180, breaking: {Name:breaking1 Hobbies:[basketball football]}\\n// 0x140001081b0, breaking2: {Name:breaking2 Hobbies:[basketball ping-pong ball]}\\n```\\n\\n可以看到新旧Struct的修改不会相互影响\\n\\n#### 引用拷贝-浅拷贝\\n\\n如果直接赋值旧变量的地址，则实际拷贝的是变量指针值，新的变量指针指向了同样的数据内存地址，看起来则为浅拷贝\\n\\n```go\\ntype Student struct {\\n\\tName    string\\n\\tHobbies []string\\n}\\n\\nfunc main() {\\n\\tbreaking := &Student{\\n\\t\\tName: \\\"breaking\\\",\\n\\t\\tHobbies: []string{\\\"basketball\\\", \\\"football\\\"},\\n\\t}\\n\\tbreaking2 := breaking\\n\\n\\tbreaking.Name = \\\"breaking1\\\"\\n\\tbreaking2.Name = \\\"breaking2\\\"\\n\\tbreaking2.Hobbies = []string{\\\"basketball\\\", \\\"ping-pong ball\\\"}\\n\\n\\tfmt.Printf(\\\"%p, breaking: %+v\\\\n\\\", breaking, breaking)\\n\\tfmt.Printf(\\\"%p, breaking2: %+v\\\\n\\\", breaking2, breaking2)\\n}\\n// 0x14000108180, breaking: &{Name:breaking2 Hobbies:[basketball ping-pong ball]}\\n// 0x14000108180, breaking2: &{Name:breaking2 Hobbies:[basketball ping-pong ball]}\\n```\\n\\n### 3. Slice\\n\\n#### 引用拷贝-浅拷贝\\n\\n```go\\nfunc main() {\\n    a := []int{1, 2, 3, 4, 5}\\n\\tb := a\\n\\tb[1] = 12\\n\\n\\tfmt.Printf(\\\"%p, a: %v\\\\n\\\", a, a)\\n\\tfmt.Printf(\\\"%p, b: %v\\\\n\\\", b, b)\\n}\\n// 0x14000020090, a: [1 12 3 4 5]\\n// 0x14000020090, b: [1 12 3 4 5]\\n```\\n\\n#### copy深拷贝\\n\\n```go\\nfunc main() {\\n\\ta := []int{1, 2, 3, 4, 5}\\n\\tb := make([]int, len(a))\\n\\tcopy(b, a)\\n\\n\\tb[1] = 12\\n\\n\\tfmt.Printf(\\\"%p, a: %v\\\\n\\\", a, a)\\n\\tfmt.Printf(\\\"%p, b: %v\\\\n\\\", b, b)\\n}\\n// 0x14000124030, a: [1 2 3 4 5]\\n// 0x14000124060, b: [1 12 3 4 5]\\n```\\n\\n### 4. Map\\n\\n#### 引用拷贝-浅拷贝\\n\\n```go\\nfunc main() {\\n\\ta := map[int]string{\\n\\t\\t0: \\\"0\\\",\\n\\t\\t1: \\\"1\\\",\\n\\t}\\n\\tb := a\\n\\n\\ta[0] = \\\"00\\\"\\n\\tb[1] = \\\"11\\\"\\n\\n\\tfmt.Printf(\\\"%p, a: %v\\\\n\\\", a, a)\\n\\tfmt.Printf(\\\"%p, b: %v\\\\n\\\", b, b)\\n}\\n// 0x14000060180, a: map[0:00 1:11]\\n// 0x14000060180, b: map[0:00 1:11]\\n```\\n\\n#### 深拷贝\\n\\nMap中的其实是不能拷贝的，如果想要拷贝一个map，唯一办法就是循环赋值：\\n\\n```go\\nfunc main() {\\n    a := map[int]string{\\n\\t\\t0: \\\"0\\\",\\n\\t\\t1: \\\"1\\\",\\n\\t}\\n\\tb := make(map[int]string, len(a))\\n\\tfor k, v := range a {\\n\\t\\tb[k] = v\\n\\t}\\n\\n\\ta[0] = \\\"00\\\"\\n\\tb[1] = \\\"11\\\"\\n\\n\\tfmt.Printf(\\\"%p, a: %v\\\\n\\\", a, a)\\n\\tfmt.Printf(\\\"%p, b: %v\\\\n\\\", b, b)\\n}\\n// 0x14000060180, a: map[0:00 1:1]\\n// 0x140000601b0, b: map[0:0 1:11]\\n```\\n\\n如果 `map` 中有指针，同样需要考虑深浅拷贝的问题\\n\\n#### map包含Struct\\n\\n主要注意，map不是一个并发安全的结构，所以，并不能修改他内部结构体中的值，比如下面是不可行的\\n\\n```go\\nfunc main() {\\n\\ta := map[int]Student{\\n\\t\\t1: {ID: 1, Name: \\\"break\\\", Hobbies: []string{\\\"basketball\\\"}},\\n\\t}\\n\\tb := a\\n\\n    a[1].ID = 11\\t// 报错: 无法分配给 a[1].ID\\n\\n\\tfmt.Printf(\\\"%p, a: %v\\\\n\\\", a[1], a[1])\\n\\tfmt.Printf(\\\"%p, b: %v\\\\n\\\", b[1], b[1])\\n}\\n```\\n\\n如果想要修改Map内Struct的字段值，有两种方法：\\n\\n+ 创建临时struct，赋值后整个struct赋值给原变量\\n\\n    ```go\\n    func main() {\\n    \\ta := map[int]Student{\\n    \\t\\t1: {ID: 1, Name: \\\"break\\\", Hobbies: []string{\\\"basketball\\\"}},\\n    \\t}\\n    \\n    \\tt := a[1]\\n    \\tt.ID = 11\\n    \\ta[1] = t\\n    }\\n    ```\\n\\n+ struct使用指针\\n\\n    ```go\\n    func main() {\\n    \\ta := map[int]*Student{\\n    \\t\\t1: {ID: 1, Name: \\\"break\\\", Hobbies: []string{\\\"basketball\\\"}},\\n    \\t}\\n    \\n    \\ta[1].ID = 11\\n    }\\n    ```\\n\\n如果使用指针型Struct，则需要考虑引用拷贝为浅拷贝问题，如果需要深拷贝则需要每次创建新的结构体进行赋值\\n\\n```go\\ntype Student struct {\\n\\tID      int\\n\\tName    string\\n\\tHobbies []string\\n}\\n\\nfunc main() {\\n\\ta := map[int]*Student{\\n\\t\\t1: {ID: 1, Name: \\\"break\\\", Hobbies: []string{\\\"basketball\\\"}},\\n\\t}\\n\\tb := make(map[int]*Student, len(a))\\n\\tfor k, v := range a {\\n\\t\\tif v == nil {\\n\\t\\t\\tcontinue\\n\\t\\t}\\n\\t\\tb[k] = &Student{\\n\\t\\t\\tID:      v.ID,\\n\\t\\t\\tName:    v.Name,\\n\\t\\t\\tHobbies: v.Hobbies,\\n\\t\\t}\\n\\t}\\n\\n\\ta[1].ID = 11\\n\\tb[1].ID = 22\\n\\n\\tfmt.Printf(\\\"%p, a: %v\\\\n\\\", a[1], a[1])\\n\\tfmt.Printf(\\\"%p, b: %v\\\\n\\\", b[1], b[1])\\n}\\n```\\n\\n#### map包含Slice\\n\\n由于Slice默认拷贝为浅拷贝，所以上述例子中Struct内部包含了字符串Slice，实际上Hobbies字段为浅拷贝\\n\\n```go\\nfunc main() {\\n\\ta := map[int]*Student{\\n\\t\\t1: {ID: 1, Name: \\\"break\\\", Hobbies: []string{\\\"basketball\\\"}},\\n\\t}\\n\\tb := make(map[int]*Student, len(a))\\n\\tfor k, v := range a {\\n\\t\\tif v == nil {\\n\\t\\t\\tcontinue\\n\\t\\t}\\n\\t\\tb[k] = &Student{\\n\\t\\t\\tID:      v.ID,\\n\\t\\t\\tName:    v.Name,\\n\\t\\t\\tHobbies: v.Hobbies,\\n\\t\\t}\\n\\t}\\n\\n\\tb[1].Hobbies[0] = \\\"football\\\"\\n\\n\\tfmt.Printf(\\\"%p, a: %v\\\\n\\\", a[1], a[1])\\n\\tfmt.Printf(\\\"%p, b: %v\\\\n\\\", b[1], b[1])\\n}\\n// 0x140000a4030, a: &{1 break [football]}\\n// 0x140000a4060, b: &{1 break [football]}\\n```\\n\\n需要对Slice进行特殊处理\\n\\n```go\\nfunc main() {\\n\\ta := map[int]*Student{\\n\\t\\t1: {ID: 1, Name: \\\"break\\\", Hobbies: []string{\\\"basketball\\\"}},\\n\\t}\\n\\tb := make(map[int]*Student, len(a))\\n\\tfor k, v := range a {\\n\\t\\tif v == nil {\\n\\t\\t\\tcontinue\\n\\t\\t}\\n\\t\\tb[k] = &Student{\\n\\t\\t\\tID:      v.ID,\\n\\t\\t\\tName:    v.Name,\\n\\t\\t}\\n\\t\\tb[k].Hobbies = make([]string, len(v.Hobbies))\\n\\t\\tcopy(b[k].Hobbies, v.Hobbies)\\n\\t}\\n\\n\\tb[1].Hobbies[0] = \\\"football\\\"\\n\\n\\tfmt.Printf(\\\"%p, a: %v\\\\n\\\", a[1], a[1])\\n\\tfmt.Printf(\\\"%p, b: %v\\\\n\\\", b[1], b[1])\\n}\\n// 0x14000108180, a: &{1 break [basketball]}\\n// 0x140001081b0, b: &{1 break [football]}\\n```\\n\\n**Map内可以有Slice，Slice可以是Map Slice，各种类型交错组合，在写深拷贝时需要特别注意**\\n\\n\\n\\n___\\n\\n总结：golang所有参数传递都是`值拷贝`，但是Slice、Map类型存储的是`内存地址`，所以值拷贝的是`内存地址`，也就是所谓的浅拷贝\",\"category\":\"Golang\",\"createTime\":\"2022/04/08 20:01:12\"},{\"id\":\"1632138738854\",\"name\":\"Linux常用命令全称\",\"title\":\"Linux常用命令对应全称\",\"content\":\"\\n\\n| 简写  | 全称                                   | 作用                                   |\\n| ----- | -------------------------------------- | -------------------------------------- |\\n| rmp   | red hat package manager                | Centos体系安装包                       |\\n|       | `-i=>install` `-e=>erase` `-r=>remove` |                                        |\\n| dpkg  | debian package manager                 | Debian或基于Debian的发行版中提供       |\\n| cd    | change directory                       | 重定位到目录                           |\\n| ls    | list                                   | 列表                                   |\\n| chown | change owner                           | 所属用户                               |\\n| chgrp | change group                           | 改变所属组                             |\\n| chmod | change mod                             | 改变权限                               |\\n| su    | switch user                            | 切换用户                               |\\n| pwd   | print work directory                   | 打印当前目录的绝对路径                 |\\n| ps    | process status                         | 进程状态                               |\\n| df    | disk free                              | 磁盘可用空间数目信息及空间结点信息     |\\n| du    | disk usage                             | 磁盘已使用                             |\\n| rm    | remove                                 | 删除目录或文件                         |\\n| mkdir | make directory                         | 创建目录                               |\\n| mv    | move file                              | 移动文件                               |\\n| rm    | remove file                            | 删除文件                               |\\n| cp    | copy file                              | 复制文件                               |\\n| ln    | link file                              | 链接文件                               |\\n| nohup | no hang up                             | 不挂起，即当前交互命令行退出后程序还在 |\\n|       |                                        |                                        |\\n|       |                                        |                                        |\\n|       |                                        |                                        |\\n\\n\",\"category\":\"Linux\",\"createTime\":\"2021/09/19 16:00:00\"},{\"id\":\"1630140845566\",\"name\":\"Mysql日志\",\"title\":\"Mysql日志\",\"content\":\"\\n\\nMysql共有六种日志：\\n\\n+ redo log\\n+ undo log\\n+ binlog\\n+ errlog\\n+ slow query log\\n+ general log\\n+ relay log\\n\\n### 1. redo log\\n\\nredo log是物理日志，InnoDB特有，包含两部分：\\n\\n+ `redo log buffer` :  内存中的日志缓存\\n+ `redo log file`：磁盘上的重做日志文件\\n\\nredo log 是物理日志，记录的是“在**某个数据页**上做了什么修改”\\n\\n事务的每个操作都会记录到`redo log buffer`中，而什么时候更新到`redo log file` 由参数 `innodb_flush_log_at_trx_commit` 决定\\n\\n+ 1 每次commit都会把redo log从`redo log buffer`写入到`os buffer`，如果不是只读操作，即涉及到数据修改，则调用`fsync()`刷新到磁盘文件`redo log file`中\\n+ 2 每次commit都写入到`os buffer`，但是每秒才调用`fsync()`刷新到`redo log file`\\n+ 0 每秒写入到 `os buffer`并刷新到`redo log file`\\n\\n#### 1.1 redo log文件\\n\\nredo log file 可以有多个文件，由参数`innodb_log_files_in_group`决定，它们的大小完全一致，将`os buffer`刷新到这些`redo log file`中是循环写入的，从第一个文件开始写，写满了从第二个文件继续写，全满了就从第一个文件从头开始覆盖写，当然，覆盖前得确保这些数据更新到这些操作对应的数据中\\n\\n#### 1.2 日志刷盘规则\\n\\n`redo log buffer`中未保存到磁盘的的日志称为`dirty log`\\n\\n刷日志到磁盘有以下几种触发规则：\\n\\n+ 上面已经提到的，事务`commit`动作是否提交由`innodb_flush_log_at_trx_commit`决定\\n+ 每秒刷一次。由`innodb_flush_log_at_timeout`决定，默认1秒，注意与`commit动作无关`\\n+ `当redo log buffer`中已经使用的内存超过一半\\n+ 当有`checkpoint`时\\n\\n#### 1.3 数据页刷盘\\n\\n同样的，内存中（`buffer pool`）未刷到磁盘的数据称为脏数据（`dirty data`），注意，虽然修改记录已经记录到`redo log file`中，但是并未更新到真正的数据中，所以内存和磁盘中的数据是不一致的。\\n\\n触发数据页刷盘的规则只有一个：`checkpoint`。但是触发`checkpoint`的情况却有几种。不管怎样，`checkpoint`触发后，会将`buffer`中脏日志页都刷到磁盘，脏数据页部分或全部刷到数据\\n\\nInnoDB 存储引擎中`checkpoint`分为两种：\\n\\n+ `share checkpoint`：在重用`redo log`文件（例如切换日志文件）的时候，将所有已记录到`redo log`中对应的脏数据刷到磁盘\\n+ `fuzzy checkpoint`：一次只刷一小部分的日志到磁盘，而非将所有脏日志刷盘\\n  + `master thread checkpoint`：由`master`线程控制，每秒或每 10 秒刷入一定比例的脏页到磁盘\\n  + `flush_lru_list checkpoint`：从 MySQL5.6 开始可通过`innodb_page_cleaners`变量指定专门负责脏页刷盘的`page cleaner`线程的个数，该线程的目的是为了保证`lru`列表有可用的空闲页\\n  + `async/sync flush checkpoint`：同步刷盘还是异步刷盘\\n  + `dirty page too much checkpoint`：脏页太多时强制触发检查点，目的是为了保证缓存有足够的空闲空间。`too much`的比例由变量`innodb_max_dirty_pages_pct`控制，MySQL 5.6 默认的值为 75，即当脏页占缓冲池的 75% 后，就强制刷一部分脏页到磁盘。\\n\\n### 2. binlog\\n\\nbinlog是逻辑日志，在Server层实现的，追加写入文件，所有存储引擎都能使用，记录的是这个这个语句的原始逻辑。\\n\\n主要用于归档、主从同步等。\\n\\n格式：\\n\\n+ statement\\n\\n  记录的是sql原句，如果主备库进行同步可能出现不一致：\\n\\n  `delete from t where a>=4 and t_modified<='2018-11-10' limit 1;`\\n\\n  如果主库使用索引a进行查找，删除了一行记为 ROW1；\\n\\n  记录到binlog，备库执行该语句不一定使用a索引，可能使用t_modified索引，找到的第一行不一定是ROW1这一行，可能会删除其他行导致主备不一致\\n\\n+ row\\n\\n  row格式会记录行的内容，记两条，更新前和更新后都有。row 格式的缺点是很占空间。如果删除10万行数据，用 statement 只需要记录一个SQL语句；用 row 要把这10万条记录都写到binlog中，不仅占用更大的空间，同时写 binlog 也要耗费IO资源，影响执行速度\\n\\n+ mixed\\n\\n  使用 mixed 格式的binlog，Mysql 会判断 SQL语句是否可能引起主备不一致，如果有可能，就用row格式，否则用 statement格式\\n\\n### 3. undo log\\n\\n+ 回滚日志用于事务确保原子性，事务的每个操作都会记录逆向逻辑操作，当执行rollback时，可以执行`undo log`实现回到起点\\n+ 同时`undo log`也是实现MVCC的基础\\n\\n\\n\\n系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。\\n\\n### 3. 两阶段提交\\n\\n比如执行：`mysql> update T set c=c+1 where ID=2;`\\n\\n1. 执行器先找引擎取 ID=2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID=2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\\n2. 执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\\n3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务\\n4. 执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\\n5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。\\n\\n两阶段提交是为了让两份日志之间的逻辑一致。\\n\\n\\n\\n### 总结问题\\n\\n1. redo log 和 bin log区别\\n\\n   binlog主要用于归档，它不知道哪些操作已经刷新到磁盘数据中了，如果DB异常重启，不能恢复内存中未更新到磁盘的数据\\n\\n   而redo log日志则记录了未刷新数据的操作位置，如果异常重启，重启之后，可以使用redo log日志恢复数据，也就是拥有 crash-safe 能力\\n\\n\\n\\n___\\n\\n参考文章：\\n\\n1. https://time.geekbang.org/column/intro/139\\n2. https://www.cnblogs.com/wy123/p/8365234.html\\n3. https://www.cnblogs.com/xinysu/p/6555082.html#_lab2_1_0\\n4. https://blog.csdn.net/qq_35246620/article/details/79345359\\n\\n\",\"category\":\"Mysql\",\"createTime\":\"2021/08/23 18:00:00\",\"banner\":\"http://static.mittacy.com/blog/202109041441156.jpg\"},{\"id\":\"1660643420092\",\"name\":\"JWT\",\"title\":\"JWT\",\"content\":\"\\n\\n## JWT\\n\\n互联网服务离不开用户认证\\n\\n### 1. session认证\\n\\n1. 用户发送用户名和密码向服务器发送登录请求\\n2. 服务器验证通过后，在当前对话（session）里面保存相关数据，比如用户角色、登录时间、过期时间等等\\n3. 服务器生成session_id作为key，val为用户id等身份数据，然后向用户返回一个 session_id，写入用户的 cookie\\n4. 用户随后的每次请求，都会通过 cookie，将 session_id 传回服务器\\n5. 服务器收到 session_id，使用session_id查询用户身份数据，由此得知用户的身份\\n\\n这种方式的好处是session可控制，缺点是扩展性差、占用内存/存储空间，跨域等问题\\n\\n### 2. JWT的原理\\n\\n服务器不保存 session 数据，所有数据都保存在客户端，每次请求发回服务器，这就是jwt的原理，但是直接发送是不安全的，所以进行了加密，这就是JWT。\\n\\nJWT全称 JSON Web Token，服务器认证以后，生成一个 JSON 对象，发回给用户，就像下面这样：\\n\\n```json\\n{\\n  \\\"姓名\\\": \\\"张三\\\",\\n  \\\"角色\\\": \\\"管理员\\\",\\n  \\\"到期时间\\\": \\\"2022年7月8日0点0分\\\"\\n}\\n```\\n\\n用户之后的每次请求通信，都要带上这个JSON对象，服务器只靠这个对象认定用户身份，为了防止用户篡改数据，服务器在生成这个对象的时候会进行加密和签名\\n\\n### 3. JWT的数据结构\\n\\n实际的JWT大概长这样：`Header.Payload.Signature`\\n\\n```json\\n\\n```\\n\\n+ Header 头部：\\n+ Payload 负载：\\n+ Signature 签名：\\n\\n#### 3.1 Header 头部\\n\\nHeader 部分是一个 JSON对象，描述 JWT 的元数据，通常是下面的样子：\\n\\n```json\\n{\\n    \\\"alg\\\": \\\"HS256\\\",\\n    \\\"typ\\\": \\\"JWT\\\"\\n}\\n```\\n\\n+ `alg` 属性表示签名的算法，默认是 HMAC SHA256；\\n+ `typ` 表示令牌的类型，JWT令牌统一写为 JWT\\n\\n#### 3.2 Payload 负载\\n\\nPayload 也是一个 JSON 对象，用来存放实际需要传递的数据。JWT 规定了7个官方字段供选用\\n\\n+ iss (issuer)：签发人\\n+ exp (expiration time)：过期时间\\n+ sub (subject)：主题\\n+ aud (audience)：受众\\n+ nbf (Not Before)：生效时间\\n+ iat (Issued At)：签发时间\\n+ jti (JWT ID)：编号\\n\\n我们的用户信息也在这个部分进行定义：\\n\\n```json\\n{\\n    \\\"sub\\\": \\\"1234567890\\\",\\n  \\t\\\"name\\\": \\\"Mittacy Chen\\\",\\n  \\t\\\"role\\\": \\\"admin\\\"\\n}\\n```\\n\\n注意，JWT 默认是不加密的，任何人都可以读到，所以不要把秘密信息放在这个部分。\\n\\n#### 3.3 Signature 签名\\n\\nsignature 部分是对前两部分的签名，防止数据篡改\\n\\n首先，需要指定一个 **密钥 secret**，这个密钥只有服务器才只知道，不能泄露给用户。\\n\\n然后使用 Header 里面指定的签名算法（默认是 HMAC SHA256）产生签名：\\n\\n`HMACSHA256(base64UrlEncode(header) + \\\".\\\" + base64UrlEncode(payload), secret)`\\n\\n算出签名以后，把 Header、Payload、Signature 三个部分拼成一个字符串，就可以返回给用户\\n\\n#### 3.4 Base64URL\\n\\n前面提到，Header 和 Payload 串型化的算法是 Base64URL，这个算法跟 Base64 算法的差异为：base64有三个字符 `+`、`/`、`=` 在URL里面有特殊含义，所以要被替换掉：`=被省略`、`+被替换成-`、`/被替换成_`\\n\\n### 4. JWT 的使用方式\\n\\n客户端收到服务器返回的 JWT后，客户端每次与服务器通信，都要带上这个 JWT。\\n\\n+ 可以存储在Cookie里面，这种方式不支持跨域\\n+ 存储在localStorage，发送时放在 HTTP 请求的头信息 `Authorization` 字段\\n\\n### 5. JWT的几个特点\\n\\n+ JWT不仅可以用于认证，也可以用于交换信息。有效使用 JWT，可以降低服务器查询数据库的次数\\n\\n+ JWT的最大缺点是，由于服务器不保存session状态，因此无法再使用过程中废止某个token，或者更改token的权限，一旦JWT签发了，在到期之前就会始终有效。可以使用redis记录黑名单token，有效期就截止该token的有效期，在解析token前先查询黑名单是否存在，存在则无效，这种做法可以解决退出后让token失效，但是有一种情况是没法解决的：\\n\\n    > 一个用户在手机A中登录了，然后又在手机B中登录，在过期之前手机A和B都可以登录，无法做到B登录后让A过期，如果要做到这点，就必须让服务器维护一个清单（记录该账号是否已经签发token），这样又回到session的老路了\\n\\n+ JWT本身包含了认证信息，一旦泄露，任何人都可以使用该令牌的所有权限，为了减少盗用，JWT的有效期应该设置得短一些，可以采用续签的方式，在校验token快过期时重新签发；同时 JWT 应该使用 HTTPS 协议传输\\n\\n\\n\\n## Go实现用户身份校验\\n\\n###  1. 登录\\n\\nJWT服务：\\n\\n```go\\n// 生成管理员登录token\\nfunc (ctl *jwtService) GenerateAdminToken(id int64, name string, role model.UserRole, expire time.Duration) (string, time.Time, error) {\\n\\texpireAt := time.Now().Add(expire)\\n\\ttoken := model.Token{\\n\\t\\tID:       id,\\n\\t\\tUserName: name,\\n\\t\\tRole:     role,\\n\\t\\tRegisteredClaims: jwt.RegisteredClaims{\\n\\t\\t\\tExpiresAt: jwt.NewNumericDate(expireAt),\\n\\t\\t\\tIssuer:    viper.GetString(\\\"TOKEN_ISSUER\\\"),\\n\\t\\t},\\n\\t}\\n\\n\\tt := jwt.NewWithClaims(jwt.SigningMethodHS256, token)\\n\\tsecret := []byte(viper.GetString(\\\"TOKEN_SECRET\\\"))\\n\\ttokenStr, err := t.SignedString(secret)\\n\\tif err != nil {\\n\\t\\treturn \\\"\\\", time.Time{}, errors.WithStack(err)\\n\\t}\\n\\n\\treturn tokenStr, expireAt, nil\\n}\\n\\n// 解析token信息\\nfunc (ctl *jwtService) ParseToken(tokenStr string) (*model.Token, error) {\\n\\tsecret := []byte(viper.GetString(\\\"TOKEN_SECRET\\\"))\\n\\ttoken, err := jwt.ParseWithClaims(tokenStr, &model.Token{}, func(token *jwt.Token) (interface{}, error) {\\n\\t\\treturn secret, nil\\n\\t})\\n\\n\\tif token != nil {\\n\\t\\tif claims, ok := token.Claims.(*model.Token); ok && token.Valid {\\n\\t\\t\\treturn claims, nil\\n\\t\\t}\\n\\t}\\n\\n\\treturn nil, err\\n}\\n```\\n\\n用户服务，登录操作\\n\\n```go\\nfunc (ctl *userService) Login(c *gin.Context, username, password string) (*smodel.Login, error) {\\n\\tvar admin model.User\\n\\twhere := map[string]interface{}{\\\"user_name\\\": username, \\\"is_delete\\\": model.UserIsDeletedNo}\\n\\terr := ctl.data.First(c, where, nil, &admin)\\n\\tif err != nil && !errors.Is(err, gorm.ErrRecordNotFound) {\\n\\t\\treturn nil, err\\n\\t}\\n\\n\\t// 检查密码\\n\\tif errors.Is(err, gorm.ErrRecordNotFound) || admin.Password != encodeUtil.EncryptionPassword(password, admin.Salt) {\\n\\t\\treturn nil, bizerr.UserNamePasswordErr\\n\\t}\\n\\n\\t// 获取登录token\\n\\ttoken, expireAt, err := Jwt.GenerateAdminToken(admin.ID, admin.UserName, admin.Role, time.Hour*viper.GetDuration(\\\"TOKEN_EXPIRE_HOUR\\\"))\\n\\tif err != nil {\\n\\t\\treturn nil, errors.WithMessage(err, \\\"获取登录token失败\\\")\\n\\t}\\n\\n\\treturn &smodel.Login{Token: token, ExpireAt: expireAt}, nil\\n}\\n```\\n\\n\\n\\n\\n\\n___\\n\\n参考文章：https://www.ruanyifeng.com/blog/2018/07/json_web_token-tutorial.html\",\"category\":\"Web开发\",\"createTime\":\"2022/06/01 19:19:21\"},{\"id\":\"1630739392755\",\"name\":\"JsonSchema\",\"title\":\"JsonSchema\",\"content\":\"\\n\\n### 1. 什么是JSON Schema\\n\\nJSON Schema本身就是一种数据结构，可以清晰的描述JSON数据的结构，是一种描述JSON数据的JSON数据\\n\\n### 2. 使用JSON Schema的好处\\n\\n+ JSON Schema从Java的基本数据类型中对JSON结构进行校验，所以对JSON结构的校验可以理解为对每种不同数据类型的相应校验\\n+ 接口测试中可以快速的定位到自己数据格式的正确性\\n+ JSON Schema 非常适用于基于JSON的HTTP的API\\n\\n### 3. 常用关键字\\n\\nJSON Schema实例\\n\\n~~~json\\n{\\n    \\\"$schema\\\":\\\"http://json-schema.org/draft-04/schema#\\\",\\n  \\t\\\"items\\\": { \\\"$ref\\\": \\\"#/definitions/positiveInteger\\\"},\\n    \\\"title\\\":\\\"book info\\\",\\n    \\\"description\\\":\\\"some information about book\\\",\\n    \\\"type\\\":\\\"object\\\",\\n    \\\"properties\\\":{\\n        \\\"id\\\":{\\n            \\\"description\\\":\\\"The unique identifier for a book\\\",\\n            \\\"type\\\":\\\"integer\\\",\\n            \\\"minimum\\\":1\\n        },\\n        \\\"name\\\":{\\n            \\\"type\\\":\\\"string\\\",\\n            \\\"pattern\\\":\\\"^#([0-9a-fA-F]{6}$\\\",\\n            \\\"maxLength\\\":6,\\n            \\\"minLength\\\":6\\n        },\\n        \\\"price\\\":{\\n            \\\"type\\\":\\\"number\\\",\\n            \\\"multipleOf\\\":0.5,\\n            \\\"maximum\\\":12.5,\\n            \\\"exclusiveMaximum\\\":true,\\n            \\\"minimum\\\":2.5,\\n            \\\"exclusiveMinimum\\\":true\\n        },\\n        \\\"tags\\\":{\\n            \\\"type\\\":\\\"array\\\",\\n            \\\"items\\\":[\\n                {\\n                    \\\"type\\\":\\\"string\\\",\\n                    \\\"minLength\\\":5\\n                },\\n                {\\n                    \\\"type\\\":\\\"number\\\",\\n                    \\\"minimum\\\":10\\n                }\\n            ],\\n            \\\"additionalItems\\\":{\\n                \\\"type\\\":\\\"string\\\",\\n                \\\"minLength\\\":2\\n            },\\n            \\\"minItems\\\":1,\\n            \\\"maxItems\\\":5,\\n            \\\"uniqueItems\\\":true\\n        }\\n    },\\n    \\\"minProperties\\\":1,\\n    \\\"maxProperties\\\":5,\\n    \\\"required\\\":[\\n        \\\"id\\\",\\n        \\\"name\\\",\\n        \\\"price\\\"\\n    ]\\n}\\n~~~\\n\\n关键字：\\n\\n| 关键字      | 描述                                                 |\\n| ----------- | ---------------------------------------------------- |\\n| $schema     | 声明是JSON Schema，而不是JSON                        |\\n| title       | 一般用来进行简单的描述，可以省略                     |\\n| description | 一般是进行详细的描述信息，可以省略                   |\\n| type        | 用来约束校验的JSON元素的数据类型，必须是一个JSON对象 |\\n| properties  | 定义各个字段属性                                     |\\n| required    | 是一个数组，数组中的字符串表示必须要有的属性         |\\n| maxLength   | 最大长度                                             |\\n| minLength   | 最小长度                                             |\\n| pattern     | 如果正则表达式匹配成功则有效                         |\\n| $ref        | 用来引用其他的schema                                 |\\n\\n### 4. type常见取值\\n\\n| 取值    | 对应的Java数据类型             |\\n| ------- | ------------------------------ |\\n| object  | java.lang.Object               |\\n| array   | java.util.List                 |\\n| integer | int (java.lang.Integer)        |\\n| number  | float (java.lang.Float) 或 int |\\n| null    | null                           |\\n| boolean | java.lang.Boolean              |\\n| string  | java.lang.String               |\\n\\n#### 4.1 object类型\\n\\n~~~json\\n{\\n  \\t……\\n    \\\"type\\\":\\\"object\\\",\\n    \\\"properties\\\":{\\n        \\\"id\\\":{\\n            \\\"description\\\":\\\"The unique identifier for a book\\\",\\n            \\\"type\\\":\\\"integer\\\",\\n            \\\"minimum\\\":1\\n        },\\n        \\\"price\\\":{\\n            \\\"type\\\":\\\"number\\\",\\n            \\\"minimum\\\":0,\\n            \\\"exclusiveMinimum\\\":true\\n        }\\n    },\\n    \\\"patternProperties\\\":{\\n        \\\"^a\\\":{\\n            \\\"type\\\":\\\"number\\\"\\n        },\\n        \\\"^b\\\":{\\n            \\\"type\\\":\\\"string\\\"\\n        }\\n    },\\n    \\\"additionalProperties\\\":{\\n        \\\"type\\\":\\\"number\\\"\\n    },\\n    \\\"minProperties\\\":1,\\n    \\\"maxProperties\\\":5,\\n    \\\"required\\\":[\\n        \\\"id\\\",\\n        \\\"name\\\",\\n        \\\"price\\\"\\n    ]\\n}\\n~~~\\n\\n| 关键字                       | 描述                                                         |\\n| ---------------------------- | ------------------------------------------------------------ |\\n| type                         | 类型                                                         |\\n| properties                   | 定义各个字段属性                                             |\\n| patternProperties            | 正则匹配定义各个字段属性                                     |\\n| required                     | 必须要有的属性                                               |\\n| minProperties(maxProperties) | 最小(大)属性个数                                             |\\n| additionalProperties         | 如果待校验JSON对象中存在，既没有在properties中被定义，又没有在patternProperties中被定义，那么这些一级key必须通过additionalProperties的校验 |\\n\\n#### 4.2 array\\n\\narray 有三个独立的属性：items、minItems、uniqueItems\\n\\n~~~json\\n{\\n  ......\\n  {\\n    \\\"type\\\": \\\"array\\\",\\n\\t  \\\"items\\\": [\\n      {\\n        \\\"type\\\": \\\"string\\\",\\n        \\\"minLength\\\": 5\\n      },\\n      {\\n        \\\"type\\\": \\\"number\\\",\\n        \\\"minimum\\\": 10\\n      }\\n    ],\\n    \\\"minItems\\\": 1,\\n    \\\"maxItems\\\": 5,\\n    \\\"uniqueItems\\\": true\\n  }\\n}\\n~~~\\n\\n| 关键字              | 描述                                                         |\\n| ------------------- | ------------------------------------------------------------ |\\n| items               | array每个元素的类型                                          |\\n| minItems & maxItems | 数组最小(大)的元素个数「省略minItems则为0, 省略maxItems则没有最大限制」 |\\n| uniqueItems         | 每个元素都不相同                                             |\\n\\n#### 4.3 integer & number\\n\\ninteger和number的区别，integer相当于Java中的int类型；而number相当于Java中的int或float类型，number 关键字可以描述任意长度，任意小数点的数字\\n\\n~~~json\\n{\\n  \\\"properties\\\": {\\n    \\\"price\\\": {\\n      \\\"type\\\": \\\"number\\\",\\n      \\\"multipleOf\\\": 0.5,\\n      \\\"maximum\\\": 12.5,\\n      \\\"exclusiveMaximum\\\": true,\\n      \\\"minimum\\\": 2.5,\\n      \\\"exclusiveMinimum\\\": true\\n    }\\n  }\\n}\\n~~~\\n\\n| 关键字                              | 描述                                                         |\\n| ----------------------------------- | ------------------------------------------------------------ |\\n| minimum / maximum                   | 最小(大)值                                                   |\\n| exclusiveMinimum / exclusiveMaximum | 存在且为 true，则必须小于(大于) minimum(maximum)的值；省略或为false，则必须<=(>=) inimum(maximum) 的值 |\\n| multpleOf                           | 必须是某个数的倍数，比如`multipleOf: 0.5` 则必须是0.5的倍数  |\\n\\n#### 4.4 string\\n\\n~~~json\\n{\\n  ……\\n  \\\"properties\\\": {\\n  \\t\\\"ip\\\": {\\n  \\t\\t\\\"type\\\": \\\"string\\\",\\n  \\t\\t\\\"pattern\\\": \\\"\\\"\\n\\t\\t}\\n\\t\\t\\\"host\\\": {\\n      \\\"type\\\": \\\"phoneNumber\\\",\\n      \\\"pattern\\\": \\\"\\\"\\n    }\\n\\t\\t\\\"email\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"format\\\": \\\"email\\\"\\n    }\\n\\t}\\n\\t……\\n}\\n~~~\\n\\n##### format 取值\\n\\n+ data-time\\n+ email\\n+ hostname\\n+ ipv4\\n+ ipv6\\n+ uri\\n+ uri-reference\\n+ Uri-template\\n+ json-pointer\\n\\n例如：如果待校验的JSON元素正好是一个邮箱地址，那么，我们就可以使用format关键字进行校验，而不必通过pattern关键字指定复杂的正则表达式进行校验\\n\\n#### 其他\\n\\n#### 4.5 enum\\n\\n该关键字的值是一个数组，该数组至少要有一个元素，且数组内的每一个元素都是唯一的\\n\\n如果待校验的JSON元素和数组中的某一个元素相同，则通过校验。否则，无法通过校验\\n\\n注意，该数组中的元素值可以是任何值，包括null\\n\\n~~~json\\n{\\n\\t\\\"properties\\\": {\\n    \\\"street_type\\\": {\\n      \\\"type\\\": \\\"string\\\",\\n      \\\"enum\\\": [\\n        \\\"Street\\\",\\n        \\\"Avenue\\\",\\n        \\\"Boulevard\\\"\\n      ]\\n    }\\n  }\\n}\\n~~~\\n\\n\\n\\n\\n\\n\\n\\n\\n___\\n\\n参考链接：\\n\\n[https://www.jianshu.com/p/1711f2f24dcf?utm_campaign=hugo](https://www.jianshu.com/p/1711f2f24dcf?utm_campaign=hugo)\\n\\n\",\"category\":\"Web开发\",\"createTime\":\"2021/04/08 21:33:00\"},{\"id\":\"1630743821768\",\"name\":\"XSS攻击\",\"title\":\"XSS攻击\",\"content\":\"\\n\\n### 1. 前言\\n\\nXSS全称 Cross Site Scripting，跨站脚本漏洞，通过执行恶意脚本，以实现窃取用户登录态、劫持会话等目的的攻击方式。恶意脚本的输入源有：Cookie、Post表的、Get请求、HTTP头内容等，通常将一段 XSS 攻击的代码称为**XSS向量**。主要原因是没有针对用户输入的数据进行检查、过滤。\\n\\n### 2. XSS类型\\n\\n+ **放射性XSS**：直接将 XSS 向量拼接在 URL 中，诱导用户点击，链接中所携带的参数会回显于页面中或者作为页面的处理数据源，最终造成XSS攻击\\n+ **存储型XSS**：通过表单，将 XSS 向量提交到数据库。当页面展示数据时，执行 XSS 向量\\n+ **DOM Based XSS：**通过修改浏览页面的 DOM ，绕过防御规则，执行恶意脚本，达到攻击目的\\n\\n### 3. XSS防范手段\\n\\n+ 前、后端穷举有限标签和属性，进行白名单过滤\\n    + 说明：前端要求用户仅能输入指定、有限的标签和属性。前端可以通过富文本编辑器配置仅显示指定标签，提升用户体验。后端不能信任前端数据，需要基于白名单再次过滤，保证入库的数据都是可信任的\\n    + 适用场景：简单富文本输入\\n\\n+ 后端转移存储，前端展示时，进行黑名单过滤\\n    + 说明：实际上普通用户不会输入 XSS 向量，而攻击者可以很轻松地直接发起API请求，所以前端不进行数据检查，后端完全不信任数据输入，直接将用户输入的数据转义入库，然后反转义输出，保证数据库中的内容是可信任的。展示数据时，前端对展示的内容进行基于黑名单的过滤\\n    + 使用场景：对输入标签范围不定，富文本编辑功能复杂\\n\\n### 4. Cookie HttpOnly\\n\\n大部分攻击者会想要获取到用户的cookie，所以我们需要在 http 的响应头 set-cookie 时设置 httponly，让浏览器知道不能通过document.cookie的方式获取到cookie内容\\n\\n### 5. 设置CSP\\n\\nCSP (Content Security Policy) 是用来防御 XSS 的安全策略\\n\\nCSP 通过白名单控制，仅允许加载指定的资源，包括 JavaScript、CSS、HTML、image、、video、Frames等\\n\\n#### 设置CSP的方式\\n\\n+ 设置 HTTP 头信息的 `Content-Security-Policy` 字段\\n+ 在网页添加 `<meta>` 标签\\n\\n#### 指令及说明\\n\\n+ `default-src`：定义资源默认加载策略\\n+ `connect-src`：定义 Ajax、WebSocket 等加载策略\\n+ `font-src`：定义 Font 加载策略\\n+ `frame-src`：定义 Frame 加载策略\\n+ `img-src`：定义图片加载策略\\n+ `media-src`：定义 audio、video等引用资源加载策略\\n+ `object-src`：定义 applet、embed、object 等引用资源加载策略\\n+ `script-src`： 定义 JS 加载策略\\n+ `style-src`：定义CSS 加载策略\\n\\n#### 配置CSP\\n\\n+ 只允许同源资源\\n\\n    ```shell\\n    Content-Security-Policy: default-src 'self';\\n    ```\\n\\n+ 允许同源以及指定地址的 JS 资源\\n\\n    ```shell\\n    Content-Security-Policy: script-src 'self' www.google-analytics.com ajax.googleapis.com;\\n    ```\\n\\n+ 多个资源时，后面的会覆盖前面的\\n\\n    ```shell\\n    Content-Security-Policy: default-src 'none'; script-src 'self'; connect-src 'self'; img-src 'self';\\n    ```\\n\\n    或者使用 meta\\n\\n    ```shell\\n    <meta http-equiv=\\\"Content-Security-Policy\\\" content=\\n        \\\"script-src 'self' *.qq.com *.cdn-go.cn; \\n        img-src 'self' *.cdn-go.cn *.gtimg.cn data:;\\n        style-src 'unsafe-inline' *.cdn-go.cn; \\n        media-src 'none'; \\n        child-src *.qq.com\\\">\\n    ```\\n\\n\\n\\n\\n\\n____\\n\\n[前端安全之防范XSS实战小结](https://segmentfault.com/a/1190000022678120)\\n\\n[如何预防 Web 富文本中的 XSS 攻击](https://www.chenshaowen.com/blog/how-to-prevent-xss-in-web-rich-text.html)\\n\\n\",\"category\":\"Web开发\",\"createTime\":\"2020/04/02 10:16:00\"},{\"id\":\"1604036912755\",\"name\":\"protobuf入门\",\"title\":\"protobuf\",\"content\":\"\\n\\nProtocol Buffer (简称Protobuf) 是Google出品的性能优异、跨语言、跨平台的序列化库。\\n\\n> 序列化(serialization、marshalling)的过程是指将数据结构或者对象的状态转换成可以存储(比如文件、内存)或者传输的格式(比如网络)。反向操作就是反序列化(deserialization、unmarshalling)的过程。\\n\\nProtobuf支持很多语言，比如C++、C#、Dart、Go、Java、Python、Rust等，同时也是跨平台的，所以得到了广泛的应用。\\n\\nProtobuf包含序列化格式的定义、各种语言的库以及一个IDL编译器。正常情况下你需要定义proto文件，然后使用IDL编译器编译成你需要的语言。\\n\\n### 1. 历史\\n\\n2001年初，Protobuf首先在Google内部创建， 我们把它称之为 `proto1`\\n\\n2008年7月7日，Protobuf开始公布出来，称为 `proto2`\\n\\n> Protobuf公布出来也得到了大家的广泛的关注， 逐步地也得到了大家的认可，很多项目也采用Protobuf进行消息的通讯，还有基于Protobuf的微服务框架GRPC。在使用的过程中，大家也提出了很多的意见和建议，Protobuf也在演化\\n\\n2016年推出了Proto3，Proto3简化了proto2的开发，提高了开发的效能，但是也带来了版本不兼容的问题。\\n\\n官方建议新项目采用proto3，老项目因为兼容性的问题继续使用proto2,并且会长时间的支持proto2。\\n\\n### 2. Proto3的改变\\n\\n- 移除了原始值字段的出现逻辑。\\n- 移除了`required`字段\\n- 移除了缺省值\\n- 移除了`unknown`字段 （3.5中又加上了）\\n- 移除了扩展，使用`Any`代替\\n- 修复了未知的枚举值的语义\\n- 添加了map类型\\n- 添加了一些标准类似，比如time、动态数据的呈现\\n- 可以使用JSON编码代替二进制proto编码\\n\\n### 3. 一个简单的例子\\n\\n```protobuf\\nsyntax = \\\"proto3\\\";\\n\\nmessage ListArticlesRequest {\\n\\tint64 page = 1;\\t\\t\\t// 页码\\n\\tint64 page_size = 2;\\t// 分页大小\\n}\\n\\nmessage ListArticlesResponse {\\n\\trepeated Article articles = 1;\\t// 文章列表\\n\\tint64 total_size = 2;\\t// 所有文章总数\\n}\\n\\nmessage Article {\\n\\tint64 id = 1;\\n\\tstring title = 2;\\n\\tstring content = 3;\\n}\\n```\\n\\n+ 第一行指定protobuf的版本，这里是以`proto3`格式定义\\n+ message类型会被protoc编译成不同的编程语言的相应对象，比如Java中的class、Go中的struct等\\n+ 字段格式：`[repeated] type fieldName = fieldNumber [[ fieldOptions ]];`\\n+ 编译生成代码：在当前的目录下执行`protoc -I=. -I /usr/local/include -I=$(GOPATH)/src --go_out=. simple.proto`, 可以将这个proto编译成Go的代码，因为这里我们使用了`go_out`输出格式\\n    + `-I` 指定protoc的搜索import的proto的文件夹。在`MacOS`操作系统中protobuf把一些扩展的proto放在了`/usr/local/include`对应的文件夹中，一些第三方的Go库放在了gopath对应的包下，所以这里都把它们加上了。对于这个简单的例子，实际是不需要的。\\n    + `go_out`用来生成Go代码，`cpp_out`用来生成C++代码，`java_out`产生Java代码，`python_out`产生python代码，类似地还有`csharp_out`、`objc_out`、`ruby_out`、`php_out`等参数\\n    + `--go_out=.` 指定代码生成后存放的路径\\n\\n### 4. 引入其他proto文件\\n\\n```protobuf\\nimport \\\"other.proto\\\";\\nimport public \\\"other2.proto\\\";\\nimport weak \\\"other.proto\\\";\\n```\\n\\n比较少使用的是`public`和`weak`关键字。默认情况下`weak`引入的文件允许不存在(missing)，只为了google内部使用。`public`具有传递性，如果你在文件中通过`public`引入第三方的proto文件，那么引入你这个文件同时也会引入第三方的proto。\\n\\n我们一般忽略`public`和`weak`关键字，这两个关键字也没有在规范中详细进行介绍。\\n\\n### 5. package\\n\\n定义proto的包名，包名可以避免对message 类型之间的名字冲突，同名的Message可以通过package进行区分。\\n\\n在没有为特定语言定义 `option xxx_package` 的时候，它还可以用来生成特定语言的包名，比如Java package, go package。\\n\\n```protobuf\\npackage foo.bar;\\n```\\n\\n### 6. option\\n\\noption可以用在proto的scope中，或者message、enum、service的定义中。\\n可以是Protobuf定义的option，或者自定义的option。\\n\\noption的定义格式是`\\\"option\\\" optionName \\\"=\\\" constant \\\";\\\"`\\n\\n比如设置各种语言的包名：\\n\\n```protobuf\\noption go_package = \\\"learnkratos/api/helloworld/v1;v1\\\";\\noption java_multiple_files = true;\\noption java_package = \\\"helloworld.v1.errors\\\";\\noption objc_class_prefix = \\\"APIHelloworldErrors\\\";\\n```\\n\\n\\n\\n一些Protobuf定义的option:\\n\\n- java_package\\n- java_multiple_files\\n- java_outer_classname\\n- optimize_for\\n- cc_enable_arenas\\n- objc_class_prefix\\n- deprecated\\n\\n### 7. 字段\\n\\n前面讲过，字段格式：`[repeated] type fieldName = fieldNumber [[ fieldOptions ]];`\\n\\n`repeated`允许字段重复，对于Go语言来说，它会编译成数组类型\\n\\n其中类型可以是以下几种类型：\\n\\n- 数字类型： double、float、int32、int64、uint32、uint64、sint32、sint64: 存储长度可变的浮点数、整数、无符号整数和有符号整数\\n- 存储固定大小的数字类型：fixed32、fixed64、sfixed32、sfixed64: 存储空间固定\\n- 布尔类型: bool\\n- 字符串: string\\n- bytes: 字节数组\\n- messageType: 消息类型\\n- enumType:枚举类型\\n\\n字段名、消息名、枚举类型名、map名、服务名等名称首字母必须是字母类型，然后可以是字母、数字或者下划线_\\n\\nproto类型和各语言的对应关系可以参考文档：[Scalar Value Types](https://developers.google.com/protocol-buffers/docs/proto3#scalar)\\n\\n同一个message的每个字段都有唯一一个编号，并且建议终生这个编号都不要改变。\\n\\n#### 7.1 oneof\\n\\n如果你有一组字段，同时最多允许这一组中的一个字段出现，就可以使用`Oneof`定义这一组字段\\n\\n比如请求用户队列，有个判断用户身份类型的字段，只能选择特定值中的一个\\n\\n```protobuf\\nsyntax = \\\"proto3\\\";\\npackage abc;\\nmessage ListArticlesRequest {\\n    oneof user_status {\\n      int64 normal = 1;\\n      int64 admin = 2;\\n    }\\n}\\n```\\n\\n#### 7.2 map\\n\\nmap类型需要设置键和值的类型，格式是 `map<keyType,valueType> mapName = fieldNumber [filedOptions]`\\n\\n比如：`map<int64,string> values = 1;`\\n\\n**map`字段不能同时使用`repeated**\\n\\n#### 7.3 Reserved\\n\\nReserved可以用来指明此message占位但不使用某些字段，也就是忽略这些字段，可以通过字段编号范围或者字段名称指定保留的字段\\n\\n```protobuf\\nsyntax = \\\"proto3\\\";\\npackage abc;\\nmessage AllNormalypes {\\n  reserved 2, 4 to 6;\\n  reserved \\\"field14\\\", \\\"field11\\\";\\n  double field1 = 1;\\n  // float field2 = 2;\\n  int32 field3 = 3;\\n  // int64 field4 = 4;\\n  // uint32 field5 = 5;\\n  // uint64 field6 = 6;\\n  sint32 field7 = 7;\\n  sint64 field8 = 8;\\n  fixed32 field9 = 9;\\n  fixed64 field10 = 10;\\n  // sfixed32 field11 = 11;\\n  sfixed64 field12 = 12;\\n  bool field13 = 13;\\n  // string field14 = 14;\\n  bytes field15 = 15;\\n}\\n```\\n\\n#### 7.4 枚举类型\\n\\n限定字段的值只能取某个特定的值，比如星期类型只能取周一到周日七个值\\n\\n注意枚举类型的定义采用C++ scoping规则，也就是枚举值是枚举类型的兄弟类型，而不是子类型，所以避免在同一个package定义重名的枚举字段。\\n\\n```protobuf\\nenum EnumAllowingAlias {\\n  option allow_alias = true;\\n  UNKNOWN = 0;\\n  STARTED = 1;\\n  RUNNING = 1;\\n}\\nenum EnumNotAllowingAlias {\\n  UNKNOWN2 = 0;\\n  STARTED2 = 1;\\n  // RUNNING = 1; \\n}\\n```\\n\\n**虽然产生的Go代码会给产生的类型加上前缀，但是proto的定义还是需要避免重名(把上面的STARTED2改成STARTED试试)。**\\n\\n如果设置`allow_alias`，允许字段编号重复，`RUNNING`是`STARTED`的别名。\\n\\n#### 7.5 其他类型\\n\\n可以使用其它message类型作为字段的类型值。因为前面在介绍字段的类型的时候说了，类型可以是消息类型和枚举类型，枚举类型如上所示，而消息类型如下所示：\\n\\n```protobuf\\nmessage SearchResponse {\\n  repeated Result results = 1;\\n}\\n\\nmessage Result {\\n  string url = 1;\\n  string title = 2;\\n  repeated string snippets = 3;\\n}\\n```\\n\\n如果要使用的类型在其它proto文件中定义，你需要使用`import`把对应的文件引入进来。\\n\\n#### 7.6 嵌套类型\\n\\n嵌套类型就是消息类型里面定义了消息类型:\\n\\n```protobuf\\nmessage SearchResponse {\\n  message Result {\\n    string url = 1;\\n    string title = 2;\\n    repeated string snippets = 3;\\n  }\\n  repeated Result results = 1;\\n}\\n```\\n\\n#### 7.7 Any\\n\\n`Any`字段允许你处理嵌套数据，并不需要它的proto定义。一个`Any`以bytes呈现序列化的消息，并且包含一个URL作为这个类型的唯一标识和元数据。\\n\\n为了使用`Any`类型，需要引入`google/protobuf/any.proto`\\n\\n```protobuf\\nimport \\\"google/protobuf/any.proto\\\";\\nmessage ErrorStatus {\\n  string message = 1;\\n  repeated google.protobuf.Any details = 2;\\n}\\n```\\n\\n### 8. 更新消息类型\\n\\n有时候不得不修改正在使用的proto文件，比如为类型增加一个字段，protobuf支持这种修改而不影响已有的服务，不过你需要遵循一定的规则：\\n\\n- 不要改变已有字段的字段编号\\n- 当你增加一个新的字段的时候，老系统序列化后的数据依然可以被你的新的格式所解析，只不过你需要处理新加字段的缺省值。 老系统也能解析你信息的值，新加字段只不过被丢弃了\\n- 字段也可以被移除，但是建议你Reserved这个字段，避免将来会使用这个字段\\n- int32, uint32, int64, uint64 和 bool类型都是兼容的\\n- sint32 和 sint64兼容，但是不和其它整数类型兼容\\n- string 和 bytes兼容，如果 bytes 是合法的UTF-8 bytes的话\\n- 嵌入类型和bytes兼容，如果bytes包含一个消息的编码版本的话\\n- fixed32和sfixed32, fixed64和sfixed64\\n- enum和int32, uint32, int64, uint64格式兼容\\n- 把单一一个值改变成一个新的oneof类型的一个成员是安全和二进制兼容的。把一组字段变成一个新的oneof字段也是安全的，如果你确保这一组字段最多只会设置一个。把一个字段移动到一个已存在的oneof字段是不安全的\\n\\n\",\"category\":\"Web开发\",\"createTime\":\"2021/10/11 15:00:00\"},{\"id\":\"1630743675831\",\"name\":\"socket\",\"title\":\"socket\",\"content\":\"\\n\\n### 1. socket概念\\n\\n![socket与应用层和运输层、网络层关系](https://static.mittacy.com/blog/20190718154523875.png)\\n\\nSocket是应用层与TCP/IP协议族通信的中间软件抽象层，它是一组接口。在设计模式中，Socket其实就是一个门面模式，它把复杂的TCP/IP协议族隐藏在Socket接口后面，对用户来说，一组简单的接口就是全部，让Socket去组织数据，以符合指定的协议。\\n\\n### 2. socket基本操作\\n\\n#### 2.1 socket()\\n\\nsocket(int domain, int type, int protocol)\\n\\n用于创建一个socket描述符（socket descriptor），它唯一标识一个socket\\n\\n+ domain **协议域**，协议族决定了socket的地址类型，在通信中必须采用对应的地址\\n\\n    常用的协议族有，AF_INET、AF_INET6、AF_LOCAL（或称AF_UNIX，Unix域socket）、AF_ROUTE等\\n\\n+ type **指定socket类型**，常用的有，SOCK_STREAM、SOCK_DGRAM、SOCK_RAW、SOCK_PACKET、SOCK_SEQPACKET等\\n\\n+ protocol **协议**，常用的协议有，IPPROTO_TCP、IPPTOTO_UDP、IPPROTO_SCTP、IPPROTO_TIPC等\\n\\n#### 2.3 bind()\\n\\nbind(int sockfd, const struct sockaddr *addr, socklen_t addrlen)\\n\\n把一个地址族中的特定地址赋给 socket\\n\\n+ sockfd socket描述字，通过socket()函数创建\\n\\n+ addr 指向要绑定给 sockfd 的协议地址，这个地址结果根据地址创建 socket 时的地址**协议族**的不同而不同\\n\\n    ~~~c\\n    // ipv4\\n    struct sockaddr_in {\\n      sa_family_t \\t\\tsin_family;\\n      in_port_t \\t\\t\\tsin_port;\\n      struct in_addr\\tsin_addr;\\n    };\\n    struct in_addr {\\n      uint32_t\\ts_addr;\\n    };\\n    // ipv6\\n    struct sockaddr_in6 { \\n        sa_family_t     sin6_family;    \\n        in_port_t       sin6_port;      \\n        uint32_t        sin6_flowinfo;  \\n        struct in6_addr sin6_addr;      \\n        uint32_t        sin6_scope_id;  \\n    };\\n    \\n    struct in6_addr { \\n        unsigned char   s6_addr[16];    \\n    };\\n    ~~~\\n\\n+ addrlen 地址的长度\\n\\n#### 2.4 listen()\\n\\nint listen(int sockfd, int backlog);\\n\\n如果作为一个服务器，在调用socket()、bind()之后就会调用listen()来监听这个socket\\n\\n+ sockfd socket描述字\\n+ backlog 相应socket可以排队的最大连接个数\\n\\n#### 2.5 accept()\\n\\n1. TCP服务器端依次调用socket()、bind()、listen()之后，就会监听指定的socket地址了\\n2. TCP客户端依次调用socket()、connect()之后就向TCP服务器发送了一个连接请求\\n3. TCP服务器监听到这个请求之后，就会调用accept()函数取接收请求，这样连接就建立好了\\n\\n~~~\\nint accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen);\\n~~~\\n\\n+ sockfd 服务器的socket描述字\\n+ addr 指向struct sockaddr *的指针，用于返回客户端的协议地址\\n+ addrlen 协议地址的长度\\n\\n如果accpet成功，那么其返回值是由内核自动生成的一个全新的描述字，代表与返回客户的TCP连接\\n\\n注意：accept的第一个参数为服务器的socket描述字，是服务器开始调用socket()函数生成的，称为监听socket描述字；而accept() 返回的事已连接的socket描述字。\\n\\n一个服务器通常仅仅只创建了一个已连接socket描述字，它在该服务器的生命周期内一直存在。内核为每个由服务器进程接收的客户连接创建了一个已连接socket描述字，当服务器完成了对某个客户的服务，相应的已连接socket描述字就关闭\\n\\n#### 2.6 connect()\\n\\n客户端调用connect()发出连接请求，服务器端就会接收到这个请求。\\n\\n~~~c\\nint connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen);\\n~~~\\n\\n+ sockfd 客户端socket描述字\\n+ *addr 服务器的scoket地址\\n+ addrlen socket地址的长度\\n\\n#### 2.7 read()/write()\\n\\n至此，服务器与客户已经建立好连接了。可以调用I/O进行读写操作了，即实现了网络中不同进程之间的通信\\n\\n网络I/O操作有：\\n\\n+ read()/write()\\n+ recv()/send()\\n+ readv()/writev()\\n+ recvmsg()/sendmsg()\\n+ recvfrom()/sendto()\\n\\n推荐使用`recvmsg()/sendmsg()`函数，这两个函数是最通用的I/O函数，实际上可以把上面的其它函数都替换成这两个函数\\n\\n函数声明如下：\\n\\n~~~c\\nssize_t read(int fd, void *buf, size_t count);\\nssize_t write(int fd, const void *buf, size_t count);\\n\\nssize_t recv(int sockfd, void *buf, size_t len, int flags);\\nssize_t send(int sockfd, const void *buf, size_t len, int flags);\\n\\nssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen);\\nssize_t sendto(int sockfd, const void *buf, size_t len, int flags, \\n\\t\\t\\t\\t\\t\\t\\t\\tconst struct sockaddr *dest_addr, socklen_t addrlen);\\n\\nssize_t recvmsg(int sockfd, struct msghdr *msg, int flags);\\nssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags);\\n~~~\\n\\nread函数是负责从fd中读取内容\\n\\n+ 当读成功时，read返回实际所读的字节数\\n+ 如果返回的值是0表示已经读到文件的结束了\\n+ 小于0表示出现了错误\\n    + 如果错误为EINTR说明读是由中断引起的\\n    + 如果是ECONNREST表示网络连接出了问题\\n\\nwrite函数将buf中的nbytes字节内容写入文件描述符fd\\n\\n+ 成功，返回写的字节数\\n+ 失败时返回-1，并设置errno变量\\n\\n在网络程序中，当我们向套接字文件描述符写时有俩种可能\\n\\n+ write的返回值大于0，表示写了部分或者是 全部的数据\\n+ 返回的值小于0，此时出现了错误\\n    + 如果错误为EINTR表示在写的时候出现了中断错误\\n    + 如果为EPIPE表示 网络连接出现了问题(对方已经关闭了连接)\\n\\n#### 2.8 close()\\n\\n在服务器与客户端建立连接之后，会进行一些读写操作，完成了读写操作就要关闭相应的socket描述字，好比操作完打开的文件要调用fclose关闭打开的文件\\n\\n```c\\nint close(int fd);\\n```\\n\\nclose一个TCP socket的缺省行为时把该socket标记为以关闭，然后立即返回到调用进程。该描述字不能再由调用进程使用，也就是说不能再作为read或write的第一个参数\\n\\n**注意：close操作只是使相应socket描述字的引用计数-1，只有当引用计数为0的时候，才会触发TCP客户端向服务器发送终止连接请求**\\n\\n### 3. tcp三次握手与socket\\n\\n![tcp三握手](https://static.mittacy.com/blog/Snipaste_2020-09-04_12-51-27.jpg)\\n\\n1. 客户端调用 connect()出发连接请求，向服务器发送了 SYN J包，connect 进入阻塞状态；\\n2. 服务器监听到连接请求，即受到 SYN J包，调用 accept() 接收请求向客户端发送 SYN K、ACK J+1，accpet() 进入阻塞状态；\\n3. 客户端受到服务器的 SYN K、ACK J+1后，这时 connect() 返回，并对 SYN K进行确认；\\n4. 服务器受到 ACK K+1时，accept() 返回，至此三次握手完毕，连接建立\\n\\n### 4. tcp四次挥手与scoket\\n\\n![四次挥手](https://static.mittacy.com/blog/Snipaste_2020-09-04_12-59-20.jpg)\\n\\n1. 某个应用进程首先条用 close() 主动关闭连接，这时 TCP 发送一个 FIN M；\\n2. 服务端接收到 FIN M 之后，执行被动关闭，对这个 FIN 进行确认。它的接收也作为文件结束符传递给应用进程，因为 FIN 的接收意味着应用进程在相应的连接上再也不用接收数据\\n3. 接收到文件结束符的应用 发送完剩余数据后，调用 close() 关闭它的 socket，发送一个 FIN N；\\n4. 接收到这个 FIN 的源发送端 TCP 对它进行确认\\n\\n\\n\\n\\n\\n___\\n\\n参考链接：\\n\\nhttps://blog.csdn.net/pashanhu6402/article/details/96428887\\n\\n\",\"category\":\"Web开发\",\"createTime\":\"2020/07/2 16:12:00\"},{\"id\":\"1632138536484\",\"name\":\"单点登录\",\"title\":\"sso单点登录实现\",\"content\":\"\\n\\n单点登录英文全称Single Sign On，简称就是SSO。它的解释是：**在多个应用系统中，只需要登录一次，就可以访问其他相互信任的应用系统**\\n\\n4个系统，分别是Application1、Application2、Application3、和SSO。Application1、Application2、Application3没有登录模块，而SSO只有登录模块，没有其他的业务模块\\n\\n当Application1、Application2、Application3需要登录时，将跳到SSO系统，SSO系统完成登录，其他的应用系统也就随之登录了。\\n\\n### 1. 同域下的单点登录\\n\\n一个企业一般情况下只有一个域名，通过二级域名区分不同的系统。比如我们有个域名叫做：mittacy.com，同时有两个业务系统分别为：app1.mittacy.com 和 app2.mittacy.com。\\n\\n我们要做单点登录（SSO）叫做：sso.mittacy.com，只要在 sso.mittacy.com 中登录，app1.mittacy.com 和 app2.mittacy.com 也就登录了\\n\\n在 sso.mittacy.com 中登录，其实是在 sso.mittacy.com 的服务端 session 中记录了登录状态，同时在浏览器端的 sso.mittacy.com 下写入 cookie，登录成功后，如果想让 app1.mittacy.com 和 app2.mittacy.com 随之登录，需要解决两个问题：\\n\\n+ cookie 是不能跨域的，cookie 的 domain 属性是 sso.mittacy.com，在给 app1.mittacy.com 和 app2.mittacy.com 发送请求时是带不上的\\n\\n  > *解决方案：登录 sso 系统后，将 cookie 设置为顶域(设置host)，即mittacy.com*\\n\\n+ sso、app1 和 app2 是不同的应用，它们的 session 存在自己的应用内，是不共享的\\n\\n  > *解决方案：共享 session 的方案，例如 Spring-Session、redis*\\n\\n同域下的单点登录就实现了，**但这还不是真正的单点登录。**\\n\\n### 2. 不同域下的单点登录\\n\\n同域下的单点登录巧用了 Cookie 顶域的特性，但是是不同域之间 cookie 是不共享的，怎么办？\\n\\n这时候需要看看 **CAS** 流程，该流程是单点登录的标志流程\\n\\n![sso-app1-login](http://static.mittacy.com/blog/202109171839579.png)\\n\\n1. 用户访问 `app1.mittacy.com`，aap1系统是需要登录的，但用户没有登录\\n2. 跳转到 `CAS Server`，即 sso 登录系统。sso系统也没有登录，弹出登录页\\n3. 填入用户、密码后，`sso系统进行认证，认证成功后<u>将登录状态写入 sso 的 session，浏览器中写入 sso 域下的 cookie</u>\\n4. `sso 系统`登录完成后会生成一个 `ST(Service Ticket)`，然后<u>跳转到 app1系统，同时将 ST 作为参数传递给app1系统</u>\\n5. `app1系统` 拿到 ST 后，<u>从后台向 sso 系统发送请求验证 ST 是否有效</u>\\n6. 验证通过后，`app1服务端`<u>将登录状态写入 session 并设置 app1 域下的 cookie</u>\\n\\n至此，单点登录就完成了。此时\\n\\n+ 浏览器中的 cookie有：sso域下的cookie、app1域下的cookie\\n+ 服务端session有：sso服务端的session、app1服务端的session\\n\\n以后再访问 app1 系统时，由于app1的cookie和session都有了，所以app1是可以直接登录成功的\\n\\n\\n\\n接下来我们访问 app2 系统的流程\\n\\n![sso-app2-login](http://static.mittacy.com/blog/202109171839031.png)\\n\\n1. 用户访问 app2.mittacy.com，app2系统是需要登录的，但用户没有登录\\n2. 跳转到 sso 登录系统，sso系统已经登录了\\n3. sso 生成 ST， 跳转到 app2 系统， ST 作为参数传递给 app2系统\\n4. app2 拿到 ST，后台访问 sso 验证 ST 有效性\\n5. 验证成功后，app2服务端 将登录状态写入 session并设置 app2域下的 cookie\\n\\n\\n\\n\\n\\n___\\n\\n参考链接\\n\\nhttps://developer.aliyun.com/article/636281\\n\\n\",\"category\":\"Web开发\",\"createTime\":\"2021/09/17 18:41:00\"},{\"id\":\"1630743675832\",\"name\":\"跨域请求\",\"title\":\"跨域请求\",\"content\":\"\\n\\n**跨域请求**：当前发起请求的域与该请求指向的资源所在的域不一样\\n\\n(域：认为若协议 + 域名 + 端口号均相同就是同域)\\n\\n比如我的博客blog.mittacy.com, 发起了blog.mittacy.com/api/admin的Ajax请求，这个请求就是同域的；\\n\\n相反，如果发起了www.baidu.com/....的请求就是跨域请求\\n\\n### 1.跨域安全问题\\n\\n​\\t大多数浏览器都会跨域请求作出限制，这是从浏览器层面上的一种安全防御\\n\\n#### CSRF攻击\\n\\n​\\tCSRF(Cross-site request forgery) 跨站请求伪造\\n\\n​\\t可以这么理解CSRF攻击：**攻击者盗用了你的身份，以你的名义发送恶意请求**。CSRF能够做的事情包括：以你名义发送邮件，发消息，盗取你的账号，甚至于购买商品，虚拟货币转账......造成的问题包括：个人隐私泄露以及财产安全\\n\\n**原理**\\n\\n​\\t有两个网站，其中A网站是真实受信任的网站，而B网站是危险网站\\n\\n​\\t在用户登陆了受信任的A网站时，本地会存储A网站相关的Cookie，并且浏览器也维护这一个Session会话。这时，如果用户在没有登出A网站的情况下访问危险网站B，那么危险网站B就可以模拟发出一个对A网站的请求（跨域请求）对A网站进行操作，而在A网站的角度来看是并不知道请求是由B网站发出来的（Session和Cookie均为A网站的），这时便成功发动一次CSRF 攻击。\\n\\n### 2.同源策略\\n\\n**同源**：域名、协议、端口有一个不同就不是同源，三者均相同，这两个网站才是同源\\n\\n支持JavaScript的浏览器都使用同源策略\\n\\n+ 禁止Ajax直接发起跨域http请求(实际上发送了请求，只是结果被浏览器拦截)\\n+ Ajax请求不能携带与本站不同源的Cookie\\n+ `<img><iframe><link><video><audio>`等带有src属性的标签可以从不同的域加载和执行资源\\n+ `flash、java applet、silverlight、googlegears`等浏览器加载的第三方插件也有各自的同源策略，只是这些同源策略不属于浏览器原生的同源策略，如果有漏洞则可能被黑客利用，从而留下XSS攻击的后患\\n\\n### 3.如何跨域\\n\\n虽然在安全层面上同源限制是必要的，但有时同源策略会对我们的合理用途造成影响，有多种方式可以绕开同源策略\\n\\n#### 3.1 JSONP\\n\\n​\\tJSONP 是一种非官方的跨域数据交互协议，本质上是利用 `<img><iframe>` 等标签不受同源策略限制，可以从不同域加载并执行资源的特性，来实现数据跨域传输\\n\\n​\\tJSONP由两部分组成：回调函数和数据。\\n\\n\\t+\\t回调函数是当响应到来时应该在页面中调用的函数\\n\\t+\\t数据就是传入回调函数中的JSON数据\\n\\n过程：\\n\\n① 与服务端约定好一个回调函数名\\n\\n② 服务端接收到请求后，将返回一段 Javascript，在这段  Javascript 代码中调用了约定好的回调函数，并且将数据作为参数进行传递。\\n\\n③ 当网页接收到这段 Javascript 代码后，就会执行这个回调函数，这时数据已经成功传输到客户端了。\\n\\n#### 3.2 CORS\\n\\n​\\tCORS(Cross-Origin Resource Sharing) 是一个新的 W3C 标准，它新增了一组HTTP首部字段，允许服务端其声明哪些源站有权限访问哪些资源。它允许浏览器向声明了 CORS 的跨域服务器，发出 XMLHttpReuest 请求，从而克服 Ajax 只能同源使用的限制。\\n\\n​\\t对于非简单请求(如POST)，流览器必须首先使用 OPTION 方法发起一个预检请求(preflight request)，从而获知服务端是否允许该跨域请求，在服务器确定允许后，才发起实际的HTTP请求。\\n\\n**CORS新增首部字段**\\n\\n+ Access-Control-Allow-Origin 响应首部中可以携带这个头部表示服务器允许哪些域可以访问该资源\\n\\n    + ```jsx\\n        Access-Control-Allow-Origin: <origin> | *\\n        ```\\n\\n    + origin 参数的值指定了允许访问该资源的外域 URI\\n\\n+ Access-Control-Allow-Methods 该首部字段用于预检请求的响应，指明实际请求所允许使用的HTTP方法\\n\\n+ Access-Control-Allow-Headers 该首部字段用于预检请求的响应。指明了实际请求中允许携带的首部字段。\\n\\n+ Access-Control-Max-Age 该首部字段用于预检请求的响应，指定了预检请求能够被缓存多久\\n\\n+ Access-Control-Allow-Credentials 该字段可选。它的值是一个布尔值，表示是否允许发送Cookie，默认允许\\n\\n+ Origin 该首部字段表明预检请求或实际请求的源站。不管是否为跨域请求，Origin字段总是被发送\\n\\n+ Access-Control-Request-Method 该首部字段用于预检请求。其作用是，将实际请求所使用的 HTTP 方法告诉服务器。\\n\\n+ Access-Control-Request-Headers 该首部字段用于预检请求。其作用是，将实际请求所携带的首部字段告诉服务器。\\n\\n**优点**：支持所有类型的 HTTP 请求，可以是使用普通的 XMLHttpRequest 发起请求和获取数据，比起 JSONP 有更好的错误处理\\n\\n**缺点**：一些比较老的浏览器不支持\\n\\n\\n\\n___\\n\\n[什么是跨域请求以及实现跨域的方案](https://www.jianshu.com/p/f880878c1398)\\n\\n\",\"category\":\"Web开发\",\"createTime\":\"2020/01/12 12:16:00\"},{\"id\":\"1630739392756\",\"name\":\"Mac重装系统\",\"title\":\"Mac重装系统\",\"content\":\"\\n\\n## 准备\\n\\n**注意，Mac一般没有分盘分区，重装系统就会全部格式化，所以数据必须都备份到U盘或其他电脑**\\n\\n+ 大于8gU盘\\n+ MacOS系统镜像：<http://www.pc6.com/pc/OSxtjx/>\\n\\n## 一. 下载\\n\\napp store或者其他可信任网站下载系统镜像，解压将app文件放入应用中(app store下载的就在应用中了)\\n\\n## 二. 重装盘制作\\n\\n1. 格式化U盘\\n\\n    +\\t`command`+`空格`打开搜索工具输入“磁盘工具”打开磁盘工具\\n    +\\t![](https://static.mittacy.com/blog/20200228125424.jpeg)\\n    +\\t![](https://static.mittacy.com/blog/20200228125541.jpeg)\\n\\n    \\n\\n2. 打开终端根据要安装的系统包选择相应的命令(文末有多种版本命令)，比如我要安装的是Mojave，所以我输入\\n\\n`sudo /Applications/Install\\\\ macOS\\\\ Mojave.app/Contents/Resources/createinstallmedia --volume /Volumes/mine`\\n\\n**注意mine是U盘的名字**\\n\\n回车输入密码，注意这里输入密码不会显示被隐藏了，只管输入后回车就好了\\n\\n等待完成\\n\\n![](https://static.mittacy.com/blog/20200228130352.png)\\n\\n到这里系统U盘制作完成\\n\\n## 三. 开始重装\\n\\n+ 关机状态下插入系统U盘，同时安装`option`&`开机`键\\n\\n+ 选择第二个系统U盘启动\\n\\n    ![](https://static.mittacy.com/blog/20200229002559.jpeg)\\n\\n+ 进入磁盘工具抹除原系统\\n\\n    ![](https://static.mittacy.com/blog/20200229003133.jpeg)\\n\\n    ![](https://static.mittacy.com/blog/20200229003144.jpeg)\\n\\n+ 出来一直下一步到选择系统盘为安装盘\\n\\n    ![](https://static.mittacy.com/blog/20200229003254.jpeg)\\n\\n    ![](https://static.mittacy.com/blog/20200229003332.jpeg)\\n\\n    一直下一步然后就交给电脑自己安装了，坐一会儿出现这个画面就表示安装成功\\n\\n    ![](https://static.mittacy.com/blog/20200229003429.jpeg)\\n\\n    接下来自己认证设置一遍吧!\\n\\n## 不同系统版本重装命令\\n\\n### Catalina\\n\\n```\\nsudo /Applications/Install\\\\ macOS\\\\ Catalina.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume\\n```\\n\\n以后在使用Catalina提示文件损坏无法打开的解决方法：\\n\\n终端`sudo xattr -d com.apple.quarantine` 拉入应用回车输入密码\\n\\n重新打开一般就可以打开了\\n\\n### Mojave\\n\\n~~~\\nsudo /Applications/Install\\\\ macOS\\\\ Mojave.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume\\n~~~\\n\\n### High Sierra\\n\\n~~~\\nsudo /Applications/Install\\\\ macOS\\\\ High\\\\ Sierra.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume\\n~~~\\n\\n### Sierra\\n\\n```\\nsudo /Applications/Install\\\\ macOS\\\\ Sierra.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume --applicationpath /Applications/Install\\\\ macOS\\\\ Sierra.app\\n```\\n\\n### El Capitan\\n\\n~~~\\nsudo /Applications/Install\\\\ OS\\\\ X\\\\ El\\\\ Capitan.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume --applicationpath /Applications/Install\\\\ OS\\\\ X\\\\ El\\\\ Capitan.ap\\n~~~\",\"category\":\"三脚猫功夫\",\"createTime\":\"2021/04/08 21:16:00\"},{\"id\":\"1630739392757\",\"name\":\"Windowns重装系统\",\"title\":\"Windows重装系统\",\"content\":\"\\n\\n### 准备\\n\\n+ 备份数据到其他U盘或其他电脑\\n+ 一个没有数据的8g以上U盘\\n+ md5校验工具: <https://pan.baidu.com/s/1neMDkyEg0tHlWmwtG2k7BQ>     密码:1zi6\\n\\n+ UltraISO刻录工具: <https://cn.ultraiso.net/xiazai.html>\\n+ ISO系统镜像: <https://msdn.itellyou.cn/>\\n\\n个人建议重装系统嘛，就是全部重来要清除所有冗余的数据，所以建议把需要的数据都备份到U盘或者其他电脑，然后重装系统的时候整个电脑格式化，装完系统后就很干净了，然后再把备份的数据转进去\\n\\n### 1.查看处理器\\n\\n**64位处理器可以安装32位和64位操作系统，但是一般安装64位系统，性能更好**\\n\\n**32位处理器只能安装32位操作系统**\\n\\n查看电脑处理器是否支持64，还是只能32位：在`我的电脑`右键点击`属性`\\n\\n![0](https://static.mittacy.com/blog%2Fwindow.jpeg)\\n\\n+\\t如果此处为64位，那么处理器便支持64位操作系统\\n+\\t如果为32位，不一定就只能支持32位操作系统，有可能之前安装了32位的系统, [点击查看是否支持64位](http://www.xitongcheng.com/jiaocheng/xtazjc_article_14486.html)\\n\\n### 2. 下载系统\\n\\n[点击MSDN](https://msdn.itellyou.cn/)下载需要的系统\\n\\n![1](https://static.mittacy.com/blog%2Fwindow1.jpeg)\\n\\n![2](https://static.mittacy.com/blog%2Fwindow3.jpeg)\\n\\n下载HashMyFiles(链接在文章开头)，将下载好的hashmyfiles解压\\n\\n![4](https://static.mittacy.com/blog%2Fwindow4.png)\\n\\n打开hashmyfiles检验md5是否正确\\n\\n将下载的ISO镜像拉入HashMyFiles窗口\\n\\n![5](https://static.mittacy.com/blog%2Fwindow5.png)\\n\\n等待进度走完对比SHA1是否正确\\n\\n![6](https://static.mittacy.com/blog%2Fwindow6.png)\\n\\n### 3. 制作系统盘\\n\\n点击下载刻录工具\\n\\n打开UltraISO，点击继续试用\\n\\n1. 选择`文件`->`打开`, 打开下载好的系统ISO文件\\n\\n2. 插入准备好的U盘\\n\\n3. 选择`启动` -> `写入硬盘映像`\\n\\n![7](https://static.mittacy.com/blog%2Fwindow7.png)\\n\\n点击写入等进度条完成就制作完成了\\n\\n![9](https://static.mittacy.com/blog%2Fwindow9.png)\\n\\n### 4. 如何进入U盘启动\\n\\n不同品牌电脑不一样，有些需要进入BIOS设置，有些直接可以开机选择启动\\n\\n自行百度: 比如\\\"联想u盘启动\\\"\\n\\n我的古董联想开机出现开机画面狂戳F12就可以选择U盘启动了\\n\\n![](https://static.mittacy.com/blog/20200225210106.jpeg)\\n\\n有时候电脑开机太快来不及反应按键，可能是打开了快速启动, 把它关了\\n\\n相应的，安装完系统可以到这里把它打开有助于快速开机\\n\\n![8](https://static.mittacy.com/blog%2Fwindow8.jpeg)\\n\\n### 5. 开始重装系统\\n\\n进入U盘启动后\\n\\n#### 5.1 普通设置\\n\\n![](https://static.mittacy.com/blog/20200225210359.jpeg)\\n\\n**直接跳过，安装完再弄**\\n\\n![](https://static.mittacy.com/blog/20200225210413.jpeg)\\n\\n这里选择需要的版本，我选择了专业版\\n\\n![](https://static.mittacy.com/blog/20200225210420.jpeg)\\n\\n下面的我选择自定义然后将服务都取消了进入下一步\\n\\n![](https://static.mittacy.com/blog/20200225210429.jpeg)\\n\\n#### 5.2 硬盘分区\\n\\n![](https://static.mittacy.com/blog/20200225211153.jpeg)\\n\\n+ 不需要重新分区，分别选中驱动器0每个分区然后点击格式化\\n+ 需要重新分区，把我的电脑硬盘即驱动器0每个分区分别选中并点击删除，然后重新分区\\n\\n![](https://static.mittacy.com/blog/20200225211809.jpeg)\\n\\n选中驱动器0，然后点击新建依次建立分区\\n\\n我的建议是：系统盘50g，软件盘30g(如果硬盘比较大就50g以上)，其他一个盘放文件\\n\\n分区完成点击下一步\\n\\n![](https://static.mittacy.com/blog/20200225212021.jpeg)\\n\\n#### 5.3 最后设置\\n\\n完成以上后等一会儿进入下面画面进入最后设置\\n\\n![](https://static.mittacy.com/blog/20200225212225.jpeg)\\n\\n后面的设置自己设置好经过一两次重启就大功告成了来到了主界面\\n\\n![](https://static.mittacy.com/blog/20200225212338.jpeg)\\n\\n咦？空空如也，干净得太干净了吧？莫急，接着往下设置\\n\\n### 6. 设置系统\\n\\n又到了下载东西的时候了，因为太过干净连解压工具都没有\\n\\n+ 解压工具WinRar:  <http://www.winrar.com.cn/>\\n+ 激活工具:  <https://pan.baidu.com/s/11LyE0NOvE6D0NY0YSwJzyw> 提取码: 9wph\\n\\n#### 6.1 解压工具\\n\\n下载好WinRar直接安装就可以了\\n\\n#### 6.2 激活工具\\n\\n下载好激活工具，解压安装，记住安装的位置，比如我安装在了D盘下的`Program Files`下\\n\\n![](https://static.mittacy.com/blog/20200225213138.jpeg)\\n\\n右键`KMSELDI`程序选择`以管理员方式启动`\\n\\n![](https://static.mittacy.com/blog/20200225213410.png)\\n\\n#### 6.3 系统设置\\n\\n![](https://static.mittacy.com/blog/20200225213534.jpeg)\\n\\n![](https://static.mittacy.com/blog/20200225213614.png)\\n\\n以上就打开了桌面的图标了，然后**自己通读系统每一个设置选项设置好电脑**\\n\\n### 7. 管理\\n\\n1. **不下载**任何杀毒软件不用填补漏洞\\n2. **不安装**应用在系统盘即C盘(除了有些应用没法选择例如PS)\\n3. D盘下新建`Program Files`文件夹用来**安装应用**，例如\\n\\n![](https://static.mittacy.com/blog/20200225214100.png)\\n\\n4. [点击关闭Windows自动更新](https://www.cnblogs.com/taiyonghai/p/10489105.html)，安不安全我不敢说，方正用着舒服多了(滑稽.jpg)\\n\\n\",\"category\":\"三脚猫功夫\",\"createTime\":\"2021/03/18 18:00:00\"},{\"id\":\"1630741683837\",\"name\":\"密码加密存储\",\"title\":\"密码加密存储\",\"content\":\"\\n\\n2011年12月，[密码外泄门](https://baike.baidu.com/item/%E5%AF%86%E7%A0%81%E5%A4%96%E6%B3%84%E9%97%A8/4976608?fr=aladdin) 造成了CSDN 2010年9月之前600多万明文帐号数据泄露，对用户账号造成了威胁。\\n\\nCSDN发布声明：\\n\\n> 我们非常抱歉，发生了CSDN用户数据库泄露事件，您的用户密码可能被公开。我们恳切地请您修改CSDN相关密码，如果您在其他网站也使用同一密码。请一定同时修改相关网站的密码。\\n>\\n> CSDN已向公安机关正式报案，公安机关也正在调查相关线索。\\n>\\n> 再次向您致以深深的歉意！\\n\\n可见，明文存储密码是很危险的，我们应该对用户的密码进行加密存储，并且这个加密过程是不可逆的！\\n\\n### 1. 用户注册和登录验证\\n\\n密码加密不可逆后，又要怎么验证用户登录时输入的密码正确性呢？\\n\\n我们以用户注册和登录验证为例，讲讲密码加密后如何进行密码正确性验证。\\n\\n#### 1.1 注册过程\\n\\n以下过程省略<u>用户名验证</u>和<u>密码复杂度限制</u>等\\n\\n1. 前端首先对用户密码进行固定规则加密，生成加密字符串作为密码\\n2. 后端接收前端创建用户请求，解析得到用户数据 `{username: 'mittacy', password: '加密字符串'}`\\n3. 采用某种加密算法再次进行加密，得到一串的字符串 `5e884898da28047151d0e56f8dc62`\\n4. 将 `{username: 'mittacy', password: '5e884898da28047151d0e56f8dc62'}` 插入数据库，返回注册成功\\n\\n#### 1.2 登录过程\\n\\n1. 前端首先采用注册时同样的加密规则对用户密码加密，生成加密字符串作为密码\\n2. 后端接收前端用户登录请求，解析得到用户数据 `{username: 'mittacy', password: '加密字符串'}`\\n3. 通过 `username` 到数据库查询得到正确的加密密码字符串，记为 `password`\\n4. 采用注册过程中的加密算法对密码进行加密，得到一串的字符串 `5e884898da28047151d0e56f8dc62`，记为requestPassword\\n5. 对比`requestPassword` 和 `password` ，相同返回 登录成功，否则返回 登录失败\\n\\n可以看到，我们存储的密码是加密后的字符串，并且不可逆，即使数据库泄露，攻击者也只能拿到这些加密后的字符串，几乎无法反推真正的密码，更加安全，只要及时修改密码即可。\\n\\n那我们应该采用哪种加密算法呢？首先明确要求：\\n\\n+ 同一个密码 使用算法加密后 产生的字符串始终都是一样的\\n+ 不同密码 使用算法加密后 的字符要尽可能的不同(理论上没法确保一定不同)\\n+ 不可逆的，不能从加密字符串倒推出密码\\n\\n### 2. 加密算法分类\\n\\n+ `对称加密算法`\\t加密解密都是用同一个密钥，有AES、DES等\\n+ `非对称加密算法` 加密解密使用不同的密钥：公钥和私钥，最有名的就是RSA\\n+ `单向Hash算法` 主要用于验证，防止信息被修改，有 MD5、SHA1、SHA256、SHA512等\\n\\n对称加密和非对称加密都不符合我们的要求，因为数据库泄露了，密钥也很有可能泄露，这两种算法都能解密获取原密码。\\n\\n单向Hash算法，比如MD5，无法通过计算还原出原始密码，而且两个字符串就算只是相差一个字符，计算出来的加密字符串也大不相同，重合率较低，所以很适合用来加密用户密码\\n\\n关于MD5原理，有一篇有趣的文章可以看看 [漫画趣解MD5](https://www.tomorrow.wiki/archives/503)\\n\\n以为这样子就可以安枕无忧了吗？当然不是。\\n\\n### 3. 彩虹表攻击\\n\\n彩虹表原理：[高效的密码攻击方法：彩虹表](https://blog.csdn.net/whatday/article/details/88527936/)\\n\\n### 4. 防御彩虹表\\n\\n#### 4.1 客户端\\n\\n禁止使用简单的密码\\n\\n#### 4.2 服务端\\n\\n+ 使用更好的Hash算法\\n\\n    生成的字符串越长攻击者越难破解，但相应的计算速度越慢\\n\\n    下面是几种常用的单向Hash算法的对比\\n\\n    | 哈希   | 长度(bit) | 数据库长度(byte) |\\n    | ------ | --------- | ---------------- |\\n    | md5    | 128       | 16               |\\n    | sha1   | 160       | 20               |\\n    | sha256 | 256       | 32               |\\n    | sha512 | 512       | 64               |\\n\\n+ 加盐\\n\\n    我们在收到用户注册的密码时，可以用一定的规则将密码和盐拼接组成新的密码串，再通过算法加密生成字符串存入数据库\\n\\n    随机盐使得彩虹表的建表难度大幅增加，随机盐的长度一般不能少于8字节\\n\\n\",\"category\":\"业务设计\",\"createTime\":\"2020/04/10 18:25:00\",\"banner\":\"http://static.mittacy.com/blog/202109041547534.jpg\"},{\"id\":\"1630140182576\",\"name\":\"接口的幂等性\",\"title\":\"接口的幂等性\",\"content\":\"\\n\\n## 概念\\n\\n不知道你有没有遇到过这些场景：\\n\\n+ 有时我们在填写表单时，保存按钮不小心快速点击了两次，表中竟然产生了两条重复的数据，只是id不一样\\n+ 在项目中为了解决 **接口超时** 问题，通常会引入 **重试机制**。对于成功的请求响应没能返回成功，导致请求方重复请求，出现重复数据\\n+ mq消费者在读取消息时，处理不当会读取到 **重复消息**，如果处理不好，也会产生重复的数据\\n\\n以上这些都是幂等性问题\\n\\n**接口幂等性** 是指用户对于同一个操作发起的一次请求或者多次请求的结果是一致的，不会因为多次点击而产生副作用\\n\\n> 在这里顺便说一下，`防重设计` 和 `幂等设计`，其实是有区别的。防重设计主要为了避免产生重复数据，对接口返回没有太多要求。而幂等设计除了避免产生重复数据之外，还要求每次请求都返回一样的结果。\\n\\n+ insert 操作，这种情况下多次请求，可能会产生重复数据\\n+ update 操作，如果只是单纯的更新数据一般没有问题，如果还涉及到运算和时间，比如 `update user set status=status+1 where id = 1;` 这种情况下多次请求，可能会导致数据错误\\n\\n## 解决方案\\n\\n### 1. insert 前先 select\\n\\n在保存数据的接口中，先根据 `name` 或 `code` 等 **select** 数据，如果数据已存在，则执行 `update` 操作，如果不存在，才执行 **insert** 操作\\n\\n该方案可能是我们平时在防止产生重复数据时，使用最多的方案。但是该方案不适用于并发场景，在并发场景中，要配合其他方案一起使用，否则同样会产生重复数据。\\n\\n### 2. 加悲观锁\\n\\n加悲观锁，在同一时刻只允许一个请求获得锁，更新数据，其他的请求则等待。\\n\\n```mysql\\nselect * from user id=123 for update;\\n```\\n\\n### 3. 加乐观锁\\n\\n在表中增加一个`timestamp`或者`version`字段，这里以`version`字段为例\\n\\n在更新数据之前先查询一下数据：\\n\\n```sql\\nselect id, amount, version from user id=123;\\n```\\n\\n如果数据存在，假设查到的 `version` 等于 `1`，再使用 `id` 和 `version` 字段作为查询条件更新数据：\\n\\n```sql\\nupdate user set amount = amount+100, version = version+1 where id = 123 and version = 1;\\n```\\n\\n第一次请求`version`等于`1`是可以成功的，操作成功后`version`变成`2`了，如果并发的请求过来，再执行相同的sql，会发现 version=1 没有匹配的，该`update`操作不会真正更新数据，但为了保证接口幂等性，接口可以直接返回成功。\\n\\n### 4. 加唯一索引\\n\\n绝大数情况下，为了防止重复数据的产生，我们都会在表中加唯一索引，这是一个非常简单，并且有效的方案。\\n\\n加了唯一索引之后，第一次请求数据可以插入成功。但后面的相同请求，插入数据时会报`Duplicate entry '002' for key 'order.un_code`异常，表示唯一索引有冲突，为了保证接口幂等性，我们需要对该异常进行捕获，然后返回成功。\\n\\n### 5. 建防重表\\n\\n有时候表中并非所有的场景都不允许产生重复的数据，只有某些特定场景才不允许，这时候就不能通过在表中直接加唯一索引，显然是不太合适的，针对这种情况可以 `建防重表` 来解决。\\n\\n该表可以只包含两个字段：`id` 和 `唯一索引`，唯一索引可以使多个字段组成的唯一标识\\n\\n> 需要特别注意的是：防重表和业务表必须在同一个数据库中，并且业务表和防重表的操作要在同一个事务中\\n\\n### 6. 状态机\\n\\n很多时候业务表是有状态的，比如订单表中有：1-下单、2-已支付、3-完成、4-撤销等状态，这些状态的值是有规律的，按照业务节点正好是从小到大，我们就能通过它来保证接口的幂等性。\\n\\n假如id=123的订单状态是`已支付`，现在要变成`完成`状态：\\n\\n```sql\\n> update `order` set status=3 where id=123 and status=2;\\n```\\n\\n第一次请求时，该订单的状态是`已支付`，值是`2`，所以该`update`语句可以正常更新数据，后面有相同的请求过来，再执行相同的sql时，由于订单状态变成了`3`，再用`status=2`作为条件，无法查询出需要更新的数据，所以最终sql执行结果的影响行数是`0`，为了保证接口幂等性，影响行数是`0`时，接口也可以直接返回成功。\\n\\n> 主要特别注意的是，该方案仅限于要更新的`表有状态字段`，并且刚好要更新`状态字段`的这种特殊情况，并非所有场景都适用\\n\\n### 7. 加分布式锁\\n\\n前面介绍过的 `加唯一索引` 或者 `加防重表`，本质是使用了数据库的分布式锁，也属于分布式锁。但由于数据库分布式锁的性能不太好，可以改用 `redis`\\n\\n主要有三种方式实现redis的分布式锁：\\n\\n+ setNx命令\\n+ set命令\\n+ Redission框架\\n\\n具体步骤：\\n\\n1. 用户通过浏览器发起请求，服务端会收集数据，并且生成订单号code作为唯一业务字段\\n2. 使用redis的set命令，将该订单code设置到redis中，同时设置超时时间\\n3. 判断是否设置成功，如果设置成功，说明是第一次请求，则进行数据操作\\n4. 如果设置失败，说明是重复请求，则直接返回成功\\n\\n\\n\\n\\n\\n___\\n\\n[高并发下如何保证接口的幂等性](https://mp.weixin.qq.com/s/09CKM9wTMWnbtVgoM9_p2w)\",\"category\":\"业务设计\",\"createTime\":\"2021/08/20 20:00:00\",\"banner\":\"http://static.mittacy.com/blog/202109041440103.jpg\"},{\"id\":\"1630741894533\",\"name\":\"目录实现\",\"title\":\"目录存储设计\",\"content\":\"\\n\\n### 1. 记录父类\\n\\n#### 存储结构\\n\\n| id   | name | parent |\\n| ---- | ---- | ------ |\\n| 1    | 文具 | 0      |\\n| 2    | 笔   | 1      |\\n| 3    | 铅笔 | 2      |\\n| 4    | 钢笔 | 2      |\\n\\n文具包含了笔，笔包含了铅笔和钢笔。这种方案简单易懂，仅存在一张表，并且没有冗余字段，存储空间占用极小，在数据库层面是一种很好的设计。\\n\\n#### 数据操作\\n\\n+ 移动：修改父节点id即可，子节点跟随该节点到新的位置\\n\\n+ 删：删除节点，需要同时删除节点下的所有子节点\\n\\n+ 查：\\n\\n    + 查询文具的所有下一层分类\\n\\n        `select id, name from table where parent = 1;`\\n\\n    + 查询文具的所有下层分类，先查出直属下级（笔），才能够往下查询，这意味着需要递归\\n\\n#### 优缺点\\n\\n+ 优点：结构简单，增删改快\\n+ 缺点：查询所有下级慢\\n\\n### 2. 路径列表\\n\\n#### 存储结构\\n\\n在第一种方法 **记录父类** 中仅仅存储了直属父类，而需求却要查询出非直属下级。针对这一点，我们的表中不仅仅记录父节点id，而是将它到顶级分类之间所有分类的id都保存下来。这个字段所保存的信息就像文件树里的路径一样，所以就叫做path\\n\\n| id   | name | path |\\n| ---- | ---- | ---- |\\n| 1    | 文具 |      |\\n| 2    | 笔   | 1    |\\n| 3    | 铅笔 | 1,2  |\\n| 4    | 钢笔 | 1,2  |\\n| 6    | 其他 |      |\\n\\n#### 数据操作\\n\\n+ 增：path为父类的`path`加上父类的id\\n\\n    比如在笔中添加圆珠笔：`insert into table (name, path) values (圆珠笔, '1,2');`\\n\\n+ 移动：将分类及其所有子分类的`path`设为其父类的`path`并在最后追加父类的id\\n\\n    比如将`笔`移动到`其他`，需要将笔、铅笔、钢笔的path中的1都依次修改为6\\n\\n    如果使用mysql来操作较为复杂，建议先查询，在业务层进行修改，再更新\\n\\n+ 删：使用模糊查询匹配所有子类并删除\\n\\n+ 查：\\n\\n    + 查询笔的所有下一层分类\\n\\n        `select * from table where path = '1,2';`\\n\\n    + 查询文具的所有下层分类\\n\\n        `select * from table where path like '1,%';`\\n\\n#### 优缺点\\n\\n+ 优点：增删改慢，只要在path建立索引查询很快，模糊查询可以用到path索引\\n+ 缺点\\n    + 不遵守数据库范式，将列表数据直接作为字符串来存储\\n    + 字段长度是有限的，不能真正达到无限级深度，当然一般业务会进行层数限制，这个问题一般不影响\\n\\n### 3. 闭包表\\n\\n#### 存储结构\\n\\n除了分类表以外，新建一张表来记录分类直接的层级关系\\n\\n| id   | name |\\n| ---- | ---- |\\n| 1    | 文具 |\\n| 2    | 笔   |\\n| 3    | 铅笔 |\\n| 4    | 钢笔 |\\n\\n+ ancestor：父节点\\n+ descendant：子节点\\n+ distance：距离\\n\\n| ancestor | descendant | distance |\\n| -------- | ---------- | -------- |\\n| 1        | 2          | 1        |\\n| 1        | 3          | 2        |\\n| 1        | 4          | 2        |\\n| 2        | 3          | 1        |\\n| 2        | 4          | 1        |\\n\\n#### 数据操作\\n\\n+ 移动：较为麻烦，涉及到相关节点的distance增减\\n+ 删：删除所有相关节点即可\\n+ 查：两边连接查询\\n\\n#### 优缺点\\n\\n+ 优点：可以支持更多的操作，比如查询某个层的所有节点，而且查询速度较快\\n+ 缺点：特别非空间，增删改麻烦\\n\\n## 总结\\n\\n需要注意的是像目录这样的结构，是很少改动的，所以很适合利用redis来缓存加快访问速度，虽然 `闭包法` 支持更多的操作，但较为复杂且数据冗余太严重，个人更倾向于选择 `记录父类法` 和 `路劲列表法` 配合 redis 缓存使用，缓存整个结构，查询时直接返回给业务，进行更多的取舍即可。\",\"category\":\"业务设计\",\"createTime\":\"2021/05/10 14:25:00\"},{\"id\":\"1630739979797\",\"name\":\"短网址实现\",\"title\":\"如何实现短网址系统\",\"content\":\"\\n\\n如何实现长网址到短网址，短网址到长网址的映射呢，比如：\\n```\\n原始网址：https://github.com/wangzheng0822/ratelimiter4j\\n短网址：http://t.cn/EtR9QEG\\n```\\n\\n## 一. 通过哈希算法\\n\\n### 1. 实现\\n\\n**MurmurHash** 算法，提供了两种长度的哈希值，一种是 32bits，一种是 128bits。为了让最终生成的短网址尽可能短，我们可以选择 32bits 的哈希值。对于开头那个 GitHub 网址，经过 MurmurHash 计算后，得到的哈希值就是 181338494\\n\\n再将哈希值 `181338494` 转化为62进制 `cgSqq`\\n\\n最终网址变为：http://t.cn/cgSqq\\n\\n哈希算法无法避免的一个问题，就是哈希冲突。尽管 MurmurHash 算法，冲突的概率非常低。\\n\\n我们可以给原始网址拼接一串特殊字符，比如“[DUPLICATED]”，然后再重新计算哈希值，两次哈希计算都冲突的概率，显然是非常低的。假设出现非常极端的情况，又发生冲突了，我们可以再换一个拼接字符串，比如“[OHMYGOD]”，再计算哈希值。然后把计算得到的哈希值，跟原始网址拼接了特殊字符串之后的文本，一并存储。\\n\\n### 2. 存储\\n\\n可以通过mysql存储原网址和短网址的映射\\n\\n```sql\\ncreate table url (\\n  short char(...) not null '短网址',\\n\\tsource varchar(...) not null comment '源网址',\\n  primary key (short),\\n  key `source_idx` (`source`)\\n)ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\\n```\\n\\n### 3. 流程\\n\\n1. 当有新的原始网址需要生成短网址的时候，直接将生成的短网址与对应的原始网址存储到数据库\\n    + 存储成功：没有冲突\\n    + 存储失败：不一定是冲突。我们需要进行`查询 -> 判断是否原网址相同 -> 相同直接返回短网址 -> 不相同添加特殊字符重新尝试存储`\\n2. 访问短网址：到数据库查找对应的原始网址，如果原始网址有拼接特殊字符（这个很容易通过字符串匹配算法找到），我们就先将特殊字符去掉，然后再将不包含特殊字符的原始网址返回给浏览器。\\n\\n在`第1点中`我们还可以把已经生成的短网址，构建成布隆过滤器。\\n\\n布隆过滤器是比较节省内存的一种存储结构，长度是 10 亿的布隆过滤器，也只需要 125MB 左右的内存空间。\\n\\n当有新的短网址生成的时候，先拿这个新生成的短网址，在布隆过滤器中查找。\\n\\n如果查找的结果是不存在，那就说明这个新生成的短网址并没有冲突。这个时候，我们只需要再执行写入短网址和对应原始网页的 SQL 语句就可以了。通过先查询布隆过滤器，总的 SQL 语句的执行次数减少了。\\n\\n## 二. ID 生成器生成短网址\\n\\n我们可以维护一个 ID 自增生成器。它可以生成 1、2、3…这样自增的整数 ID。当短网址服务接收到一个原始网址转化成短网址的请求之后，它先从 ID 生成器中取一个号码，然后将其转化成 62 进制表示法，拼接到短网址服务的域名后面，就形成了最终的短网址。最后，我们还是会把生成的短网址和对应的原始网址存储到数据库中。\\n\\n出现问题：**相同的原始网址可能会对应不同的短网址**\\n\\n处理：\\n\\n+ 不做处理，因为只需要保证用户访问短网址能拿到正确的原网址，但是造成资源浪费\\n+ 通过原始网址在数据库查找是否已存在，如果存在直接返回短网址。这种方法需要给原始网址加索引，一方面两个索引会占用更多的存储空间，另一方面索引还会导致插入、删除等操作性能的下降\\n\\n\\n\\n\\n\\n## 三. 短网址的用处\\n\\n+ 缩短内容长度，在限制字数的社交平台有用\\n\\n+ 便于数据统计\\n\\n    `A网址 -> 短连接服务 -> B网址`\\n\\n+ 简化二维码\\n\\n    如果链接长度过长，生成的二维码图片过于复杂， 会降低二维码扫描的成功率，缩短后的网址二维码就会清晰容易识别\\n\\n\",\"category\":\"业务设计\",\"createTime\":\"2021/05/12 12:16:00\"},{\"id\":\"1630739979796\",\"name\":\"排序算法\",\"title\":\"排序算法\",\"content\":\"\\n\\n\\n+ 原地排序：是否需要额外的空间\\n+ 稳定性：相同元素排序后前后位置是否改变\\n+ 时间复杂度\\n+ 空间复杂度\\n\\n![](http://static.mittacy.com/blog/202109041517751.jpg) \\n\\n### 1. 冒泡排序算法\\n\\n~~~go\\nfunc Bubbll(arr []int) {\\n\\tif len(arr) <= 1 {\\n\\t\\treturn\\n\\t}\\n\\tfor i := 0; i < len(arr); i++ {\\n\\t\\tflag := false\\t// 提前退出冒泡循环的标志位\\n\\t\\tfor j := 1; j < len(arr) - i; j++ {\\n\\t\\t\\tif arr[j] < arr[j-1] {\\n\\t\\t\\t\\tflag = true\\n\\t\\t\\t\\tarr[j], arr[j-1] = arr[j-1], arr[j]\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\tif !flag {\\t\\t// 满足条件说明本循环一次也没发生交换，说明数组已经排列好了\\n\\t\\t\\treturn\\n\\t\\t}\\n\\t}\\n}\\n~~~\\n\\n### 2. 插入排序 (数据整体移动)\\n\\n从无序组中拿出第一个插入到有序组中合适的位置\\n\\n~~~go\\nfunc InsertSort(arr []int) {\\n\\tlength := len(arr)\\n\\tif length <= 1 {\\n\\t\\treturn\\n\\t}\\n\\tfor i := 1; i < length; i++ {\\n\\t\\tj := i - 1\\n\\t\\tvalue := arr[i]\\n\\t\\tfor ; j >= 0; j-- {\\n\\t\\t\\tif arr[j] > value {\\n\\t\\t\\t\\tarr[j+1] = arr[j]\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tbreak\\n\\t\\t\\t}\\n\\t\\t\\tarr[j+1] = value\\n\\t\\t}\\n\\t}\\n}\\n~~~\\n\\n### 3. 选择排序 (数据交换)\\n\\n**从无序组中选择出最小的值和无序组第一个交换，然后该值便成了有序组的最大值**\\n\\n选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾\\n\\n~~~go\\nfunc SelectSort(arr []int) {\\n\\tlength := len(arr)\\n\\tif length <= 1 {\\n\\t\\treturn\\n\\t}\\n\\tfor i := 0; i < length-1; i++ {\\n\\t\\tminIndex := i\\n\\t\\tfor j := i + 1; j < length; j++ {\\n\\t\\t\\tif arr[j] < arr[minIndex] {\\n\\t\\t\\t\\tminIndex = j\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\tif minIndex != i {\\n\\t\\t\\tarr[minIndex], arr[i] = arr[i], arr[minIndex]\\n\\t\\t}\\n\\t}\\n\\treturn\\n}\\n~~~\\n\\n### 4. 归并排序 O(nlogn)\\n\\n~~~go\\nfunc MergeSort(arr []int) {\\n\\tif len(arr) <= 1 {\\n\\t\\treturn\\n\\t}\\n\\tmergeSort(arr, 0, len(arr)-1)\\n}\\n\\nfunc mergeSort(arr []int, p, r int) {\\n\\t// 递归终止条件\\n\\tif p >= r {\\n\\t\\treturn\\n\\t}\\n\\tmiddle := (p + r) / 2\\n\\t// 不断地进行左右对半划分\\n\\tmergeSort(arr, p, middle)\\n\\tmergeSort(arr, middle+1, r)\\n\\t// 合并\\n\\tmerge(arr, p, middle, r)\\n}\\n// merge 从小到大合并两个有序数组\\nfunc merge(arr []int, p, middle, r int) {\\n\\ttemp := make([]int, 0)\\n\\ti, j:= p, middle+1\\n\\tfor i <= middle && j <= r {\\n\\t\\tif arr[i] > arr[j] {\\n\\t\\t\\ttemp = append(temp, arr[j])\\n\\t\\t\\tj++\\n\\t\\t} else {\\n\\t\\t\\t\\ttemp = append(temp, arr[i])\\n\\t\\t\\t\\ti++\\n\\t\\t}\\n\\t}\\n\\t// 把左右边剩余的数移入数组\\n\\tif i > middle {\\n\\t\\ttemp = append(temp, arr[j:r+1]...)\\n\\t} else {\\n\\t\\ttemp = append(temp, arr[i:middle+1]...)\\n\\t}\\n\\t// 将temp修改到arr中\\n\\tfor i, v := range temp {\\n\\t\\tarr[p + i] = v\\n\\t}\\n}\\n~~~\\n\\n### 5. 快速排序 O(nlogn)\\n\\n~~~go\\nfunc QuickSort(arr []int) {\\n\\tif len(arr) <= 1 {\\n\\t\\treturn\\n\\t}\\n\\tquickSort(arr, 0, len(arr)-1)\\n}\\n\\nfunc quickSort(arr []int, p, r int) {\\n\\tif p >= r {\\n\\t\\treturn\\n\\t}\\n\\tq := partition(arr, p, r) // 获取分区点\\n\\tquickSort(arr, p, q-1)\\n\\tquickSort(arr, q+1, r)\\n}\\n\\nfunc partition(arr []int, p, r int) int {\\n\\tpivot := arr[r]\\n\\ti := p\\n\\tfor j := p; j <= r-1; j++ {\\n\\t\\t// < pivot移动i，否则不移动i => i停留的位置一直是大于pivot的数字\\n\\t\\tif arr[j] < pivot {\\n\\t\\t\\tarr[i], arr[j] = arr[j], arr[i]\\n\\t\\t\\ti++\\n\\t\\t}\\n\\t}\\n\\tarr[i], arr[r] = arr[r], arr[i]\\n\\treturn i\\n}\\n~~~\\n\\n优化：\\n\\n+ 针对pivot的选取：三数取中法\\n+ 针对大量重复元素：\\n\\n### 6. 桶排序 O(n)\\n\\n### 7. 计数排序 O(n+k)\\n\\n### 8. 基数排序 O(dn)\\n\\n### 9. 希尔排序\\n\\n希尔排序的实质就是分组插入排序，该方法又称缩小增量排序\\n\\n先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成的）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。因为直接插入排序在元素基本有序的情况下（接近最好情况），效率是很高的。\\n\\n**步长选择：**1，5，9，41，109...\\n\\n+ 原地排序：是\\n+ 稳定算法：否\\n+ 时间复杂度：取决于步长和分组内部采用的排序\\n\\n```go\\n// 分组内部采用了插入排序\\nfunc ShellSort(arr []int) {\\n\\tlength := len(arr)\\n\\tif length <= 1 {\\n\\t\\treturn\\n\\t}\\n\\tfor gap := length/2; gap >= 1; gap /= 2 {\\n\\t\\t// i = gap，i从gap开始就可以了，即每个分组的第二个元素\\n\\t\\tfor i := gap; i < length; i++ {\\n\\t\\t\\tshellInsert(arr, gap, i)\\n\\t\\t}\\n\\t}\\n}\\n/*\\narr: 排序数组\\ngap: 希尔排序步长\\ni: 当前排序元素\\nshellInsert 对 i 元素执行它所在分组的插入排序\\n */\\nfunc shellInsert(arr []int, gap int, i int) {\\n\\tvalue := arr[i]\\n\\tj := i - gap\\n\\tfor ; j >= 0; j = j - gap {\\n\\t\\tif arr[j] > value {\\n\\t\\t\\tarr[j+gap] = arr[j]\\n\\t\\t} else {\\n\\t\\t\\tbreak\\n\\t\\t}\\n\\t}\\n\\tarr[j+gap] = value\\n}\\n```\\n\\n简单易懂图解希尔排序\\n\\n### 10. 通用的排序算法\\n\\n如果对小规模数据进行排序，可以选择时间复杂度是 O(n2) 的算法；如果对大规模数据进行排序，时间复杂度是 O(nlogn) 的算法更加高效。所以，为了兼顾任意规模数据的排序，一般都会首选 **时间复杂度是 O(nlogn)** 的排序算法来实现排序函数\\n\\n使用归并排序的情况其实并不多,归并排序并不是原地排序算法，空间复杂度是 O(n)。所以，粗略点、夸张点讲，如果要排序 100MB 的数据，除了数据本身占用的内存之外，排序算法还要额外再占用 100MB 的内存空间，空间耗费就翻倍了。\\n\\n### 11. 优化快速排序\\n\\n**三数取中法**\\n\\n我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”\",\"category\":\"数据结构与算法\",\"createTime\":\"2020/05/12 12:12:00\"},{\"id\":\"1630740355433\",\"name\":\"搜索引擎纠错功能\",\"title\":\"搜索引擎纠错功能\",\"content\":\"\\n\\n### 编辑距离\\n\\n量化两个字符串之间的相似程度 —— **编辑距离**\\n\\n将一个字符串转化成另一个字符串，需要的最少编辑操作次数（比如增加一个字符、删除一个字符、替换一个字符）\\n\\n编辑距离越大，说明两个字符串的相似程度越小；相反，编辑距离就越小，说明两个字符串的相似程度越大。对于两个完全相同的字符串来说，编辑距离就是 0。\\n\\n根据所包含的编辑操作种类的不同，编辑距离有多种不同的计算方式，比较著名的有\\n\\n+ 莱文斯坦距离（Levenshtein distance），允许增加、删除、替换字符三个编辑操作\\n    + 莱文斯坦距离的大小，表示两个字符串差异的大小\\n+ 最长公共子串长度（Longest common substring length），只允许增加、删除字符\\n    + 最长公共子串的大小，表示两个字符串相似程度的大小\\n\\n比如，两个字符串 mitcmu 和 mtacnu 的莱文斯坦距离是 3，最长公共子串长度是 4\\n\\n![](https://static.mittacy.com/blog/20200408151621.jpg)\\n\\n### 如何编程计算莱文斯坦距离\\n\\n这个问题等价于：把一个字符串变成另一个字符串，需要的最少编辑次数\\n\\n整个求解过程，涉及多个决策阶段，所以，这个问题符合多阶段决策最优解模型。\\n\\n我们需要依次考察一个字符串中的每个字符，跟另一个字符串中的字符是否匹配\\n\\n+ 匹配的话如何处理\\n+ 不匹配的话又如何处理\\n\\n我们先使用简单的回溯算法来解决\\n\\n### 回溯解决莱文斯坦距离\\n\\n回溯是一个递归处理的过程。如果 a[i]与 b[j]匹配，我们递归考察 a[i+1]和 b[j+1]。\\n\\n如果 a[i]与 b[j]不匹配，那我们有多种处理方式可选：\\n\\n+ 增加字符\\n    + 可以在 a[i]前面添加一个跟 b[j]相同的字符，然后递归考察 a[i]和 b[j+1]\\n    + 可以在b[j]前面添加一个跟 a[i] 相同的字符，然后递归考察 a[i+1] 和 b[j]\\n+ 删除字符\\n    + 可以删除 a[i]，然后递归考察 a[i+1] 和 b[j]\\n    + 可以删除 b[j]，然后递归考察 a[i] 和 b[j+1]\\n+ 修改字符\\n    + 可以将 a[i]替换成 b[j]，然后递归考察 a[i] 和 b[j]\\n    + 可以将 b[j] 替换成 a[i]，然后递归考察 a[i] 和 b[j]\\n\\n翻译成代码：\\n\\n~~~go\\nvar minDist =  math.MaxInt64 // 存储结果\\n\\nfunc lwstBT(a, b string) {\\n\\tminDist = math.MaxInt64\\n\\tf(a, b, 0, 0, 0)\\n}\\n\\nfunc f(a, b string, i, j int, edit int) {\\n\\t// 判断是否结束\\n\\tif i == len(a) || j == len(b) {\\n\\t\\t// 删除i剩下的字符\\n\\t\\tif i < len(a) {\\n\\t\\t\\tedit += len(a)-i\\n\\t\\t}\\n\\t\\tif j < len(b) {\\n\\t\\t\\tedit += len(b)-j\\n\\t\\t}\\n\\t\\tif edit < minDist {\\n\\t\\t\\tminDist = edit\\n\\t\\t}\\n\\t\\treturn\\n\\t}\\n\\tif a[i] == b[j] { // 相等不用增加\\n\\t\\tf(a, b, i+1, j+1, edit)\\n\\t} else {\\n\\t\\t// 删除a[i]或者b[j]前添加一个字符\\n\\t\\tf(a, b, i+1, j, edit+1)\\n\\t\\t// 删除b[j]或者a[i]前添加一个字符\\n\\t\\tf(a, b, i, j+1, edit+1)\\n\\t\\t// 将a[i]和b[j]替换为相同字符\\n\\t\\tf(a, b, i+1, j+1, edit+1)\\n\\t}\\n}\\n~~~\\n\\n调用\\n\\n~~~go\\nfunc main() {\\n\\ta := \\\"mitcmu\\\"\\n\\tb := \\\"mtacnu\\\"\\n\\tnow := time.Now()\\n\\tlwstBT(a, b)\\n\\tfmt.Printf(\\\"%d, \\\", minDist)\\n\\tfmt.Println(\\\"耗时: \\\", time.Since(now))\\n}\\n/*\\n 3, 耗时:  101.58µs\\n*/\\n~~~\\n\\n### 动态规划\\n\\n根据回溯算法的代码实现，我们可以画出递归树，看是否存在重复子问题\\n\\n+ 如果存在重复子问题，那我们就可以考虑能否用动态规划来解决\\n+ 如果不存在重复子问题，那回溯就是最好的解决方法\\n\\n![](https://static.mittacy.com/blog/20200408160549.jpg)\\n\\n在递归树中，每个节点代表一个状态，状态包含三个变量 (i, j, edist)，其中，edist 表示处理到 a[i]和 b[j]时，已经执行的编辑操作的次数。\\n\\n在递归树中，(i, j) 两个变量重复的节点很多，比如 (3, 2) 和 (2, 3)。\\n\\n对于 (i, j) 相同的节点，我们只需要保留 edist 最小的，继续递归处理就可以了，剩下的节点都可以舍弃。\\n\\n所以，状态就从 (i, j, edist) 变成了 (i, j, min_edist)，其中 min_edist 表示处理到 a[i]和 b[j]，已经执行的最少编辑次数。\\n\\n这个问题的状态转移方式比较复杂，状态 (i, j) 可能从 (i-1, j)，(i, j-1)，(i-1, j-1) 三个状态中的任意一个转移过来\\n\\n![](https://static.mittacy.com/blog/20200408160801.jpg)\\n\\n尝试着将把状态转移的过程，用公式写出来(状态转移方程):\\n\\n~~~go\\n// 如果：a[i]!=b[j]，那么：min_edist(i, j)就等于：\\nmin(min_edist(i-1,j)+1, min_edist(i,j-1)+1, min_edist(i-1,j-1)+1)\\n// 如果：a[i]==b[j]，那么：min_edist(i, j)就等于：\\nmin(min_edist(i-1,j)+1, min_edist(i,j-1)+1，min_edist(i-1,j-1))\\n~~~\\n\\n了解了状态与状态之间的递推关系，我们画出一个二维的状态表，按行依次来填充状态表中的每个值。\\n\\n1. 首先需要初始化 0行 和 0列\\n2. 从第一行开始逐行计算\\n\\n![](https://static.mittacy.com/blog/20200408161128.jpg)\\n\\n思路理清之后，代码就很容易了，如下\\n\\n~~~go\\nfunc LwstBTDB(a, b string) int {\\n\\t// 创建动态矩阵\\n\\tminDist := make([][]int, len(a))\\n\\tfor i := range a {\\n\\t\\tminDist[i] = make([]int, len(b))\\n\\t}\\n\\t// 初始化第一行第一列\\n\\tfor j := 0; j < len(minDist[0]); j++ {\\n\\t\\t// 第一行\\n\\t\\tif a[0] == b[j] {\\n\\t\\t\\tminDist[0][j] = j\\n\\t\\t} else if j != 0 {\\n\\t\\t\\tminDist[0][j] = minDist[0][j-1]+1\\n\\t\\t} else {\\n\\t\\t\\tminDist[0][j] = 1\\n\\t\\t}\\n\\t}\\n\\t// 第一列\\n\\tfor i := 0; i < len(minDist); i++ {\\n\\t\\t// 第一列\\n\\t\\tif b[0] == a[i] {\\n\\t\\t\\tminDist[i][0] = i\\n\\t\\t} else if i != 0 {\\n\\t\\t\\tminDist[i][0] = minDist[i-1][0] + 1\\n\\t\\t} else {\\n\\t\\t\\tminDist[i][0] = 1\\n\\t\\t}\\n\\t}\\n\\t// 从第一行开始到结束填表\\n\\tfor i := 1; i < len(minDist); i++ {\\n\\t\\tfor j := 1; j < len(minDist[0]); j++ {\\n\\t\\t\\tif a[i] == b[j] {\\n\\t\\t\\t\\tminDist[i][j] = min(minDist[i][j-1]+1, minDist[i-1][j]+1, minDist[i-1][j-1])\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tminDist[i][j] = min(minDist[i][j-1]+1, minDist[i-1][j]+1, minDist[i-1][j-1]+1)\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n\\treturn minDist[len(minDist)-1][len(minDist[0])-1]\\n}\\n~~~\\n\\n调用\\n\\n~~~go\\nfunc main() {\\n  a := \\\"mitcmu\\\"\\n\\tb := \\\"mtacnu\\\"\\n\\tnow := time.Now()\\n\\tfmt.Printf(\\\"%d, \\\", LwstBTDB(a, b))\\n\\tfmt.Println(\\\"耗时: \\\", time.Since(now))\\n}\\n/*\\n 3, 耗时:  39.466µs\\n*/\\n~~~\\n\\n\\n\\n用长一些的字符串来比较两个实现的差距\\n\\n~~~go\\nfunc main() {\\n\\ta := \\\"mitcmusufhgr\\\"\\n\\tb := \\\"mtacnusguhgr\\\"\\n\\tnow := time.Now()\\n\\tLwstBT(a, b)\\t// 回溯\\n\\tfmt.Printf(\\\"%d, \\\", minDist)\\n\\tfmt.Println(\\\"耗时: \\\", time.Since(now))\\n\\tnow = time.Now()\\n\\tfmt.Printf(\\\"%d, \\\", LwstBTDB(a, b)) // 动态规划\\n\\tfmt.Println(\\\"耗时: \\\", time.Since(now))\\n}\\n/*\\n 5, 耗时:  18.690455ms\\n 5, 耗时:  41.003µs\\n*/\\n~~~\\n\\n### 搜索引擎的拼写纠错功能\\n\\n回到本文标题，搜索引擎的拼写纠错功能是如何实现的\\n\\n当用户在搜索框内，输入一个拼写错误的单词时，我们就拿这个单词跟词库中的单词一一进行比较，计算编辑距离，将编辑距离最小的单词，作为纠正之后的单词，提示给用户，这就是拼写纠错最基本的原理。\\n\\n不过，真正用于商用的搜索引擎，拼写纠错功能显然不会就这么简单。一方面，单纯利用编辑距离来纠错，效果并不一定好；另一方面，词库中的数据量可能很大，搜索引擎每天要支持海量的搜索，所以对纠错的性能要求很高。\\n\\n针对纠错效果不好的问题，有很多种优化思路：\\n\\n+ 不仅仅取出编辑距离最小的那个单词，而是取出编辑距离最小的 TOP 10，然后根据其他参数，决策选择哪个单词作为拼写纠错单词。比如使用搜索热门程度来决定哪个单词作为拼写纠错单词。\\n+ 还可以用多种编辑距离计算方法，然后分别编辑距离最小的 TOP 10，然后求交集，用交集的结果，再继续优化处理。\\n+ 还可以通过统计用户的搜索日志，得到最常被拼错的单词列表，以及对应的拼写正确的单词。搜索引擎在拼写纠错的时候，首先在这个最常被拼错单词列表中查找。如果一旦找到，直接返回对应的正确的单词。这样纠错的效果非常好\\n+ 还有更加高级一点的做法，引入个性化因素。针对每个用户，维护这个用户特有的搜索喜好，也就是常用的搜索关键词。当用户输入错误的单词的时候，我们首先在这个用户常用的搜索关键词中，计算编辑距离，查找编辑距离最小的单词。\\n\\n针对纠错性能方面，我们也有相应的优化方式，两种分治的优化思路：\\n\\n+ 如果纠错功能的 TPS 不高，我们可以部署多台机器，每台机器运行一个独立的纠错功能。当有一个纠错请求的时候，我们通过负载均衡，分配到其中一台机器，来计算编辑距离，得到纠错单词。\\n+ 如果纠错系统的响应时间太长，也就是，每个纠错请求处理时间过长，我们可以将纠错的词库，分割到很多台机器。当有一个纠错请求的时候，我们就将这个拼写错误的单词，同时发送到这多台机器，让多台机器并行处理，分别得到编辑距离最小的单词，然后再比对合并，最终决定出一个最优的纠错单词。\\n\\n\",\"category\":\"数据结构与算法\",\"createTime\":\"2020/08/23 19:00:00\"},{\"id\":\"1630741277453\",\"name\":\"数据结构-二叉查找树\",\"title\":\"数据结构-二叉查找树\",\"content\":\"\\n\\n### 1. 结构\\n\\n![](https://static.mittacy.com/blog/20200403134554.jpg)\\n\\n二叉查找树要求，在树中的任意一个节点\\n\\n+ 其左子树中的每个节点的值，都要小于这个节点的值\\n+ 右子树节点的值都大于这个节点的值\\n\\n~~~go\\ntype Tree struct {\\n  root *TreeNode\\n}\\ntype TreeNode struct {\\n  value int\\n  left *TreeNode\\n  right *TreeNode\\n}\\n// NewTree 创建一颗空树\\nfunc NewTree() Tree {\\n\\treturn Tree{root: nil}\\n}\\n~~~\\n\\n### 2. 必备方法\\n\\n~~~go\\nfunc (tree *Tree) Insert(val int) {...}\\t// 插入结点\\nfunc (tree *Tree) Find(val int) *TreeNode {...}\\t\\t// 查找结点\\nfunc (tree *Tree) Delete(val int) error {...} // 删除结点\\nfunc (tree *Tree) PreOrder() {...} // 先序遍历\\nfunc (tree *Tree) InOrder() {...} // 中序遍历\\nfunc (tree *Tree) Order() {...} // 后续遍历\\n~~~\\n\\n#### 2.1 插入和查找\\n\\n由其结构可以看出，可以很方便的查找一个数据，插入也是类似的方法\\n\\n![](https://static.mittacy.com/blog/20200403134817.jpg)\\n\\n+ 实现插入\\n\\n~~~go\\n// Insert 插入结点\\nfunc (tree *Tree) Insert(val int) {\\n\\tnewNode := &TreeNode{value: val}\\n\\t// 如果树为空，则直接作为根结点就可以了\\n\\tif tree.root == nil {\\n\\t\\ttree.root = newNode\\n\\t\\treturn\\n\\t}\\n\\t// 其他情况需要左右查找\\n\\tcurNode := tree.root\\n\\tfor curNode != nil {\\n\\t\\t// 比结点大，向右边\\n\\t\\tif val > curNode.value {\\n\\t\\t\\t// 如果右结点为空，那就插入该位置，否则继续查找\\n\\t\\t\\tif curNode.right == nil {\\n\\t\\t\\t\\tcurNode.right = newNode\\n\\t\\t\\t\\treturn\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tcurNode = curNode.right\\n\\t\\t\\t}\\n\\t\\t} else {\\t// 比结点小，向左边\\n\\t\\t\\t// 如果左结点为空，那就插入该位置，否则继续查找\\n\\t\\t\\tif curNode.left == nil {\\n\\t\\t\\t\\tcurNode.left = newNode\\n\\t\\t\\t\\treturn\\n\\t\\t\\t} else {\\n\\t\\t\\t\\tcurNode = curNode.left\\n\\t\\t\\t}\\n\\t\\t}\\n\\t}\\n}\\n~~~\\n\\n+ 实现查找\\n\\n~~~go\\n// Find 查找结点\\nfunc (tree *Tree) Find(val int) *TreeNode {\\n\\tcurNode := tree.root\\n\\tfor curNode != nil {\\n\\t\\t// 等于该结点，返回\\n\\t\\tif val == curNode.value {\\n\\t\\t\\treturn curNode\\n\\t\\t} else if val < curNode.value {\\n\\t\\t\\t// 小于结点，向左边\\n\\t\\t\\tcurNode = curNode.left\\n\\t\\t} else {\\n\\t\\t\\t// 大于结点，向右边\\n\\t\\t\\tcurNode = curNode.right\\n\\t\\t}\\n\\t}\\n\\treturn nil\\n}\\n~~~\\n\\n#### 2.2 删除\\n\\n二叉查找树的查找、插入操作都比较简单易懂，但是它的删除操作就比较复杂了 ，有三种情况\\n\\n![](https://static.mittacy.com/blog/20200403142627.jpg)\\n\\n+ 比如删除图中的55。它没有左右子节点，只需要直接将父节点中，指向要删除节点的指针置为 null\\n\\n+ 比如删除图中的13。它只有左右子节点其中一个。只需要让16指向13的指针指向15就可以了\\n\\n+ 比如删除图中的18。它有左右子节点，我们需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点，本例子是找到18右子树中的最小节点为19，19替换18，然后删除19\\n\\n    > 注意19没有左节点，但是可以有右节点，所以需要执行函数删除19，不能直接让19的父节点指向nil，比如删除50的时候\\n\\n总体逻辑就是：查找删除结点 A，如果有两个子节点，从右子树中找到最小节点 B，交换A、B节点值，则现在转化为删除Bc\\n\\n~~~go\\n// Delete 删除结点\\nfunc (tree *Tree) Delete(val int) error {\\n\\t// 树为空，找不到错误\\n\\tif tree.root == nil {\\n\\t\\treturn errors.New(\\\"the tree is empty\\\")\\n\\t}\\n\\t// curNode 代表要删除的节点，curNodeFather 代表要curNode的父节点\\n\\tcurNode := tree.root\\n\\tvar curNodeFather *TreeNode\\n\\tfor curNode != nil && val != curNode.value {\\n\\t\\tcurNodeFather = curNode\\n\\t\\tif val > curNode.value {\\n\\t\\t\\tcurNode = curNode.right\\n\\t\\t\\tcontinue\\n\\t\\t}\\n\\t\\tcurNode = curNode.left\\n\\t}\\n\\t// 没有找到\\n\\tif curNode == nil {\\n\\t\\treturn errors.New(\\\"the node no exists\\\")\\n\\t}\\n\\t// 删除的节点如果有两个子节点，处理成删除另一个节点\\n\\tif curNode.left != nil && curNode.right != nil {\\n\\t\\t// 找到curNode右子树的最小节点\\n\\t\\tminNode := curNode.right\\n\\t\\tminNodeFather := curNode\\n\\t\\tfor minNode.left != nil {\\n\\t\\t\\tminNodeFather = minNode\\n\\t\\t\\tminNode = minNode.left\\n\\t\\t}\\n\\t\\t// 将最小节点的值替换curNode的值\\n\\t\\tcurNode.value = minNode.value\\n\\t\\t// 并且将curNode换到最小节点，即现在变成了要删除最小节点\\n\\t\\tcurNode = minNode\\n\\t\\tcurNodeFather = minNodeFather\\n\\t}\\n\\t// 删除节点肯定是叶子节点或者仅有一个子节点，因为上面的情况已经处理转化了\\n\\t// 先保存curNode的子节点(如果有的话)\\n\\tvar curNodeChild *TreeNode\\n\\tif curNode.left != nil {\\n\\t\\tcurNodeChild = curNode.left\\n\\t} else if curNode.right != nil {\\n\\t\\tcurNodeChild = curNode.right\\n\\t}\\n\\t// 开始删除\\n\\tif curNodeFather == nil {\\t// 删除的是根节点\\n\\t\\ttree.root = curNodeChild\\n\\t} else if curNodeFather.left == curNode {\\n\\t\\tcurNodeFather.left = curNodeChild\\n\\t} else {\\n\\t\\tcurNodeFather.right = curNodeChild\\n\\t}\\n\\treturn nil\\n}\\n~~~\\n\\n#### 2.3 遍历\\n\\n~~~go\\n// PreOrder 先序遍历\\nfunc (tree *Tree) PreOrder() {\\n\\tPreNode(tree.root)\\n\\tfmt.Println()\\n}\\nfunc PreNode(node *TreeNode) {\\n\\tif node == nil {\\n\\t\\treturn\\n\\t}\\n\\tfmt.Printf(\\\"%d \\\", node.value)\\n\\tPreNode(node.left)\\n\\tPreNode(node.right)\\n}\\n// InOrder 中序遍历\\nfunc (tree *Tree) InOrder() {\\n\\tInNode(tree.root)\\n\\tfmt.Println()\\n}\\nfunc InNode(node *TreeNode) {\\n\\tif node == nil {\\n\\t\\treturn\\n\\t}\\n\\tInNode(node.left)\\n\\tfmt.Printf(\\\"%d \\\", node.value)\\n\\tInNode(node.right)\\n}\\n// PostOrder 后序遍历\\nfunc (tree *Tree) PostOrder() {\\n\\tPostNode(tree.root)\\n\\tfmt.Println()\\n}\\nfunc PostNode(node *TreeNode) {\\n\\tif node == nil {\\n\\t\\treturn\\n\\t}\\n\\tfmt.Printf(\\\"%d \\\", node.value)\\n\\tPostNode(node.left)\\n\\tPostNode(node.right)\\n}\\n~~~\\n\\n### 3. 常用方法\\n\\n~~~go\\nfunc (tree *Tree) Height() int {...}\\t// 获取树的高度\\nfunc (tree *Tree) Min() (int, error) {...} // 最小值\\nfunc (tree *Tree) Max() (int, error) {...} // 最大值\\n~~~\\n\\n#### 3.1 求树的高度\\n\\n~~~go\\n// Height 获取树的高度\\nfunc (tree *Tree) Height() int {\\n\\treturn getHeight(tree.root)\\n}\\nfunc getHeight(node *TreeNode) int {\\n\\tif node == nil {\\n\\t\\treturn 0\\n\\t}\\n\\t// 返回左右边比较高的节点+1\\n\\tleftHeight := getHeight(node.left)\\n\\trightHeight := getHeight(node.right)\\n\\tif leftHeight >= rightHeight {\\n\\t\\treturn leftHeight + 1\\n\\t}\\n\\treturn rightHeight + 1\\n}\\n~~~\\n\\n#### 3.2 最小/大值\\n\\n~~~go\\n// Min 最小值\\nfunc (tree *Tree) Min() (int, error) {\\n\\tcurNode := tree.root\\n\\tif curNode == nil {\\n\\t\\treturn 0, errors.New(\\\"The tree is empty.\\\")\\n\\t}\\n\\tfor curNode.left != nil {\\n\\t\\tcurNode = curNode.left\\n\\t}\\n\\treturn curNode.value, nil\\n}\\n// Max 最大值\\nfunc (tree *Tree) Max() (int, error) {\\n\\tcurNode := tree.root\\n\\tif curNode == nil {\\n\\t\\treturn 0, errors.New(\\\"The tree is empty.\\\")\\n\\t}\\n\\tfor curNode.right != nil {\\n\\t\\tcurNode = curNode.right\\n\\t}\\n\\treturn curNode.value, nil\\n}\\n~~~\\n\",\"category\":\"数据结构与算法\",\"createTime\":\"2020/03/14 09:20:10\"},{\"id\":\"1630740705992\",\"name\":\"数据结构-堆\",\"title\":\"数据结构-堆\",\"content\":\"\\n\\n+ 堆的结构是怎么样的\\n+ 堆支持哪些操作\\n+ 堆的用途\\n+ 如何存储一个堆\\n\\n### 1. 结构\\n\\n+ 堆是一个完全二叉树\\n+ 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值\\n\\n第一点，堆必须是一个完全二叉树。完全二叉树除了最后一层，其他层的节点个数都是满的，最后一层的节点都**靠左排列**。\\n\\n第二点，堆中每个节点的值都大于等于（或者小于等于）其左右子节点的值。这两种表述是等价的。\\n\\n![](https://static.mittacy.com/blog/20200329154803.jpg)\\n\\n1、2是大顶堆，3是小顶堆，4不是堆\\n\\n### 2. 堆支持哪些操作\\n\\n+ 插入元素(插入到叶子结点，然后从下向上堆化)\\n+ 删除堆顶元素(最后一个叶子结点和堆顶元素交换，然后从上向下堆化)\\n\\n### 3. 如何实现一个堆\\n\\n完全二叉树比较适合用数组来存储。用数组来存储完全二叉树是非常节省存储空间的。因为我们不需要存储左右子节点的指针，单纯地通过数组的下标，就可以找到一个节点的左右子节点和父节点。\\n\\n![](https://static.mittacy.com/blog/20200329155447.jpg)\\n\\n从图中我们可以看到，数组中下标为 i 的节点的左子节点，就是下标为 i∗2 的节点，右子节点就是下标为 i∗2+1 的节点，父节点就是下标为 2i 的节点。0位置不存储数据，是为了方便标记父子节点\\n\\n~~~go\\ntype Heap struct {\\n\\tcap int\\t// 堆可以存储的最大数据个数\\n\\tlen int // 堆中已经存储的数据个数\\n\\tarr []int\\t// 数组，从下标1开始存储数据\\n}\\nfunc (heap *Heap) Insert(v int) {}\\nfunc (heap *Heap) Delte(v int) error {}\\n~~~\\n\\n#### 4.1 插入操作\\n\\n往堆中插入一个元素后，我们需要继续满足堆结构的两个特性\\n\\n+ 堆是一个完全二叉树\\n+ 堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值\\n\\n如下图是不符合的\\n\\n![](https://static.mittacy.com/blog/20200329161637.jpg)\\n\\n所以我们必须进行调整，让其重新满足堆的特性，这个过程我们起了一个名字，就叫作**堆化**\\n\\n堆化实际上有两种，从下往上和从上往下。这里使用的是从下往上的堆化方法\\n\\n![](https://static.mittacy.com/blog/20200329162027.jpg)\\n\\n​\\t让新插入的节点与父节点对比大小。如果不满足子节点小于等于父节点的大小关系，我们就互换两个节点。一直重复这个过程，直到父子节点之间满足刚说的那种大小关系\\n\\n~~~go\\nfunc (heap *Heap) Insert(v int) {\\n\\tif heap.len >= heap.cap {\\n\\t\\treturn\\n\\t}\\n\\theap.len++\\n\\theap.arr[heap.len] = v\\n\\t// 自下往上堆化\\n\\ti := heap.len\\n\\tfor i/2 > 0 && heap.arr[i] > heap.arr[i/2] {\\n\\t\\theap.arr[i], heap.arr[i/2] = heap.arr[i/2], heap.arr[i]\\n\\t\\ti = i / 2\\n\\t}\\n}\\n~~~\\n\\n#### 4.2 删除堆顶\\n\\n假设我们构造的是大顶堆，堆顶元素就是最大的元素。当我们删除堆顶元素之后，就需要把第二大的元素放到堆顶，那第二大元素肯定会出现在左右子节点中。然后我们再迭代地删除第二大节点，以此类推，直到叶子节点被删除。\\n\\n![](https://static.mittacy.com/blog/20200329175439.jpg)\\n\\n可以看到不满足完全二叉树这个条件，稍微改变一下思路，就可以解决这个问题。\\n\\n把最后一个节点放到堆顶，然后利用同样的父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程，直到父子节点之间满足大小关系为止。这就是从上往下的堆化方法。\\n\\n![](https://static.mittacy.com/blog/20200329175551.jpg)\\n\\n~~~go\\nfunc heapify(arr []int, length int, startIndex int) {\\n\\tfor {\\n\\t\\tmaxPos := startIndex\\n\\t\\t// 跟其左结点比较大小\\n\\t\\tif startIndex*2 <= length && arr[startIndex] < arr[startIndex*2] {\\n\\t\\t\\tmaxPos = startIndex * 2\\n\\t\\t}\\n\\t\\t// 跟其右结点比较大小\\n\\t\\tif startIndex*2+1 <= length && arr[maxPos] < arr[startIndex*2+1] {\\n\\t\\t\\tmaxPos = startIndex * 2 + 1\\n\\t\\t}\\n\\t\\t// 如果比左右结点都大，则满足要求了可以退出\\n\\t\\tif maxPos == startIndex {\\n\\t\\t\\tbreak\\n\\t\\t}\\n\\t\\tarr[maxPos], arr[startIndex] = arr[startIndex], arr[maxPos]\\n\\t\\tstartIndex = maxPos\\n\\t}\\n}\\n~~~\\n\\n### 4. 实现一个大顶堆\\n\\n~~~go\\ntype Heap struct {\\n\\tcap int\\t// 堆可以存储的最大数据个数\\n\\tcount int // 堆中已经存储的数据个数\\n\\tarr []int\\t// 数组，从下标1开始存储数据\\n}\\n// NewHeap 返回一个新堆\\nfunc NewHeap(cap int) Heap {\\n\\treturn Heap{cap: cap, count: 0, arr: make([]int, cap+1)}\\n}\\n// Insert 插入一个结点\\nfunc (heap *Heap) Insert(v int) {\\n\\tif heap.count >= heap.cap {\\n\\t\\treturn\\n\\t}\\n\\theap.count++\\n\\theap.arr[heap.count] = v\\n\\t// 自下往上堆化\\n\\ti := heap.count\\n\\tfor i/2 > 0 && heap.arr[i] > heap.arr[i/2] {\\n\\t\\theap.arr[i], heap.arr[i/2] = heap.arr[i/2], heap.arr[i]\\n\\t\\ti = i / 2\\n\\t}\\n}\\n// MoveTop 删除Top结点\\nfunc (heap *Heap) MoveTop() error {\\n\\tif heap.count == 0 {\\n\\t\\treturn errors.New(\\\"没有数据\\\")\\n\\t}\\n\\theap.arr[1] = heap.arr[heap.count]\\t// 将最后一个数字放到堆顶\\n\\t// 从上到下开始堆化\\n\\theap.count--\\n\\theapify(heap.arr, heap.count, 1)\\n\\treturn nil\\n}\\n// GetArr 获取堆的数组\\nfunc (heap *Heap) GetArr() []int {\\n\\treturn heap.arr[1:]\\n}\\n// heapify 自上往下堆化\\nfunc heapify(arr []int, length int, startIndex int) {\\n\\tfor {\\n\\t\\tmaxPos := startIndex\\n\\t\\t// 跟其左结点比较大小\\n\\t\\tif startIndex*2 <= length && arr[startIndex] < arr[startIndex*2] {\\n\\t\\t\\tmaxPos = startIndex * 2\\n\\t\\t}\\n\\t\\t// 跟其右结点比较大小\\n\\t\\tif startIndex*2+1 <= length && arr[maxPos] < arr[startIndex*2+1] {\\n\\t\\t\\tmaxPos = startIndex * 2 + 1\\n\\t\\t}\\n\\t\\t// 如果比左右结点都大，则满足要求了可以退出\\n\\t\\tif maxPos == startIndex {\\n\\t\\t\\tbreak\\n\\t\\t}\\n\\t\\tarr[maxPos], arr[startIndex] = arr[startIndex], arr[maxPos]\\n\\t\\tstartIndex = maxPos\\n\\t}\\n}\\n// Count 返回heap的个数\\nfunc (heap *Heap) Count() int {\\n\\treturn len(heap.arr)\\n}\\n// Cap 返回heap的容量\\nfunc (heap *Heap) Cap() int {\\n\\treturn cap(heap.arr)\\n}\\n~~~\\n\\n### 5. 堆的用途\\n\\n+ 利用堆求 Top K\\n+ 优先级队列\\n    + 合并有序小文件\\n    + 高性能定时器\\n+ 流里面的中值\\n+ 流里面的中位数\\n\\n针对Top K 这一用途，来构造的是一个K容量的堆，当容量满了的时候插入数据，就要删除一个最大/小的值\\n\\n+ 如果是想要输出**Top K 小**，建立大顶堆，那么每次满了的时候就需要删除一个最大值，最后剩下的K个值就是最小的\\n+ 如果是想要输出**Top K 大**，建立小顶堆，那么每次满了的时候就需要删除一个最小值，最后剩下的K个值就是最大的\\n\\n我们来实现一个求**TopK小**的堆\\n\\n我们只需要根据 上面实现的堆，增加获取修改堆顶元素的权限，再改造一下`func (heap *Heap) Insert(v int){}`函数就可以了\\n\\n**增加堆顶权限**\\n\\n~~~go\\n// GetTopVal 获取堆顶元素\\nfunc (heap *Heap) GetTopVal() (int, error) {\\n\\tif heap.count == 0 {\\n\\t\\treturn 0, errors.New(\\\"没有元素\\\")\\n\\t}\\n\\treturn heap.arr[1], nil\\n}\\n// PutTopVal 修改堆顶元素\\nfunc (heap *Heap) PutTopVal(val int) error {\\n\\tif heap.count == 0 {\\n\\t\\treturn errors.New(\\\"没有元素\\\")\\n\\t}\\n\\theap.arr[1] = val\\n\\treturn nil\\n}\\n~~~\\n\\n**修改insert操作**\\n\\n~~~go\\n// Insert 插入一个结点\\nfunc (heap *Heap) Insert(v int) {\\n\\t// 堆满了的时候，新数据与堆顶比较，小的话就替换堆顶，然后进行堆化\\n\\tif heap.count >= heap.cap {\\n\\t\\tif top, _ := heap.GetTopVal(); v > top {\\n\\t\\t\\treturn\\n\\t\\t}\\n\\t\\t// 替换堆顶元素，然后堆化\\n\\t\\theap.PutTopVal(v)\\n\\t\\theapify(heap.arr, heap.count, 1)\\n\\t\\treturn\\n\\t}\\n\\theap.count++\\n\\theap.arr[heap.count] = v\\n\\t// 自下往上堆化\\n\\ti := heap.count\\n\\tfor i/2 > 0 && heap.arr[i] > heap.arr[i/2] {\\n\\t\\theap.arr[i], heap.arr[i/2] = heap.arr[i/2], heap.arr[i]\\n\\t\\ti = i / 2\\n\\t}\\n}\\n~~~\\n\\n**完整的大顶堆求Top K小值 的代码**\\n\\n~~~go\\ntype Heap struct {\\n\\tcap int\\t// 堆可以存储的最大数据个数\\n\\tcount int // 堆中已经存储的数据个数\\n\\tarr []int\\t// 数组，从下标1开始存储数据\\n}\\n// NewHeap 返回一个新堆\\nfunc NewHeap(cap int) Heap {\\n\\treturn Heap{cap: cap, count: 0, arr: make([]int, cap+1)}\\n}\\n// Insert 插入一个结点\\nfunc (heap *Heap) Insert(v int) {\\n\\tif heap.count >= heap.cap{\\n\\t\\t// 堆满了的时候，新数据与堆顶比较，小的话就替换堆顶，然后进行堆化\\n\\t\\tif top, _ := heap.GetTopVal(); v >= top {\\n\\t\\t\\treturn\\n\\t\\t}\\n\\t\\t// 替换堆顶元素，然后堆化\\n\\t\\theap.PutTopVal(v)\\n\\t\\theapify(heap.arr, heap.count, 1)\\n\\t\\treturn\\n\\t}\\n\\t// 堆未满\\n\\theap.count++\\n\\theap.arr[heap.count] = v\\n\\t// 自下往上堆化\\n\\ti := heap.count\\n\\tfor i/2 > 0 && heap.arr[i] > heap.arr[i/2] {\\n\\t\\theap.arr[i], heap.arr[i/2] = heap.arr[i/2], heap.arr[i]\\n\\t\\ti = i / 2\\n\\t}\\n}\\n// GetArr 获取堆的数组\\nfunc (heap *Heap) GetArr() []int {\\n\\treturn heap.arr[1:]\\n}\\n// heapify 自上往下堆化\\nfunc heapify(arr []int, length int, startIndex int) {\\n\\tfor {\\n\\t\\tmaxPos := startIndex\\n\\t\\t// 跟其左结点比较大小\\n\\t\\tif startIndex*2 <= length && arr[startIndex] < arr[startIndex*2] {\\n\\t\\t\\tmaxPos = startIndex * 2\\n\\t\\t}\\n\\t\\t// 跟其右结点比较大小\\n\\t\\tif startIndex*2+1 <= length && arr[maxPos] < arr[startIndex*2+1] {\\n\\t\\t\\tmaxPos = startIndex * 2 + 1\\n\\t\\t}\\n\\t\\t// 如果比左右结点都大，则满足要求了可以退出\\n\\t\\tif maxPos == startIndex {\\n\\t\\t\\tbreak\\n\\t\\t}\\n\\t\\tarr[maxPos], arr[startIndex] = arr[startIndex], arr[maxPos]\\n\\t\\tstartIndex = maxPos\\n\\t}\\n}\\n// GetTopVal 获取堆顶元素\\nfunc (heap *Heap) GetTopVal() (int, error) {\\n\\tif heap.count == 0 {\\n\\t\\treturn 0, errors.New(\\\"没有元素\\\")\\n\\t}\\n\\treturn heap.arr[1], nil\\n}\\n// PutTopVal 修改堆顶元素\\nfunc (heap *Heap) PutTopVal(val int) error {\\n\\tif heap.count == 0 {\\n\\t\\treturn errors.New(\\\"没有元素\\\")\\n\\t}\\n\\theap.arr[1] = val\\n\\treturn nil\\n}\\n~~~\\n\\n**测试**\\n\\n输出数组[5,6,7,8,9,10,...,23]的5个最小元素\\n\\n~~~go\\nfunc TestHeap(t *testing.T) {\\n  h := NewHeap(5)\\n\\tfor i := 5; i < 23; i++ {\\n\\t\\th.Insert(i)\\n\\t}\\n\\th.Print()\\n}\\n/*\\n9 8 6 5 7\\n*/\\n~~~\\n\\nGo也提供了heap，我们使用Go标准库heap实现Top K算法：[Go container heap用法](https://blog.mittacy.com/article/46)\\n\\n### 6. Go实现Top K\\n\\n我们使用Go 自带的heap来实现 Top K\\n\\n~~~go\\ntype Interface interface {\\n\\tsort.Interface\\n\\tPush(x interface{}) // add x as element Len()\\n\\tPop() interface{}   // remove and return element Len() - 1.\\n}\\ntype Interface interface {\\n\\t// Len is the number of elements in the collection.\\n\\tLen() int\\n\\t// Less reports whether the element with\\n\\t// index i should sort before the element with index j.\\n\\tLess(i, j int) bool\\n\\t// Swap swaps the elements with indexes i and j.\\n\\tSwap(i, j int)\\n}\\n~~~\\n\\n首先，Go提供了一个接口，我们需要实现以下方法，便可以实现接口，从而使用 heap\\n\\n- Len() int\\n- Less(i, j int) bool\\n- Swap(i, j int)\\n- Push(x interface{})\\n- Pop() interface{}\\n\\n~~~go\\ntype IntHeap []int\\n\\nfunc (h IntHeap) Len() int {\\n\\treturn len(h)\\n}\\n\\nfunc (h IntHeap) Less(i, j int) bool {\\n\\treturn h[i] < h[j]\\n}\\n\\nfunc (h IntHeap) Swap(i, j int) {\\n\\th[i], h[j] =  h[j], h[i]\\n}\\n\\nfunc (h *IntHeap) Pop() interface{} {\\n\\told := *h\\n\\titem := old[len(old)-1]\\n\\t*h = old[:len(old)-1]\\n\\treturn item\\n}\\n\\nfunc (h *IntHeap) Push(value interface{}) {\\n\\t*h = append(*h, value.(int))\\n}\\n~~~\\n\\n实现了这五个方法的数据类型就能使用go标准库给我们提供的heap了，标准库提供的方法有\\n\\n~~~go\\nfunc Init(h Interface)  // 对heap进行初始化，生成小根堆（或大根堆）\\nfunc Push(h Interface, x interface{})  // 往堆里面插入内容\\nfunc Pop(h Interface) interface{}  // 从堆顶pop出内容\\nfunc Remove(h Interface, i int) interface{}  // 从指定位置删除数据，并返回删除的数据\\nfunc Fix(h Interface, i int)  // 从i位置数据发生改变后，对堆再平衡，优先级队列使用该方法\\n~~~\\n\\n使用：\\n\\n~~~go\\npackage main\\n\\nimport (\\n\\t\\\"container/heap\\\"\\n\\t\\\"fmt\\\"\\n)\\n\\nfunc main() {\\n\\tarr := []int{2, 1, 5, 6, 4, 7, 9, 8, 0}\\n\\th := IntHeap{}  // 创建slice\\n\\tfor _, val := range arr {\\n\\t\\theap.Push(&h, val)\\n\\t}\\n  fmt.Println(h)\\n}\\n/*\\n[0 1 5 2 4 7 9 8 6]\\n*/\\n~~~\\n\\n**改成大顶堆**\\n\\n只需要修改 Less()函数\\n\\n~~~go\\nfunc (h IntHeap) Less(i, j int) bool {\\n\\treturn h[i] > h[j]\\n}\\n\\nfunc main() {\\n\\tarr := []int{2, 1, 5, 6, 4, 7, 9, 8, 0}\\n\\th := IntHeap{}  // 创建slice\\n\\tfor _, val := range arr {\\n\\t\\theap.Push(&h, val)\\n\\t}\\n  fmt.Println(h)\\n}\\n/*\\n[9 8 7 5 4 2 6 1 0]\\n*/\\n~~~\\n\\n我们只需要修改我们实现的相关函数，改成自己想要的效果，就可以变成各种堆，比如我们来实现Top K最大算法\\n\\n~~~go\\nvar K = 5\\n\\ntype IntHeap []int\\n\\nfunc (h IntHeap) Len() int {\\n\\treturn len(h)\\n}\\nfunc (h IntHeap) Less(i, j int) bool {\\n\\treturn h[i] < h[j]\\n}\\nfunc (h IntHeap) Swap(i, j int) {\\n\\th[i], h[j] =  h[j], h[i]\\n}\\nfunc (h *IntHeap) Pop() interface{} {\\n\\told := *h\\n\\titem := old[len(old)-1]\\n\\t*h = old[:len(old)-1]\\n\\treturn item\\n}\\nfunc (h *IntHeap) Push(value interface{}) {\\n\\told := *h\\n\\tif h.Len() == K {\\n\\t\\tif old[0] >= value.(int) {\\n\\t\\t\\treturn\\n\\t\\t}\\n\\t\\theap.Pop(h)\\n\\t}\\n\\t*h = append(*h, value.(int))\\n}\\n~~~\\n\\n我们只是修改了 Push() 函数，让堆达到K之后，开始比较堆顶和新数据 并更新，这样就实现了求数组的Top5大值\\n\\n~~~go\\nfunc main() {\\n  arr := []int{2, 1, 5, 6, 4, 7, 9, 8, 0}\\n\\th := IntHeap{}  // 创建slice\\n    heap.Init(h)\\n\\tfor _, val := range arr {\\n\\t\\tfmt.Printf(\\\"插入%d, \\\", val)\\n\\t\\theap.Push(&h, val)\\n\\t\\tfmt.Println(h)\\n\\t}\\n}\\n/*\\n插入2, [2]\\n插入1, [1 2]\\n插入5, [1 2 5]\\n插入6, [1 2 5 6]\\n插入4, [1 2 5 6 4]\\n插入7, [2 4 5 6 7]\\n插入9, [4 6 5 7 9]\\n插入8, [5 6 9 7 8]\\n插入0, [5 6 9 7 8]\\n*/\\n~~~\",\"category\":\"数据结构与算法\",\"createTime\":\"2020/03/12 15:39:23\"},{\"id\":\"1630741102881\",\"name\":\"数据结构-散列表\",\"title\":\"数据结构-散列表\",\"content\":\"\\n\\n### 1. 结构设计\\n\\n散列表(Hash Table) 也叫“哈希表”或者“Hash表”。\\n\\n散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。\\n\\n+ 键(Key)或关键字\\n+ 散列函数(Hash函数)\\n+ 散列值(Hash值)\\n\\n![](https://static.mittacy.com/blog/20200328102417.jpg)\\n\\n​\\t我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据\\n\\n散列函数设计的基本要求：\\n\\n+ 散列函数计算得到的散列值是一个非负整数；\\n+ 如果 key1 = key2，那 hash(key1) == hash(key2)；\\n+ 如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)\\n\\n在真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的。即便像业界著名的MD5、SHA、CRC等哈希算法，也无法完全避免这种**散列冲突**。\\n\\n### 2. 散列冲突\\n\\n再好的散列函数也无法避免散列冲突\\n\\n**装载因子**：`散列表的装载因子 = 填入表中的元素个数 / 散列表的长度`\\n\\n装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。\\n\\n我们常用的散列冲突解决方法有两类：\\n\\n+ 链表法（chaining）\\n+ 开放寻址法（open addressing）\\n    + 线性探测\\n    + 二次探测\\n    + 双重散列\\n\\n#### 2.1 线性探测\\n\\n存储：键通过散列函数计算出来的散列值到数组中相应位置，如果该位置已经存在数据了，即发生了散列冲突，顺序地往后一个一个找，看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，于是我们再从表头开始找，直到找到空闲位置\\n\\n查找：键通过散列函数计算出来的散列值到数组中相应位置，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。\\n\\n#### 2.2 二次探测\\n\\n所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+1^2，hash(key)+2^2……\\n\\n#### 2.3 双重散列\\n\\n所谓双重散列，意思就是不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。\\n\\n#### 2.4 链表法\\n\\n链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中\\n\\n**存储**：键通过散列函数计算出来的散列值到数组中相应位置，将其插入到对应链表中即可\\n\\n**查找**：键通过散列函数计算出来的散列值到数组中相应位置，然后遍历链表查找\\n\\n### 3. 扩容机制\\n\\n链表法不会有容量的限制，但是线性探测和二次探测如果初始容量小的话，很容易就满了需要进行扩容\\n\\n**Java中的实现**\\n\\n​\\t首先是，每次扩容时，哈希表的**容量增加为原先的两倍**。于是在扩容被触发时（实际装载因子达到默认装载因子时），需要对原先的表进行rehash。所以这时增加一个元素的性能是比较差的，因为要等待原先的表rehash之后才能增加该元素\\n\\n**Redis中的实现**\\n\\n**均摊思想**\\n\\n​\\t采取的是**分摊转移**的方式。即当插入一个新元素触发了扩容时，先转移第一个不为空的桶到新的哈希表，然后将该元素插入。而下一次再次插入时，继续转移旧哈希表中第一个不为空的桶，再插入元素。直至旧哈希表为空为止。这样一来，理想情况下，插入的时间复杂度是O(1)\\n\\n### 4. 应用场景\\n\\n散列表的应用场景太多了，比如Go语言的Map底层就用到了散列表，可以研究一下，[Go是如何实现Map的](https://blog.mittacy.com/article/30)\\n\",\"category\":\"数据结构与算法\",\"createTime\":\"2020/03/12 16:20:10\"},{\"id\":\"1630741277455\",\"name\":\"数据结构-栈\",\"title\":\"数据结构-栈\",\"content\":\"\\n\\n学习数据结构先思考：\\n\\n+ 栈的结构是什么样的？如何存储数据？\\n+ 有哪些应用场景\\n+ 如何使用计算机语言实现\\n\\n### 1. 结构\\n\\n​\\t关于“栈”，有一个非常贴切的例子，就是一摞叠在一起的盘子。我们平时放盘子的时候，都是从下往上一个一个放；取的时候，我们也是从上往下一个一个地依次取，不能从中间任意抽出。\\n\\n栈的实现由两种：\\n\\n+ 使用数组 —— 顺序栈，数组大小固定，当需要扩容的时候涉及数据迁移\\n+ 使用链表 —— 链式栈，每次插入一个元素就需要创建结点\\n\\n栈涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，栈是一种“操作受限”的线性表\\n\\n如果栈的容量受限，那么可以优先考虑顺序栈\\n\\n如果栈的容量需要不断变化，优先考虑链式栈\\n\\n\\n\\n~~~go\\n/* 顺序栈 */\\ntype ArrStack struct {\\n\\tdata []int\\n\\t//cap int\\t// 容量\\n}\\n\\n/* 链式栈 */\\ntype LinkStack struct {\\n\\ttop *StackNode\\n\\tlen int\\n\\t//cap int\\t// 容量\\n}\\ntype StackNode struct {\\n\\tvalue int\\n\\tnext *StackNode\\n}\\n~~~\\n\\n### 2. 应用场景\\n\\n优点：只剩下必要方法 Push Pop Top\\n\\n应用场景：\\n\\n+ 浏览器的回退前进(需要Pop不丢弃数据而只是移动Top指针)\\n\\n+ 表达式求值\\n\\n    ![](https://static.mittacy.com/blog/20200327222431.jpg)\\n\\n+ 括号匹配，和表达式求值类似\\n\\n### 3. 必备方法\\n\\n~~~go\\nfunc NewStack() Stack {}\\t// NewStack 创建栈\\nfunc (s *Stack) Push(data interface{}) {}\\t// Push 进栈，向栈的顶部添加结点\\nfunc (s *Stack) Pop() *StackNode {}\\t// Pop 出栈\\nfunc (s *Stack) Top() *StackNode {}\\t// Top 返回栈的顶部结点，没有返回nil\\n~~~\\n\\n### 4. Go实现顺序栈\\n\\n~~~go\\n/*\\n 顺序栈\\n */\\ntype ArrStack struct {\\n\\tdata []int\\n\\t//cap int\\t// 容量\\n}\\n// NewArrStack 创建栈\\nfunc NewArrStack() ArrStack {\\n\\ts := ArrStack{[]int{}}\\n\\treturn s\\n}\\n// Push 进栈，向栈的顶部添加结点\\nfunc (stack *ArrStack) Push(value int) {\\n\\tstack.data = append(stack.data, value)\\n}\\n// Top 返回栈的顶部，没有返回 err\\nfunc (stack *ArrStack) Top() (int, error) {\\n\\tlength := len(stack.data)\\n\\tif length == 0 {\\n\\t\\treturn 0, errors.New(\\\"the Stack is empty\\\")\\n\\t}\\n\\treturn stack.data[length-1], nil\\n}\\n// Pop 出栈\\nfunc (stack *ArrStack) Pop() (int, error) {\\n\\tlength := len(stack.data)\\n\\tif length == 0 {\\n\\t\\treturn 0, errors.New(\\\"the Stack is empty\\\")\\n\\t}\\n\\ttemp := stack.data[length-1]\\n\\tstack.data = stack.data[:length-1]\\n\\treturn temp, nil\\n}\\n// Len 栈的长度\\nfunc (stack *ArrStack) Len() int {\\n\\treturn len(stack.data)\\n}\\n// IsEmpty 栈是否为空\\nfunc (stack *ArrStack) IsEmpty() bool {\\n\\tif len(stack.data) == 0 {\\n\\t\\treturn true\\n\\t}\\n\\treturn false\\n}\\n~~~\\n\\n### 5. Go实现链式栈\\n\\n~~~go\\n/*\\n 链式栈\\n */\\ntype LinkStack struct {\\n\\ttop *StackNode\\n\\tlen int\\n\\t//cap int\\t// 容量\\n}\\ntype StackNode struct {\\n\\tvalue int\\n\\tnext *StackNode\\n}\\n// NewLinkStack 创建栈\\nfunc NewLinkStack() LinkStack {\\n\\treturn LinkStack{nil, 0}\\n}\\n// Push 进栈，向栈的顶部添加结点\\nfunc (stack *LinkStack) Push(value int) {\\n\\tnode := StackNode{value, stack.top}\\n\\tstack.top = &node\\n\\tstack.len++\\n}\\n// Top 返回栈的顶部，没有返回 err\\nfunc (stack *LinkStack) Top() (int, error) {\\n\\tif stack.len == 0 {\\n\\t\\treturn -1, errors.New(\\\"the Stack is empty\\\")\\n\\t}\\n\\treturn stack.top.value, nil\\n}\\n// Pop 出栈\\nfunc (stack *LinkStack) Pop() (int, error) {\\n\\tif stack.len == 0 {\\n\\t\\treturn -1, errors.New(\\\"the Stack is empty\\\")\\n\\t}\\n\\ttemp := stack.top.value\\n\\tstack.top = stack.top.next\\n\\tstack.len--\\n\\treturn temp, nil\\n}\\n// Len 栈的长度\\nfunc (stack *LinkStack) Len() int {\\n\\treturn stack.len\\n}\\n// IsEmpty 栈是否为空\\nfunc (stack *LinkStack) IsEmpty() bool {\\n\\tif stack.len == 0 {\\n\\t\\treturn true\\n\\t}\\n\\treturn false\\n}\\n~~~\\n\\n\",\"category\":\"数据结构与算法\",\"createTime\":\"2020/03/11 11:20:10\"},{\"id\":\"1630742161742\",\"name\":\"Redis基础\",\"title\":\"Redis基础\",\"content\":\"\\n\\n[Redis文档](http://redisdoc.com/index.html)\\n\\n## 一. Mac安装与启动\\n\\n~~~shell\\n$ brew install redis\\nTo have launchd start redis now and restart at login:\\n  brew services start redis\\nOr, if you don't want/need a background service you can just run:\\n  redis-server /usr/local/etc/redis.conf\\n==> Summary\\n🍺  /usr/local/Cellar/redis/5.0.6: 13 files, 3.1MB\\n# 配置文件路径: /usr/local/etc/redis.conf\\n# 安装路径: /usr/local/Cellar/redis/5.0.6\\n# 启动\\n$ redis-server /usr/local/etc/redis.conf\\n# 启动并在后台运行\\n$ brew services start redis\\n# 连接\\n$ redis-cli -h 127.0.0.1 -p 6379\\n~~~\\n\\n1. redis默认是前台启动,不是以守护进程的方式进行:`daemonize no`,把这里修改成`yes`,就可以让redis以守护进程的方式启动\\n2. 当redis使用守护进程方式运行,会默认把pid写入/var/run/reids.pid文件中,可以通过`pidfile /var/run/redis.pid`进行指定\\n3. 端口号指定,默认是`6379`,可以根据需要自己修改\\n\\n4. 客户端如果一直连接着不释放的话会自动关闭连接,这是通过`timeout 100`来设定的,如果设置为0表示不会自动关闭\\n\\n5. 设置redis数据库的数量, databases 16 默认是16\\n\\n## 二. 数据类型\\n\\n+ string 字符串\\n+ Hash 哈希\\n+ list 列表\\n+ set 集合\\n+ zset 有序集合\\n\\n### 1.string\\n\\n~~~shell\\n127.0.0.1:6379> set hello world\\nOK\\n127.0.0.1:6379> get hello\\nworld\\n~~~\\n\\n+ SET key value [EX seconds] [PX milliseconds] [NX|XX]\\n\\n    EX表示秒，PX表示毫秒\\n\\n    NX表示只在键不存在时才对键进行设置操作，XX表示只在键已经存在时才对键进行设置操作\\n\\n~~~shell\\n# 只有当hello不存在或过期的时候才对其操作\\n127.0.0.1:6379> set hello world EX 100 NX\\n# 100s内对其覆盖操作\\n127.0.0.1:6379> set hello newWorld EX 10 NX\\n(nil)\\n~~~\\n\\n### 2.hash\\n\\nRedis hash 是一个 string 类型的 key 和 value 的映射表，hash 特别适合用于存储对象\\n\\nstring 是 一个 key - value 键值对，而 hash 是多个 key - value 键值对\\n\\n~~~shell\\n127.0.0.1:6379> hset Jack name Jack\\n(integer) 1\\n127.0.0.1:6379> hset Jack age 20\\n(integer) 1\\n127.0.0.1:6379> hset Jack class 2\\n(integer) 1\\n# 获取 hash-key 这个 hash 里面的所有键值对\\n127.0.0.1:6379> hgetall Jack\\n1) \\\"name\\\"\\n2) \\\"Jack\\\"\\n3) \\\"age\\\"\\n4) \\\"20\\\"\\n5) \\\"class\\\"\\n6) \\\"2\\\"\\n# 删除 hash-key 这个 hash 里面的 age 键值对\\n127.0.0.1:6379> hdel Jack age\\n(integer) 1\\n127.0.0.1:6379> hget Jack age\\n(nil)\\n# 删除整个hash\\n127.0.0.1:6379> del Jack\\n~~~\\n\\n### 3.list\\n\\n~~~shell\\n127.0.0.1:6379> rpush color blue\\n127.0.0.1:6379> rpush color white\\n127.0.0.1:6379> rpush color red\\n# 获取某个list元素\\n127.0.0.1:6379> lindex color 1\\n\\\"red\\\"\\n# 按索引遍历list\\n127.0.0.1:6379> lrange color 0 1\\n1) \\\"blue\\\"\\n2) \\\"white\\\"\\n# 遍历整个list, 即0~-1\\n127.0.0.1:6379> lrange color 0 -1\\n1) \\\"blue\\\"\\n2) \\\"white\\\"\\n3) \\\"red\\\"\\n# 删除一个list，删除的是最后的元素blue\\t\\n127.0.0.1:6379> lpop color\\n127.0.0.1:6379> lrange color 0 -1\\n1) \\\"white\\\"\\n2) \\\"red\\\"\\n~~~\\n\\n### 4.set\\n\\n~~~shell\\n127.0.0.1:6379> sadd color blue\\n127.0.0.1:6379> sadd color white\\n127.0.0.1:6379> sadd color red\\n# 获取整个set\\n127.0.0.1:6379> smembers color\\n1) \\\"white\\\"\\n2) \\\"blue\\\"\\n3) \\\"red\\\"\\n# 添加重复元素查看，没有变化\\n127.0.0.1:6379> sadd color blue\\n127.0.0.1:6379> smembers color\\n1) \\\"white\\\"\\n2) \\\"blue\\\"\\n3) \\\"red\\\"\\n~~~\\n\\nredis 的 set 是一个 key 对应着 多个字符串类型的 value，也是一个字符串类型的集合\\n\\n但是和 list 不同的是 set 中的字符串集合元素不能重复，但是 list 可以\\n\\n### 5.Zset\\n\\nzset 和 set 一样都是 字符串类型元素的集合，并且集合内的元素不能重复。\\n\\n不同的是，zset 每个元素都会关联一个 double 类型的分数。redis 通过分数来为集合中的成员进行从小到大的排序。\\n\\nzset 的元素是唯一的，但是分数（score）却可以重复\\n\\n~~~shell\\n127.0.0.1:6379> zadd zcolor 100 blue\\n127.0.0.1:6379> zadd zcolor 200 red\\n127.0.0.1:6379> zadd zcolor 150 white\\n127.0.0.1:6379> zrange zcolor 0 -1\\n1) \\\"blue\\\"\\n2) \\\"white\\\"\\n3) \\\"red\\\"\\n~~~\\n\\n可以看到red最大排在了最后，如果重复元素并保持分数不变呢\\n\\n~~~shell\\n127.0.0.1:6379> zadd zcolor 200 red\\n(integer) 0\\n127.0.0.1:6379> zrange zcolor 0 -1 withscores\\n1) \\\"blue\\\"\\n2) \\\"100\\\"\\n3) \\\"white\\\"\\n4) \\\"150\\\"\\n5) \\\"red\\\"\\n6) \\\"200\\\"\\n~~~\\n\\nred没有变化，如果重复元素并改变分数呢\\n\\n~~~shell\\n127.0.0.1:6379> zadd zcolor 120 red\\n(integer) 0\\n127.0.0.1:6379> zrange zcolor 0 -1 withscores\\n1) \\\"blue\\\"\\n2) \\\"100\\\"\\n3) \\\"red\\\"\\n4) \\\"120\\\"\\n5) \\\"white\\\"\\n6) \\\"150\\\"\\n~~~\\n\\n可以看到red变成了120，排到了white前面\\n\\n### 6. 数据淘汰策略\\n\\n+\\tvolatile-lru：从已设置过期时间的数据集中挑选**最近最少使用**的数据淘汰\\n+\\tvolatile-ttl：从已设置过期时间的数据集中挑选**将要过期**的数据淘汰\\n+\\tvolatile-random：从已设置过期时间的数据集中**任意选择**数据淘汰\\n+\\tVolatile-flu：从已设置过期时间的数据集挑选使用**频率最低**的数据淘汰\\n+\\tAllkeys-lru：从数据集中挑选**最近最少使用**的数据淘汰\\n+\\tAllkeys-random：从数据集中任意选择数据淘汰\\n+\\tAllkeys-flu：从数据集中挑选使用频率最低的数据淘汰\\n+\\tno-enviction（驱逐）：禁止驱逐数据，这也是默认策略。\\n    +\\t当内存不足以容纳新入数据时，新写入操作就会报错，请求可以继续进行，线上任务也不能持续进行，采用no-enviction策略可以保证数据不被丢失。\\n\\n#### 淘汰机制\\n\\n+ 消极方法：被访问时如果不存在再删除\\n+ 积极方法：周期性地探测，发现失效就删除\\n+ 主动删除：当内存超过maxmemory限定时，触发主动清理策略\\n\\n## 三. 实现\\n\\n### 1. redis对象分类\\n\\n+ string 字符串\\n+ Hash 哈希\\n+ list 列表\\n+ set 集合\\n+ zset 有序集合\\n\\nRedis使用对象来表示数据库中的键和值，即每新建一个键值对，至少创建两个对象(键和值都为对象)，比如创建一个字符串\\n\\n```\\n127.0.0.1:6379> set name mittacy\\nOK\\n```\\n\\nname和mittacy都是一个string字符串对象\\n\\n这样的好处有：\\n\\n1. redis可以在执行命令前根据对象的类型判断一个对象是否可以执行给定的命令\\n2. 针对不同的使用场景，为对象设置不同的数据结构实现，从而优化对象的不同场景下的使用效率\\n3. 对象系统还可以基于引用计数的内存回收机制，自动释放对象所占用的内存，或者还可以让多个键共用同一个值对象\\n4. redis对象带有访问时间记录信息，使用该信息可以进行优化空转时长较大的key，进行删除\\n\\n#### object结构\\n\\n```c\\ntypedef struct redisObject {\\n  unsigned tyoe:4;\\t// 类型\\n  unsigned encoding:4;\\t// 编码类型\\n  void *ptr;\\t// 指向底层数据的指针\\n  ……\\n}\\n```\\n\\n### 2. redis编码类型\\n\\n编码类型：\\n\\n| 编码常量                  | 编码对应的底层数据结构     |\\n| ------------------------- | -------------------------- |\\n| redis_encoding_int        | long类型的整型             |\\n| redis_encoding_embstr     | embstr编码的简单动态字符串 |\\n| redis_encoding_raw        | 简单动态字符串             |\\n| redis_encoding_ht         | HashTable                  |\\n| redis_encoding_linkedlist | 双向链表                   |\\n| redis_encoding_ziplist    | 压缩列表                   |\\n| redis_encoding_intset     | 整数集合                   |\\n| redis_encoding_skiplist   | 跳跃表和字典               |\\n\\n### 3. 底层结构\\n\\n#### 3.1 ziplist\\n\\n压缩列表是 Redis 自己设计的一种数据存储结构。它有点儿类似数组，通过一片连续的内存空间，来存储数据。不过，它跟数组不同的一点是，它允许存储的数据大小不同。具体的存储结构也非常简单\\n\\n![ziplist](https://static.mittacy.com/blog/20200921230706.jpg)\\n\\n压缩列表这种存储结构，优点：\\n\\n+ 一方面比较节省内存\\n+ 另一方面可以支持不同类型数据的存储\\n+ 而且，因为数据存储在一片连续的内存空间，通过键来获取值为列表类型的数据，读取的效率也非常高\\n\\n#### 3.2 linkedlist\\n\\nRedis 的这种双向链表的实现方式，非常值得借鉴。它额外定义一个 list 结构体，来组织链表的首、尾指针，还有长度等信息。这样，在使用的时候就会非常方便。\\n\\n```C\\n// 以下是C语言代码，因为Redis是用C语言实现的。\\ntypedef struct listnode {\\n  struct listNode *prev;\\n  struct listNode *next;\\n  void *value;\\n} listNode;\\n\\ntypedef struct list {\\n  listNode *head;\\n  listNode *tail;\\n  unsigned long len;\\n  // ....省略其他定义\\n} list;\\n```\\n\\n#### 3.3 字典\\n\\nRedis 使用`MurmurHash2`这种运行速度快、随机性好的哈希算法作为哈希函数。对于哈希冲突问题，Redis 使用链表法来解决。除此之外，Redis 还支持散列表的动态扩容、缩容。\\n\\n+ 当数据动态增加之后，散列表的装载因子会不停地变大。当装载因子大于 1 的时候，Redis 会触发扩容，将散列表扩大为原来大小的 2 倍左右（具体值需要计算才能得到）\\n+ 当数据动态减少之后，为了节省内存，当装载因子小于 0.1 的时候，Redis 就会触发缩容，缩小为字典中数据个数的大约 2 倍大小（这个值也是计算得到的）\\n\\n扩容缩容要做大量的数据搬移和哈希值的重新计算，所以比较耗时。针对这个问题，Redis 使用渐进式扩容缩容策略，将数据的搬移分批进行，避免了大量数据一次性搬移导致的服务停顿。\\n\\n#### 3.4 skipList\\n\\n使用了zset结构，包含一个字典和一个跳跃表\\n\\n```c\\ntype struct zset {\\n  Zskiplist *zsl;\\n  dict *dict;\\n  ……\\n}\\n```\\n\\n### 4. 数据类型使用的结构\\n\\n每种Object对象至少有两种不同的编码，对应关系：\\n\\n#### 4.1 String\\n\\n+ int  `整数值实现`\\n+ embstr  `sds <= 39字节`\\n+ raw  `sds实现 >= 39字节`\\n\\n#### 4.2 List\\n\\n+ ziplist 压缩列表\\n+ linkedlist 双向列表\\n\\n使用ziplist条件：\\n\\n1. list对象保存的所有字符串元素长度都小于64字节\\n2. list对象保存的元素数量小于512个\\n\\n#### 4.3 Hash\\n\\n+ ziplist  压缩列表\\n    + 保存同一个键值对的两个节点紧靠相邻，键key在前，值value在后\\n    + 先保存的键值对在压缩列表的表头\\n+ hashtable  哈希\\n    + 字典的键位字符串对象，保存键key\\n    + 值也为字符串对象，保存键值对的值\\n\\n使用ziplist条件：\\n\\n1. list对象保存的所有字符串元素的长度都小于64字节\\n2. 保存的元素数量小于512个\\n\\n这两个上限值是可以修改的，配置文件`hash-max-zaiplist-value`和`hash-max-ziplist-entries`\\n\\n#### 4.4 Set\\n\\n+ intset  `使用整数集合作为底层实现，set对象包含的所有元素都被保存在intset整数集合里面`\\n+ hashtable  `使用散列表key存储一个set元素，而散列表value都为null`\\n\\n使用intset条件：\\n\\n1. 保存的所有元素都是整数值\\n2. 保存的元素数量不超过512个\\n\\n#### 4.5 Zset\\n\\n+ ziplist\\n\\n    + 每个集合元素使用相邻的两个压缩列表结点保存，一个保存元素成员，一个保存元素的分值，然后根据分数进行从大到小排序\\n+ skiplist\\n\\n使用ziplist条件：\\n\\n1. 有序集合保存的元素数量小于128个\\n2. 有序集合保存的所有元素的长度都小于64字节\\n\\n可以通过配置文件中 `zset-max-ziplist-entries` 和 `zset-max-ziplist-value` 修改\\n\\n## 三. 数据库操作\\n\\n+ Select 切换到指定的数据库，数据库索引号 `index` 用数字值指定，以 `0` 作为起始索引值\\n+ Exists 判断key是否存在\\n+ Type 返回key的类型\\n+ Rename 重命名key，如果newName存在，则覆盖原数据\\n+ RenameNX 仅当newName不存在时才操作修改key的name为newName\\n+ Move 移动key到其他数据库\\n+ RandomKey 随机返回一个key\\n+ DBSize 返回当前数据库的key数量\\n+ Keys\\n    + `KEYS *` 匹配数据库中所有 `key` \\n    + `KEYS h?llo` 匹配 `hello` ， `hallo` 和 `hxllo` 等\\n    + `KEYS h*llo` 匹配 `hllo` 和 `heeeeello` 等\\n    + `KEYS h[ae]llo` 匹配 `hello` 和 `hallo` ，但不匹配 `hillo`\\n+ FlushDB 清空当前数据库中的所有 key\\n+ FlushAll 清空整个 Redis 服务器的数据(删除所有数据库的所有 key )\\n+ SwapDB 交换两个数据库的数据\\n+ Scan `SCAN cursor [MATCH pattern] [COUNT count]`\\n\\n## 四. 事务\\n\\n事务中的多条命令被一次性发送给服务器，而不是一条一条地发送，这种方式被称为流水线，它可以减少客户端与服务器之间的网络通信次数从而提升性能\\n\\nRedis 最简单的事务实现方式是使用 `MULTI` 和 `EXEC` 命令将事务操作包围起来\\n\\n不同于Mysql事务，这种事务如果在中间执行遇到错误失败了，就会中断事务后续的命令就不会执行，**但是前面已经执行生效的不会回滚**\\n\\n~~~shell\\n127.0.0.1:6379> MULTI\\n127.0.0.1:6379> 操作命令\\n127.0.0.1:6379> EXEC\\n~~~\\n\\n**Redis 事务命令**\\nredis 事务的相关命令：\\n\\n+ **DISCARD** 取消事务，放弃执行事务块内的所有命令。\\n+ **EXEC** 执行所有事务块内的命令。\\n+ **MULTI** 标记一个事务块的开始。\\n+ **UNWATCH** 取消 WATCH 命令对所有 key 的监视。\\n+ **WATCH key [key …]** 监视一个 (或多个) key ，如果在事务执行之前这个 (或这些) key 被其他命令所改动，那么事务将被打断。\\n\\n## 五. 持久化\\n\\n### 1. 数据结构的持久化\\n\\nRedis 的数据格式由“键”和“值”两部分组成。而“值”又支持很多数据类型，比如字符串、列表、字典、集合、有序集合。像字典、集合等类型，底层用到了散列表，散列表中有指针的概念，而指针指向的是内存中的存储地址。 那 Redis 是如何将这样一个跟具体内存地址有关的数据结构存储到磁盘中的呢？\\n\\n这个问题并不特殊，很多场景中都会遇到。我们把它叫作数据结构的持久化问题，或者对象的持久化问题。这里的“持久化”，可以笼统地理解为“存储到磁盘”。\\n\\n主要有两种解决思路：\\n\\n+ **清除原有的存储结构**，只将数据存储到磁盘中。当我们需要从磁盘还原数据到内存的时候，再重新将数据组织成原来的数据结构。实际上，Redis 采用的就是这种持久化思路。这种方式也有一定的弊端。那就是数据从硬盘还原到内存的过程，会耗用比较多的时间\\n+ **保留原来的存储格式**，将数据按照原有的格式存储在磁盘中。我们拿散列表这样的数据结构来举例。我们可以将散列表的大小、每个数据被散列到的槽的编号等信息，都保存在磁盘中。有了这些信息，我们从磁盘中将数据还原到内存中的时候，就可以避免重新计算哈希值。\\n\\n### 2. redis持久化\\n\\n~~~sql\\n-- 获取redis安装目录\\n127.0.0.1:6379> config get dir\\n1) \\\"dir\\\"\\n2) \\\"/usr/local/var/db/redis\\\"\\n-- 备份数据(所有数据库)，将在redis安装目录生成dump.rdb文件\\n127.0.0.1:6379> save\\n127.0.0.1:6379> Bgsave\\t-- 在后台保存\\n-- 恢复数据，只需将备份文件 (dump.rdb) 移动到 redis 安装目录并启动服务即可\\n~~~\\n\\n#### 2.1 RDB持久化\\n\\n即快照式保存。Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump.rdb。可以配置Redis的持久化策略，例如数据集中每N秒钟有超过M次更新，就将数据写入磁盘；或者你可以手工调用命令SAVE或BGSAVE\\n\\n#### 2.2 AOF持久化\\n\\n*将写命令添加到 AOF 文件末尾*\\n选项同步频率：always每个写命令都同步、eyerysec每秒同步一次、no让操作系统来决定何时同步\\n\\n+\\talways 选项会严重减低服务器的性能\\n+\\teverysec 比较合适，可以保证系统崩溃时只会丢失一秒左右的数据，并且 Redis 每秒执行一次同步对服务器几乎没有任何影响\\n+\\tno 选项并不能给服务器性能带来多大的提升，而且会增加系统崩溃时数据丢失的数量。\\n    随着服务器写请求的增多，AOF 文件会越来越大。Redis 提供了一种将 AOF 重写的特性，能够去除 AOF 文件中的冗余写命令\",\"category\":\"缓存设计\",\"createTime\":\"2020/10/5 15:00:00\"},{\"id\":\"1630738548200\",\"name\":\"缓存系统稳定性\",\"title\":\"缓存系统稳定性\",\"content\":\"\\n\\n+ 稳定性\\n    + 缓存穿透\\n    + 缓存击穿\\n    + 缓存雪崩\\n+ 缓存一致性\\n+ 缓存机制\\n    + 单行查询缓存\\n    + 多行查询缓存\\n+ 可观测 - 缓存监控\\n+ 规范 - 使用工具生成打桩代码\\n\\n## 一. 稳定性\\n\\n### 1. 缓存穿透\\n\\n+ **问题描述：**查询一个根本不存在的数据，缓存肯定不存在，所以需要到数据去查询，查不到数据不回种到缓存，这将导致每次查询这个数据都要到数据库去查询。\\n\\n    这样当大量请求不存在的数据时DB压力就会特别大，尤其是攻击者发现一个数据不存在，然后就大量发起对这个不存在数据的请求\\n\\n+ **解决方案：**\\n\\n    + 缓存空对象：设置短暂过期时间（比如一分钟），该方法需要特别注意，当业务新增数据时，需要请求缓存删除该占位符，避免数据不一致\\n\\n    + 布隆过滤器：将所有可能存在的数据哈希到一个bitmap中，一个一定不存在的数据会被这个哈希过滤掉\\n\\n        > 一个值通过hash计算后将bit数组的对应k个位置置位1就可以了。查询一个值是否存在，只需要hash后判断对应的位是否都为1即可。\\n        >\\n        > + 可能要查询的元素并不存在，但是hash之后得到的k个位置上值都是1，也会导致缓存穿透，可以通过建立一个黑名单来存储可能会误判的元素\\n        > + 删除困难。一个放入容器的元素映射到bit数组的k个位置上是1，删除的时候不能简单的直接置为0，可能会影响其他元素的判断。可以采用[Counting Bloom Filter](http://wiki.corp.qunar.com/confluence/download/attachments/199003276/US9740797.pdf?version=1&modificationDate=1526538500000&api=v2)\\n\\n### 2. 缓存击穿\\n\\n+ **问题描述：** 缓存击穿的原因是热点数据的过期，因为是热点数据，所以一旦过期可能就会有大量对该热点数据的请求同时过来，这是如果所有请求在缓存里都招不到数据同时去请求 DB 的话，会造成 DB 很大的压力，甚至直接卡死\\n+ **解决方案：** 解决方案的关键在于，只允许一个请求去到 DB 查询，回种缓存，其他请求共享该缓存即可\\n    + 进程锁：并发量不是很高的情况，如果不是特别需要，推荐进程内的锁即可，毕竟引入分布式锁会增加复杂度和成本\\n    + 分布式锁：并发量很高的情况，可以使用 redis 的 `set k v ex nx` 命令，设置成功即拿到了锁，注意设置过期时间\\n\\n### 3. 缓存雪崩\\n\\n+ **问题描述：**大量同时加载的缓存有相同的过期时间，在过期时间到达的时候出现短时间内大量缓存过期，多个请求同时落到 DB 去，从而使 DB 压力激增，甚至卡死\\n\\n+ **解决方案：**\\n\\n    + 首先是做到防止 单点故障 导致的缓存雪崩，所以需要使用分布式缓存\\n\\n    + 指定范围内的随机过期时间，比如过期时间加上 5% 的标志偏差\\n\\n        > 如果用1万个数据，过期时间设为1小时，标准偏差设为5%，那么过期时间会比较均匀的分布在3400~3800秒之间。如果我们的默认过期时间是7天，那么就会均匀分布在以7天为中心点的16小时内。这样就可以很好的防止了缓存的雪崩问题\\n\\n## 二. 缓存一致性\\n\\n对缓存的删除是只删除，不更新，一旦DB里数据出现修改，我们就会直接删除对应的缓存\\n\\n那么删除缓存的顺序怎样才是正确的？\\n\\n+ 先删除缓存，再更新 DB\\n\\n    有两个并发请求，A请求需要更新数据，先删除了缓存；B请求来读取数据，此时缓存没有数据，就会从 DB 加载数据并回种缓存；然后 A 更新了 DB。那么此时缓存内的数据就会一直是脏数据，知道缓存过期或者有新的更新数据请求\\n\\n+ 先更新 DB，再删除缓存\\n\\n    有两个并发请求，A 请求先更新 DB；B请求数据从缓存读到了老数据；然后 A 删除了缓存，后续的请求都会拿到最新数据\\n\\n综上，应该先更新 DB，再删除缓存\\n\\n## 三. 缓存内容\\n\\n### 1. 单行查询缓存\\n\\n+ 部分数据查询 - 不推荐使用，无法缓存(一致性难以保障)\\n\\n+ 完整数据查询\\n\\n    + 基于主键查询\\n\\n        这种相对来讲是最容易处理的缓存，只需要在 `redis` 里用 `primary key` 作为 `key` 来缓存行记录即可\\n\\n    + 基于单列唯一索引查询\\n\\n        可以通过单列索引查询整行记录，在 `redis` 里用 `primary key` 作为 `key` 来缓存行记录，同时缓存唯一索引到主键索引的映射\\n\\n        ![](http://static.mittacy.com/blog/202109041452484.png)\\n\\n    + 基于多列唯一索引查询，和单列唯一索引一样\\n\\n单行缓存伪代码如下，实现功能：\\n\\n+ 防止数据不一致\\n+ 防止缓存击穿\\n+ 防止缓存穿透\\n+ 防止缓存雪崩\\n\\n```go\\nfunc QueryRow(...) error {\\n    singleflight {\\n        read cache\\n        \\n        // 1. 数据不存在占位符缓存，防止缓存穿透\\n        if placeholder {\\n            return not found\\n        }\\n        \\n        // 2. 有缓存直接返回\\n        if has cache {\\n            return val\\n        }\\n        \\n        // 3. 无缓冲，查询 DB，限制单个请求，防止缓存击穿\\n        query db\\n        \\n        // 4. 数据不存在，缓存占位符，防止缓存穿透\\n        if not found {\\n            set cache with not found palceholder\\n            return not found\\n        }\\n        \\n        // 5. 数据存在，缓存并使用随机过期时间，防止缓存雪崩\\n        set cache\\n        \\n        // 6. 返回数据\\n        return val\\n    }\\n}\\n```\\n\\n### 2. 多行查询缓存\\n\\n#### 不易变列表\\n\\n比如商铺的商品列表\\n\\n+ ID 存放在 redis 的 sorted set 中\\n+ 整行数据存放在 Hash 中，键值为 id \\n+ 修改友好，单条缓存删除\\n\\n![](http://static.mittacy.com/blog/202109041453719.png)\\n\\n#### 易变列表\\n\\n比如信息流时间线\\n\\n+ ID 放在 redis 的 sorted set 中\\n+ 整行数据存放在 Hash 中，键值为 id \\n+ 前面加，后面键\\n+ 单列 DB 查询 + 缓存\\n\\n![](http://static.mittacy.com/blog/202109041453524.png)\\n\\n## 四. 缓存监控\\n\\n+ 缓存是否必须\\n+ 过期时间是否合适\\n+ 命中率如何\\n+ 是否需要进一步调优\\n\\n\\n\\n\\n\\n\\n\\n___\\n\\n[缓存系统稳定性 - 架构师峰会演讲实录](https://mp.weixin.qq.com/s/o0qUY5zUjBQuOkx_4XGB6Q)\\n\\n[缓存设计的好，服务基本不会倒](https://mp.weixin.qq.com/s?__biz=Mzg2ODU1MTI0OA==&mid=2247484205&idx=1&sn=20123bff8f8ef1acb26b4e34d598f8fb&chksm=ceabdc12f9dc5504a07a3cd89eafd8486bfc5bff558b3078473cd6b9a08df0a89ce27639d73f&scene=21#wechat_redirect)\\n\",\"category\":\"缓存设计\",\"createTime\":\"2021/09/04 14:55:00\",\"banner\":\"http://static.mittacy.com/blog/202109061034950.jpg\"},];\n      export default arr;","/* tslint:disable */\n      const arr: any = [{\"title\":\"ego\",\"articles\":[{\"title\":\"项目架构\",\"articles\":[{\"id\":null,\"title\":\"项目架构\",\"content\":\"本项目是对 Gin 的二次封装，便于快速开发业务服务\\n\\n> 1. 这是一个基于 Go 语言、Gin 框架的 Web 项目骨架，对常用的库进行封装，开发者可以更快速搭建 Web 服务，更关注属于自己的业务\\n> 2. 项目要求 Go 版本 >= 1.15\\n> 3. 拉取本项目骨架，在此基础上就可以快速开发自己的项目\\n\\n### 1. 项目架构\\n\\n![](https://static.mittacy.com/blog/202111031602019.png)\\n\\n- middleware：全局中间件，所有路由都会经过这些中间件\\n\\n- router 层：定义路由，调用 api 层各个方法。每个路由也可以有自己的中间件。**建议分成两部分，高级权限的路由统一前缀管理，防止调用错路由**\\n\\n- api层：包含一个或多个 service\\n\\n    1. 调用 validator 层的请求结构体，解析请求参数，如果失败直接返回结果；\\n    2. 调用一个或多个 service 服务，获得返回结果；\\n    3. 调用 transform 对service返回的数据进行处理，然后响应给前端\\n\\n- service 层：service 包含 data 或者调用其他 service\\n\\n    1. 处理各种业务逻辑\\n    2. 调用 data 方法查询或存储数据、调用其他 service 完成操作\\n\\n- data 层：包含db、cache、外部http调用服务等，涉及数据的查询和持久化都应该在该层实现\\n\\n    > 不管是mysql、redis、mongo、es还是调用其他服务，这些操作其实都是数据的curd，对service层来说都是数据的查询与持久化，因此这些操作都应该写在data层\\n\\n- model 层：定义数据库结构体、http远程调用响应结构体……\\n\\n> model层与validator层的区别在于：\\n>\\n> + model层定义的是数据的原始结构体，即数据怎么存储那model的结构体就是一一对应的\\n> + validator层定义的结构体为请求与响应数据，即请求接口需要的数据结构、以及响应数据需要的数据结构\\n\\n\\n### 2. 项目结构\\n\\n```shell\\n├── bootstrap\\t\\t\\t\\t\\t# 服务依赖初始化\\n│   ├── http.go\\t\\t\\t\\t\\t# http服务\\n│   ├── job.go\\t\\t\\t\\t\\t# 异步任务服务\\n│   ├── log.go\\n│   ├── task.go\\t\\t\\t\\t\\t# 定时任务服务\\n│   └── viper.go\\n├── apierr\\t\\t\\t\\t\\t\\t# 业务码定义\\n│   └── code.go\\n├── cmd\\n│   └── start\\t\\t\\t\\t\\t\\n│       ├── http\\t\\t\\t\\t# http\\n│       │   └── http.go\\n│       ├── job\\t\\t\\t\\t\\t# 异步任务\\n│       │   └── job.go\\n│       └── task\\t\\t\\t\\t# 定时任务\\n│       │   └── task.go\\n│\\t\\t└── start.go\\t\\t\\t# 服务启动程序\\n├── bin\\t\\t\\t\\t\\t\\t\\t# 可执行文件存储目录，不上传\\n├── config\\t\\t\\t\\t\\t\\t# 配置设置\\n│   ├── async.go\\n│   ├── async_config\\n│   │   └── job.go\\n│   ├── mysql.go\\n│   ├── redis.go\\n│   └── task.go\\n├── middleware\\t\\t\\t\\t\\t# 中间件\\n│   ├── requestLog.go\\n│   └── requestTrace.go\\n├── router\\t\\t\\t\\t\\t\\t# 路由\\n│   ├── admin.go\\n│   └── router.go\\n├── app\\n│   ├── api\\t\\t\\t\\t\\t\\t# api控制器\\n│   │   └── user.go\\n│   ├── job\\n│   │   ├── job_payload\\t\\t\\t# 异步任务数据定义\\n│   │   │   └── example.go\\n│   │   └── job_process\\t\\t\\t# 异步任务处理器\\n│   │       └── example.go\\n│   └── task\\n│       └── example.go\\n├── internal\\n│   ├── data\\n│   │   └── user.go\\n│   ├── model\\n│   │   └── user.go\\n│   ├── service\\n│   │   └── user.go\\n│   ├── transform\\t\\t\\t# 响应数据处理、封装\\n│   │   └── user.go\\n│   └── validator\\t\\t\\t# 数据请求与参数校验、响应结构体\\n│       └── userValidator\\n│           └── user.go\\n├── main.go\\n├── hook.go\\t\\t\\t\\t\\t\\t# 服务钩子定义\\n├──.env\\t\\t\\t\\t\\t\\t\\t# 本地环境配置\\n├──.env.development\\t\\t\\t\\t# 开发环境配置\\n├──.env.production\\t\\t\\t\\t# 生产环境配置\\n```\\n\"}]},{\"title\":\"快速开始\",\"articles\":[{\"id\":null,\"title\":\"01 | 创建项目\",\"content\":\"### 1. 环境准备\\n\\n需要提前安装好对应的依赖环境以及工具：‌\\n\\n- 安装go环境，version >= 1.16\\n- 安装Mysql（如果需要）\\n- 安装Redis（如果需要）\\n\\n建议开启GO111MODULE\\n\\n```shell\\n$ go env -w GO111MODULE=on\\n$ go env -w GOPROXY=https://goproxy.cn,direct\\n```\\n\\n### 2. 安装\\n\\n安装 ego 命令工具\\n\\n#### go get 安装\\n\\n```shell\\n$ go get -u github.com/mittacy/ego@latest\\n```\\n\\n### 3. 创建项目\\n\\n```shell\\n# 创建项目模板\\n$ ego new projectName\\n```\\n\\n### 4. 修改配置文件\\n\\n配置文件位于项目根目录 `.env.development`，修改对应的配置信息：\\n\\n+\\t`APP_*` 服务信息\\n+\\t`DB_*` mysql信息\\n+\\t`REDIS_*` redis信息\\n\\n### 5. 启动服务\\n\\n#### 5.1 使用命令启动\\n\\n```shell\\n$ cd myProjectName\\n$ go mod download\\n$ go build -o ./bin/server .\\n\\n# 运行异步任务服务\\n$ ./bin/server start job -c=.env.development -e=development\\n\\n# 运行定时任务\\n$ ./bin/server start task -c=.env.development -e=development\\n\\n# 运行HTTP服务\\n$ ./bin/server start http -c=.env.development -e=development -p=8080\\n\\n$ curl localhost:8080/api/user/ping\\n{\\\"code\\\":0,\\\"data\\\":\\\"success\\\",\\\"msg\\\":\\\"success\\\",\\\"request_id\\\":\\\"r61f641e8bf370_pkL0LEODq4N2PyASnn\\\"}\\n```\\n\\n> Flags:\\n> -c, --conf string   配置文件路径 (default \\\".env.development\\\")\\n> -e, --env string    运行环境 (default \\\"development\\\")\\n>\\n> + development 会将日志同步打印到控制台\\n>\\n> + test/production 不会将日志打印到控制台，正式环境应该设置为 production\\n>\\n>     -p, --port int      监听端口 (default 8080)\\n\\n#### 5.2 Docker启动\\n\\n```shell\\n$ docker build -t 镜像名 .\\n\\n# 启动http服务\\n$ docker run --restart=on-failure --name 服务名1 -d -p 宿主端口:8080 镜像名 start http -c=.env.development -e=production -p=8080\\n# 简写\\n$ docker run --restart=on-failure --name 服务名1 -d -p 宿主端口:8080 镜像名\\n\\n# 启动job异步服务\\n$ docker run --restart=on-failure --name 服务名2 -d -p 宿主端口:8080 镜像名 start job -c=.env.development -e=production\\n\\n# 启动task定时服务\\n$ docker run --restart=on-failure --name 服务名2 -d -p 宿主端口:8080 镜像名 start task -c=.env.development -e=production\\n```\\n\\n#### 5.3 使用 systemctl 启动\\n\\n以http服务为例，job、task同理\\n\\n```shell\\n$ cd /usr/lib/systemd/system\\n$ vim 服务名_http.service\\n[Unit]\\nDescription=服务名_http.service\\nAfter=network.target\\n[Service]\\nType=simple\\nEnvironment=APP_ENV=production\\nWorkingDirectory=项目根目录\\nExecStart=项目根目录/bin/server start http -c=.env.development -e=production -p=13140\\nRestartSec=1s\\nRestart=always\\nKillMode=process\\nUser=www\\nGroup=www\\n[Install]\\nWantedBy=multi-user.target\\n\\n$ systemctl start 服务名_http.service\\n```\\n\\n### 项目模板\\n\\nego 是通过在线 github 仓库模板，并且进行拉取创建项目，对应模板地址：‌[ego-layout](https://github.com/mittacy/ego-layout)\\n\\n\"},{\"id\":null,\"title\":\"02 | 业务编码\",\"content\":\"+ 编写API文档\\n+ validator 请求结构定义\\n+ model 数据库结构定义\\n+ transform 响应数据包装、处理\\n+ api 接口，服务编排\\n+ service 业务逻辑处理\\n+ data 数据持久化、缓存等处理\\n+ router 路由编写\\n+ 测试\\n+ 完善API文档\\n\\n\\n\\n以下举例：接到一个**获取用户列表**的接口需求\\n\\n### 1. 编写API文档\\n\\n在YAPI文档中添加该路由并定义请求参数，响应参数可以暂时不定义\\n\\n![](http://static.mittacy.com/blog/202112121748210.png)\\n\\n### 2. validator 请求、响应结构定义\\n\\nvalidator 定义请求与响应结构体，每个请求体的参数必须通过定义结构体定义，在结构体中添加限制对请求参数进行校验，位于 `internal/validator/xxxValidator/`\\n\\n```go\\npackage validator\\n\\ntype ListReq struct {\\n\\tPage     int `form:\\\"page\\\" binding:\\\"required,min=1\\\"`\\n\\tPageSize int `form:\\\"page_size\\\" binding:\\\"required,min=1,max=50\\\"`\\n}\\n```\\n\\n同样的，响应数据也应该定义结构体进行响应，防止将不必要的字段返回给前端，比如说查询出的用户可能包含密码等敏感字段，通过我们的 reply 结构体转化后，就只剩下 `id`、`name`、`created_at`、`updated_at` 四个字段\\n\\n```go\\ntype ListReply struct {\\n    Users []ListUserReply `json:\\\"users\\\"`\\n    Total int64\\t\\t\\t  `json:\\\"total\\\"`\\n}\\n\\ntype ListUserReply struct {\\n    Id        int64  `json:\\\"id\\\"`\\n\\tName      string `json:\\\"name\\\"`\\n\\tCreatedAt int64  `json:\\\"created_at\\\"`\\n\\tUpdatedAt int64  `json:\\\"updated_at\\\"`\\n}\\n```\\n\\n**响应结构定义应该多包一层，比如这里给用户列表包了一层users，即使这里是获取用户详情，也建议多包一层 user代表用户信息，方便扩展增加其他信息，我们的业务API一般是面向业务而不是面向资源，往往不是获取对单一资源的操作**\\n\\n### 3. model 层\\n\\n确定好该接口涉及的数据库表，这里只涉及到 `user` 表\\n\\n```go\\npackage model\\n\\nconst (\\n\\tUserDeletedNo = 0\\n\\tUserDeletedYes = 1\\n)\\n\\ntype User struct {\\n\\tId        int64  `json:\\\"id\\\"`\\n\\tName      string `json:\\\"name\\\"`\\n\\tDeleted   int8   `json:\\\"deleted\\\"`\\n\\tCreatedAt int64  `json:\\\"created_at\\\" gorm:\\\"autoCreateTime\\\"`\\n\\tUpdatedAt int64  `json:\\\"updated_at\\\" gorm:\\\"autoUpdateTime\\\"`\\n}\\n\\n// TableName 重写gorm默认的表名映射\\nfunc (*User) TableName() string {\\n\\treturn \\\"user\\\"\\n}\\n```\\n\\n> 如果数据库字段很多，建议使用工具生成代码，这里推荐：https://www.qetool.com/sql_json_go.html\\n\\n数据库所有的状态类字段应该定义为常量存储在 model 层，比如上面定义的 `UserDeletedNo` 和 `UserDeletedYes` 。好处是在 data 层统一使用这些变量，不需要记忆数字状态码，当数据库状态码代表的意义变更时，也不需要修改 `data` 层，只需要 model 层统一修改即可。\\n\\n可能 deleted 看起来没那么明显，举另一个例子，如果有个 `state` 代表用户状态：\\n\\n+ 1：群主\\n+ 10：管理员\\n+ 20：普通用户\\n\\n我们在 model 层定义三个变量\\n\\n```go\\nconst (\\n    UserStateOwner = 1\\t\\t// 这里也不建议使用枚举iota，后期修改的时候一不小心就会改错\\n    UserStateAdmin = 10\\n    UserStateNormal = 20\\n)\\n```\\n\\n在操作数据库的时候，统一调用 UserStateOwner、UserStateAdmin、UserStateNormal，完全不用记住、关心1、10、20 是什么东西\\n\\n**另外，如果该参数可能需要前端传参，不建议使用0、空字符串等go中各种类型的默认值，因为请求参数不传就会是类型的默认空值，只能通过指针来判断参数是否有传递，很不方便，尽量在数据库设计的时候就避免**\\n\\n### 4. transform层\\n\\n建议每个查询API都对应一个数据处理函数对响应数据进行聚合、裁剪，底层可以定义一些通用的封装方法\\n\\n```go\\npackage transform\\n\\nvar User userTransform\\n\\ntype userTransform struct{}\\n\\n// ListReply 列表响应包装\\n// @param data 数据库列表数据\\n// @param totalSize 记录总数\\nfunc (ctl *User) ListReply(c *gin.Context, req interface{}, data []model.User, total int64) {\\n\\tusers, err := ctl.UsersPack(data)\\n\\tif err != nil {\\n        log.New(\\\"user\\\").ErrorwWithTrace(c, \\\"copier\\\", \\\"req\\\", req, \\\"err\\\", err)\\n\\t\\tresponse.Unknown(c)\\n\\t\\treturn\\n\\t}\\n\\n\\tres := map[string]interface{}{\\n\\t\\t\\\"users\\\": users,\\n\\t\\t\\\"total\\\": total,\\n\\t}\\n\\n\\tresponse.Success(c, res)\\n}\\n\\n// UsersPack 数据库数据转化为响应数据\\n// @param data 数据库数据\\n// @return reply 响应体数据\\n// @return err\\nfunc (ctl *User) UsersPack(data []model.User) (reply []userValidator.ListUserReply, err error) {\\n\\terr = copier.Copy(&reply, &data)\\t// 使用反射赋值，追求性能问题可自行创建并赋值\\n\\treturn\\n}\\n```\\n\\n### 5. api接口层\\n\\n接口层只负责请求解析、服务编排与响应，不要编写业务逻辑\\n\\n```go\\npackage api\\n\\nvar User userApi\\n\\ntype userApi struct{}\\n```\\n\\n编写用户列表API\\n\\n```go\\nfunc (ctl *userApi) List(c *gin.Context) {\\n    req := userValidator.ListReq{}\\n    \\n    // 1. 创建请求结构体，解析请求数据并校验，校验不通过直接调用ValidateErr返回\\n    if err := c.ShouldBindQuery(&req); err != nil {\\n        response.ValidateErr(c, err)\\n        return\\n    }\\n\\n    // 2. 调用服务\\n    user, total, err := service.User.List(req.Page, req.PageSize, true)\\n    if err != nil {\\n        response.CheckErrAndLog(c, log.New(\\\"user\\\"), req, \\\"userList\\\")\\n        return\\n    }\\n\\n    // 3. 调用 transform 数据封装并响应\\n    transform.User.ListReply(c, req, user, total)\\n}\\n```\\n\\n### 6. service层\\n\\nservice 层涉及业务逻辑编写，比如创建用户时对用户密码的加密等操作都应该在 service 层，service 内调用 data 服务来操作数据。service 层并不关心数据如何获取、如何存储，而是通过调用 data 接口获取和存储数据。\\n\\n**service层应该尽量避免跨服务调用data，应该通过调用其他service来实现，避免直接调用data层忽略了某些必要的服务处理逻辑，应该找对应服务的负责人询问调用哪个service服务合适**\\n\\n```go\\npackage service\\n\\n// 一般情况下service应该只包含并调用自己的data模型，需要其他服务的功能请service.Xxx调用服务而不是引入其他data模型\\n// User 用户服务\\nvar User = userService{\\n\\tdata: data.NewUser(),\\n}\\n\\ntype userService struct {\\n\\tdata data.User\\n}\\n\\n// List 列表\\n// @param page 页码，从1开始\\n// @param pageSize 页容量\\n// @param getTotal 是否查询总记录数\\n// @return []model.User\\n// @return int 总记录数\\n// @return error\\nfunc (ctl *userService) List(c *gin.Context, page, pageSize int, getTotal bool) (users []model.User, totalSize int64, err error) {\\n    fields := []string{\\\"id\\\", \\\"name\\\", \\\"created_at\\\", \\\"updated_at\\\"}\\n\\n    // 查询列表\\n    if users, err = data.User.List(c, fields, page, pageSize); err != nil {\\n        return\\n    }\\n    \\n    // 查询总记录数\\n    if getTotal {\\n        if totalSize, err = ctl.userData.GetSum(c); err != nil {\\n        \\treturn\\n    \\t}\\n    }\\n    \\n    return users, totalSize, nil\\n}\\n```\\n\\n### 7. data层\\n\\ndata 层就是数据操作层，包含持久化、缓存、外部服务调用等的操作，首先定义数据操作结构体包含 mysql 和 redis 的操作句柄\\n\\n```go\\npackage data\\n\\ntype User struct {\\n\\teMysql.EGorm\\n\\teRedis.ERedis\\n\\tcacheKeyPre string\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tEGorm: eMysql.EGorm{\\n\\t\\t\\tMysqlConfName: \\\"localhost\\\",\\n\\t\\t},\\n\\t\\tERedis: eRedis.ERedis{\\n\\t\\t\\tRedisConfName: \\\"localhost\\\",\\n\\t\\t\\tRedisDB:       0,\\n\\t\\t},\\n\\t\\tcacheKeyPre: fmt.Sprintf(\\\"%s:user\\\", viper.GetString(\\\"APP_NAME\\\")),\\n\\t}\\n}\\n```\\n\\n编写List方法\\n\\n```go\\n// List 按时间排序列表\\nfunc (ctl *User) List(c *gin.Context, selectFields []string, page, pageSize int) ([]model.User, error) {\\n\\tstartIndex := (page - 1) * pageSize\\n\\n\\tvar users []model.User\\n\\n\\tif err := ctl.GDB().Select(selectFields).Where(\\\"deleted != ?\\\", model.UserDeletedYes).\\n\\t\\tOffset(startIndex).Limit(pageSize).Order(\\\"created_at\\\").Find(&users).Error; err != nil {\\n\\t\\treturn nil, errors.WithStack(err)\\n\\t}\\n\\n\\treturn users, nil\\n}\\n\\n// GetSum 获取总记录数，会缓存\\nfunc (ctl *User) GetSum(c *gin.Context) (int64, error) {\\n\\t/*\\n\\t * 1. 从 redis 读取\\n\\t * 2. 不存在 => 数据库查询，存入 redis\\n\\t * 3. 从 redis 读取, 返回\\n\\t */\\n\\t// 从缓存库查询\\n\\tcount, err := ctl.RDB().Get(context.Background(), ctl.cacheSumKey()).Int64()\\n\\n\\t// 缓存查询出错\\n\\tif err != nil && !errors.Is(err, redis2.Nil) {\\n\\t\\treturn 0, errors.WithStack(err)\\n\\t}\\n\\n\\t// 不存在, 从数据库查询并存入redis\\n\\tif errors.Is(err, redis.Nil) {\\n\\t\\tcount, err = ctl.GetSumFromDB()\\n\\t\\tif err != nil {\\n\\t\\t\\treturn 0, err\\n\\t\\t}\\n\\n\\t\\t// 缓存不成功只记录错误日志，但可以返回成功\\n\\t\\tif err = ctl.RDB().Set(context.Background(), ctl.cacheSumKey(), strconv.FormatInt(count, 10), time.Hour).Err(); err != nil {\\n\\t\\t\\tlog.New(\\\"user\\\").ErrorwWithTrace(c, \\\"缓存失败\\\", \\\"err\\\", err)\\n\\t\\t}\\n\\t}\\n\\n\\t// 返回\\n\\treturn count, nil\\n}\\n\\n// GetSumFromMysql 从mysql查询用户总记录数，不会缓存\\nfunc (ctl *User) GetSumFromDB() (int64, error) {\\n\\tuser := model.User{}\\n\\tvar count int64\\n\\n\\terr := ctl.GDB().Model(&user).Select(\\\"count(*)\\\").Where(\\\"deleted = ?\\\", model.UserDeletedNo).Find(&count).Error\\n\\n\\tif err != nil {\\n\\t\\treturn 0, err\\n\\t}\\n\\n\\treturn count, nil\\n}\\n```\\n\\n### 8. router 层\\n\\n路由分为两种或者更多，主要区分管理员类权限比较高的接口和普通接口，为了防止前端误调用\\n\\n+ router\\n\\n    + admin.go\\t管理员类权限比较高的接口\\n\\n        ```go\\n        package router\\n        \\n        func InitAdminRouter(r *gin.Engine) {\\n        \\tglobalPath := \\\"/admin/api\\\"\\n        \\tg := r.Group(globalPath)\\n        \\t{\\n        \\t\\tg.DELETE(\\\"/user\\\", api.User.DeleteUser)\\n        \\t}\\n        }\\n        ```\\n        \\n    + router.go    普通接口\\n    \\n        ```go\\n        package router\\n        \\n        func InitRouter(r *gin.Engine) {\\n        \\tglobalPath := \\\"/api\\\"\\n        \\tg := r.Group(globalPath)\\n        \\t{\\n        \\t\\tg.GET(\\\"/users\\\", api.User.List)\\n        \\t}\\n        }\\n        ```\\n\\n### 9. 测试\\n\\n至此，所有代码都完成了，开发者应该在本地自行进行测试，首先需要用到 mysql 和 redis\\n\\n在配置文件填写对应信息：\\n\\n```yaml\\n# Mysql-localhost\\nDB_LOCALHOST_RW_HOST = 127.0.0.1  # 使用docker时localhost须更改为host.docker.internal\\nDB_LOCALHOST_RW_PORT = 3306\\nDB_LOCALHOST_RW_DATABASE = blog\\nDB_LOCALHOST_RW_USERNAME = root\\nDB_LOCALHOST_RW_PASSWORD = password\\n\\n# Redis-localhost\\nREDIS_LOCALHOST_RW_HOST = 127.0.0.1\\nREDIS_LOCALHOST_RW_PASSWORD =\\nREDIS_LOCALHOST_RW_PORT = 6379\\n```\\n\\n### 10. 完善API文档\\n\\n使用 Yapi、Postman 进行测试，获得响应数据后，将相应数据粘贴到 YAPI 响应数据处即可生成响应结构文档\\n\\n![](http://static.mittacy.com/blog/202112121817770.png)\\n\\n生成的响应文档如下，我们可以给每个字段设置必定返回、添加备注，点击设置按钮还能设置最大、最小、枚举值等功能\\n\\n![](http://static.mittacy.com/blog/202112121818103.png)\\n\\n> 不推荐在代码中加注释后通过命令生成文档：\\n>\\n> + 不安全，如果公司没内网所有人可看到该文档\\n> + 忘记修改\\n> + 语法虽简单，但每次写还是得去找\\n> + Go每次提交代码都会导致重新编译启动浪费资源\\n>\\n> 建议使用 [yapi](http://yapi.smart-xwork.cn/project/98312/interface/api)，后端开发人员可以使用 yapi编写文档并测试接口，修改测试用例的同时也就修改了文档，同时可以编写自动化测试用例，每次编写完成只需要一键即可测试接口。文档只开放给前端只读权限，安全高效\\n\\n\\n\\n___\\n\\n**ego工具提供模板生成功能，不需要自己编写声明，详情查看 [03 | 构建工具 章节](http://www.mittacy.com/column/1633512445750?title=03%20%7C%20%E6%9E%84%E5%BB%BA%E5%B7%A5%E5%85%B7)**\"},{\"id\":null,\"title\":\"03 | 构建工具\",\"content\":\"业务编码章节中，讲到完整的业务编码流程，在 Go 中声明各种结构体、接口还是比较繁琐重复的，建议使用构建工具自动生成\\n\\n### 1. 安装\\n\\n+ 配置go环境\\n\\n    ```shell\\n    $ go env\\n    GOPATH=\\\"/Users/mittacy/go\\\"\\n    GOROOT=\\\"/usr/local/go\\\"\\n    # 配置环境变量，mac如下\\n    $ vim .bash_profile\\n    export GOROOT=/usr/local/go\\n    export GOPATH=/Users/mittacy/go\\n    export GOBIN=$GOPATH/bin\\n    export PATH=$PATH:$GOBIN\\n    ```\\n\\n    > 如果是私有/加密仓库，配置GOPRIVATE\\n    >\\n    > go env -w GOPRIVATE=\\\"仓库域名\\\"\\n\\n+ 确保使用 go module\\n\\n    ```shell\\n    $ GO111MODULE=on\\n    $ GOPROXY=https://goproxy.cn/,direct\\n    ```\\n\\n安装\\n\\n```shell\\n$ go get -u talkcheap.xiaoeknow.com/mittacychen/ego@latest\\n```\\n\\n### 2. 创建项目\\n\\n通过 ego 命令创建项目模板：\\n\\n```bash\\n$ ego new helloworld\\n```\\n\\n输出:\\n\\n```shell\\n├── bootstrap\\t\\t\\t\\t\\t# 服务依赖初始化\\n│   ├── http.go\\t\\t\\t\\t\\t# http服务\\n│   ├── job.go\\t\\t\\t\\t\\t# 异步任务服务\\n│   ├── log.go\\n│   ├── task.go\\t\\t\\t\\t\\t# 定时任务服务\\n│   └── viper.go\\n├── apierr\\t\\t\\t\\t\\t\\t# 业务码定义\\n│   └── code.go\\n├── cmd\\n│   └── start\\t\\t\\t\\t\\t\\n│       ├── http\\t\\t\\t\\t# http\\n│       │   └── http.go\\n│       ├── job\\t\\t\\t\\t\\t# 异步任务\\n│       │   └── job.go\\n│       └── task\\t\\t\\t\\t# 定时任务\\n│       │   └── task.go\\n│\\t\\t└── start.go\\t\\t\\t# 服务启动程序\\n├── bin\\t\\t\\t\\t\\t\\t\\t# 可执行文件存储目录，不上传\\n├── config\\t\\t\\t\\t\\t\\t# 配置设置\\n│   ├── async.go\\n│   ├── async_config\\n│   │   └── job.go\\n│   ├── mysql.go\\n│   ├── redis.go\\n│   └── task.go\\n├── middleware\\t\\t\\t\\t\\t# 中间件\\n│   ├── requestLog.go\\n│   └── requestTrace.go\\n├── router\\t\\t\\t\\t\\t\\t# 路由\\n│   ├── admin.go\\n│   └── router.go\\n├── app\\n│   ├── api\\t\\t\\t\\t\\t\\t# api控制器\\n│   │   └── user.go\\n│   ├── job\\n│   │   ├── job_payload\\t\\t\\t# 异步任务数据定义\\n│   │   │   └── example.go\\n│   │   └── job_process\\t\\t\\t# 异步任务处理器\\n│   │       └── example.go\\n│   └── task\\n│       └── example.go\\n├── internal\\n│   ├── data\\n│   │   └── user.go\\n│   ├── model\\n│   │   └── user.go\\n│   ├── service\\n│   │   └── user.go\\n│   ├── transform\\t\\t\\t# 响应数据处理、封装\\n│   │   └── user.go\\n│   └── validator\\t\\t\\t# 数据请求与参数校验、响应结构体\\n│       └── userValidator\\n│           └── user.go\\n├── main.go\\n├── hook.go\\t\\t\\t\\t\\t\\t# 服务钩子定义\\n├──.env\\t\\t\\t\\t\\t\\t\\t# 本地环境配置\\n├──.env.development\\t\\t\\t\\t# 开发环境配置\\n├──.env.production\\t\\t\\t\\t# 生产环境配置\\n```\\n\\n### 3. 代码生成\\n\\n#### 3.1 创建项目\\n\\n```shell\\n$ ego new projectName\\n```\\n\\n#### 3.2 模板生成\\n\\n```shell\\n# 创建 api、validator、transform、service、data、model 代码模板\\n$ ego tpl api article\\n\\n# 创建 service、data、model 代码模板\\n$ ego tpl service article\\n\\n# 创建 data、model 代码模板\\n$ ego tpl data article\\n\\n# 创建定时任务 task 代码模板\\n$ ego tpl task notice\\n\\n# 创建异步任务 job 代码模板\\n$ ego tpl job sendEmail\\n```\\n\\n### 4. 插件\\n\\n```shell\\n# 往项目注入git commit注释规范\\n$ ego plugin git -t=./.git -k=commitLint\\n```\\n\\n\"},{\"id\":null,\"title\":\"04 | 代码示例\",\"content\":\"### 综合项目\\n\\n-  \"},{\"id\":null,\"title\":\"05 | 常见问题\",\"content\":\"### 1. new提示Permission denied\\n\\n具体参考https://www.zhihu.com/question/21402411\\n\\n如果密钥只用在github等代码库，则建议清空重新设置的方案：\\n\\n1. 清空密钥\\n\\n    ```shell\\n    $ cd ~/.ssh\\n    $ rm -rf ./*\\n    ```\\n\\n2. 重新生成密钥\\n\\n    ```shell\\n    # 设置git信息\\n    $ git config --global user.name \\\"\\\"\\n    $ git config --global user.email \\\"\\\"\\n    \\n    # 生成 ssh key，一直回车\\n    $ ssh-keygen -t rsa -C \\\"邮箱\\\"\\n    ```\\n\\n    `~/.ssh`下生成了id_rsa.pub和id_rsa,\\n\\n    将id_rsa.pub里的内容复制添加到Github、Gitlab、Gitee……个人设置的SSH Keys里即可\\n\\n\"}]},{\"title\":\"基本封装与使用\",\"articles\":[{\"id\":null,\"title\":\"01 | 封装工具总览\",\"content\":\"| 技术         | 框架                                                    | 版本    | 封装包位置                                  |\\n| ------------ | ------------------------------------------------------- | ------- | ------------------------------------------- |\\n| 网络服务框架 | [gin](https://github.com/gin-gonic/gin)                 | v1.7.2  | -                                           |\\n| 配置文件读写 | [viper](https://github.com/spf13/viper)                 | v1.8.0  | bootstrap/viper.go                          |\\n| 日志封装     | [zap](https://github.com/uber-go/zap)                   | v1.17.0 | github.com/mittacy/ego/library/log          |\\n| Mysql        | [gorm](https://gorm.io/zh_CN/docs/index.html)           | v1.21.9 | github.com/mittacy/ego/library/eMysql       |\\n| Redis        | [go-redis](https://github.com/go-redis/redis)           | v8.11.4 | github.com/mittacy/ego/library/eRedis       |\\n| 请求参数校验 | [validator](https://github.com/go-playground/validator) | v10.6.1 | github.com/mittacy/ego/library/gin/response |\\n| http请求封装 | [resty](https://github.com/go-resty/resty)              | v2.6.0  | github.com/mittacy/ego/library/thirdHttp    |\\n| 定时任务     | [cron](https://github.com/robfig/cron)                  | v3.0.1  | app/task                                    |\\n| 异步任务     | [asynq](github.com/hibiken/asynq)                       | v0.19.0 | github.com/mittacy/ego/library/async        |\\n\\n\"},{\"id\":null,\"title\":\"02 | 配置读取\",\"content\":\"### 1. 封装\\n\\n配置采用 [viper](https://github.com/spf13/viper) 库，项目采用了 env 配置文件类型\\n\\n```yaml\\n# 服务配置\\nAPP_NAME = ego-layout\\nAPP_ENV = production            # development/test/production\\nAPP_READ_TIMEOUT = 10           # 读等待时间，单位：秒\\nAPP_WRITE_TIMEOUT = 10          # 写等待时间，单位：秒\\n\\n# 日志\\nLOG_PATH = ./storage/logs\\nLOG_LOW_LEVEL = 0               # 业务日志最低级别：-1:debug、0:info、1:warn、2:error\\nLOG_ENCODER_JSON = true         # 是否为josn日志格式\\nGORM_SLOW_LOG_THRESHOLD = 100   # gorm慢日志记录阈值，单位为毫秒\\n\\n# 异步任务配置\\nQSYNC_Network = tcp\\nQSYNC_Addr = 127.0.0.1:6379\\nQSYNC_Username =\\nQSYNC_Password =\\nQSYNC_DB = 0                    # 数据库\\nQSYNC_DialTimeout = 5           # 连接超时控制, 单位: 秒\\nQSYNC_ReadTimeout = 10          # 读取超时控制, 单位: 秒\\nQSYNC_WriteTimeout = 10         # 写入超时控制, 单位: 秒\\nQSYNC_PoolSize = 10             # 最多连接数\\nQSYNC_Concurrency = 10          # 处理任务的最大并发数\\n\\n# Mysql-localhost\\nDB_LOCALHOST_RW_HOST = 127.0.0.1  # 使用docker时localhost须更改为host.docker.internal\\nDB_LOCALHOST_RW_PORT = 3306\\nDB_LOCALHOST_RW_DATABASE = blog\\nDB_LOCALHOST_RW_USERNAME = root\\nDB_LOCALHOST_RW_PASSWORD = password\\n\\n# Redis-localhost\\nREDIS_LOCALHOST_RW_HOST=127.0.0.1\\nREDIS_LOCALHOST_RW_PASSWORD=\\nREDIS_LOCALHOST_RW_PORT=6379\\n```\\n\\n项目初始化时，会根据启动命令读取env文件路径，默认为 `./.env.development`，将所有变量缓存在内存，同时监听配置文件，如果配置文件修改，会重新解析配置文件\\n\\n启动命令支持以下参数，会覆盖配置文件的配置，**注意如果后续服务运行期间修改了配置文件，会重新覆盖为新的变更值**\\n\\n+ config 配置文件路径 \\n\\n    example: `./server start http -c=./.env.development`\\n\\n+ port 服务监听端口\\n\\n    example: `./server start http -p=10244`\\n\\n+ env 服务监听端口，可选值为：development/test/production\\n\\n    example:  `./server start http -e=development `\\n\\n### 2. 使用\\n\\n需要用到配置信息时，有以下方法获取：\\n\\n+ 直接使用Viper引用即可：`viper.GetString(\\\"key\\\")`\\n\\n+ 定义结构体获取，比如定义 Mysql 结构体，则可以这样获取\\n\\n    ```go\\n    type MysqlConf struct {\\n        Host     string `mapstructure:\\\"host\\\"`\\n        Port     int    `mapstructure:\\\"port\\\"`\\n        Database string `mapstructure:\\\"database\\\"`\\n        User     string `mapstructure:\\\"user\\\"`\\n        Password string `mapstructure:\\\"password\\\"`\\n        Params   string `mapstructure:\\\"params\\\"`\\n    }\\n    \\n    var dbConfig Mysql\\n    if err := viper.UnmarshalKey(key, &dbConfig); err != nil {\\n        fmt.Println(err)\\n    }\\n    ```\\n\\n\\n更多的读取配置方法可参考 [viper官方文档](https://github.com/spf13/viper)\"},{\"id\":null,\"title\":\"03 | 日志\",\"content\":\"日志库采用了目前Go日志库速度最快的 [zap](https://github.com/uber-go/zap)，封装代码位于 `github.com/mittacy/ego/library/log` 中\\n\\n### 1. 全局配置函数\\n\\n日志库对外暴露了部分全局配置函数：\\n\\n+ 日志默认记录路径为项目根目录，可通过 `log.WithPath(\\\"./\\\")` 设置日志记录位置\\n+ 最低日志级别默认为DebugLevel，可通过 `log.WithLevel(zapcore.DebugLevel)`\\n+ `log.WithLogInConsole(true/false)` 配置是否打印到控制台，默认不打印\\n+ `log.WithFields(field ...Field)` 添加全局日志字段，所有新增的日志句柄都会包含该字段\\n+ `log.WithEncoderJSON(bool)` 日志格式是否为json格式，开发环境可以设置为false，方便开发者阅读排查问题；现网建议使用 true，方便日志收集\\n\\n以上配置需要调用 `log.SetDefaultConf(log.WithLogInConsole(true))` 进行设置\\n\\n假如我们有以下配置文件：\\n\\n```yaml\\n# 日志\\nLOG_PATH = ./storage/logs\\nLOG_LOW_LEVEL = 0               # 业务日志最低级别：-1:debug、0:info、1:warn、2:error\\nLOG_ENCODER_JSON = true         # 是否为josn日志格式\\nGORM_SLOW_LOG_THRESHOLD = 100   # gorm慢日志记录阈值，单位为毫秒\\n```\\n\\n在初始化工作中对日志库进行配置：\\n\\n```go\\nfunc init() {\\n    // 查询配置\\n\\tlogPath := viper.GetString(\\\"LOG_PATH\\\")\\n\\tlogLevel := zapcore.Level(viper.GetInt(\\\"LOG_LOW_LEVEL\\\"))\\n\\tlogEncoderJson := viper.GetBool(\\\"LOG_ENCODER_JSON\\\")\\n\\tlogInConsole := false\\n\\tif gin.Mode() == gin.DebugMode {\\n\\t\\tlogInConsole = true\\n\\t}\\n\\tglobalFields := []zapcore.Field{\\n\\t\\t{\\n\\t\\t\\tKey:    \\\"module_name\\\",\\n\\t\\t\\tType:   zapcore.StringType,\\n\\t\\t\\tString: viper.GetString(\\\"APP_NAME\\\"),\\n\\t\\t},\\n\\t}\\n\\n    // 设置全局配置\\n\\tlog.SetDefaultConf(\\n\\t\\tlog.WithPath(logPath),\\n\\t\\tlog.WithTimeFormat(\\\"2006-01-02 15:04:05\\\"),\\n\\t\\tlog.WithLevel(logLevel),\\n\\t\\tlog.WithPreName(\\\"biz_\\\"),\\n\\t\\tlog.WithEncoderJSON(logEncoderJson),\\n\\t\\tlog.WithFields(globalFields...),\\n\\t\\tlog.WithLogInConsole(logInConsole),\\n\\t\\tlog.WithRequestIdKey(middleware.RequestIdKey))\\n}\\n```\\n\\n### 2. 使用\\n\\n#### 默认日志\\n\\n```go\\nfunc TestLog(t *testing.T) {\\n\\tbizLog := New(\\\"default\\\")\\n\\n\\tbizLog.Debug(\\\"this is SugarDebug\\\")\\n\\tbizLog.Info(\\\"this is SugarInfo\\\")\\n\\tbizLog.Warn(\\\"this is SugarWarn\\\")\\n\\tbizLog.Error(\\\"this is SugarError\\\")\\n\\n\\tbizLog.Debugf(\\\"this is %s\\\", \\\"Debugf\\\")\\n\\tbizLog.Infof(\\\"this is %s\\\", \\\"Infof\\\")\\n\\tbizLog.Warnf(\\\"this is %s\\\", \\\"Warn\\\")\\n\\tbizLog.Errorf(\\\"this is %s\\\", \\\"Errorf\\\")\\n\\n\\tbizLog.Debugw(\\\"this is Debugw\\\", \\\"k\\\", \\\"Debugw\\\")\\n\\tbizLog.Infow(\\\"this is Infow\\\", \\\"k\\\", \\\"Infow\\\")\\n\\tbizLog.Warnw(\\\"this is Warnw\\\", \\\"k\\\", \\\"Warnw\\\")\\n\\tbizLog.Errorw(\\\"this is Errorw\\\", \\\"k\\\", \\\"Errorw\\\")\\n}\\n```\\n\\n在默认日志文件`biz-default.log` 中将会写相应日志信息\\n\\n#### 自定义日志文件\\n\\n```go\\n// New 创建新日志文件句柄，使用默认配置\\n// @param name 日志名\\n// @param options 日志配置，将覆盖默认配置\\n// @return *Logger\\nfunc New(name string, options ...ConfigOption) *Logger {}\\n```\\n\\noptions为自定义配置信息，有如下配置可选：\\n\\n+ WithPath 设置日志路径, 修改后，新建的日志将会是新配置，已经建立的日志配置不变\\n+ WithLevel 设置服务记录的最低日志级别\\n+ WithLogInConsole 是否输出到控制台\\n+ WithFields 添加全局日志的新字段, 新建的日志将会是新配置，已经建立的日志配置不变\\n+ WithEncoderJSON 是否设置为json格式日志\\n+ WithTimeFormat 设置时间格式\\n+ WithPreName 设置日志前缀\\n+ WithRequestIdKey 设置请求上下文请求id键名，记录日志时，将从上下文中取请求id并记录\\n\\n### 3. 日志追踪\\n\\n```go\\nfunc TestWithRequestTrace(t *testing.T) {\\n\\tk := \\\"request_id\\\"\\n\\tc := context.WithValue(context.Background(), k, \\\"r61f0ed0d70098_Zw8R1aoyl4tGeB4HMV\\\")\\n\\n\\t// 告知log如何从上下文哪个键名获取请求id\\n\\tSetDefaultConf(WithRequestIdKey(k))\\n\\n\\tl := New(\\\"trace\\\")\\n\\tl.DebugWithTrace(c,\\\"this is SugarDebug\\\")\\n\\tl.InfoWithTrace(c,\\\"this is SugarInfo\\\")\\n\\tl.WarnWithTrace(c,\\\"this is SugarWarn\\\")\\n\\tl.ErrorWithTrace(c,\\\"this is SugarError\\\")\\n\\n\\tl.DebugfWithTrace(c,\\\"this is %s\\\", \\\"Debugf\\\")\\n\\tl.InfofWithTrace(c,\\\"this is %s\\\", \\\"Infof\\\")\\n\\tl.WarnfWithTrace(c,\\\"this is %s\\\", \\\"Warn\\\")\\n\\tl.ErrorfWithTrace(c,\\\"this is %s\\\", \\\"Errorf\\\")\\n\\n\\tl.DebugwWithTrace(c,\\\"this is Debugw\\\", \\\"k\\\", \\\"Debugw\\\")\\n\\tl.InfowWithTrace(c,\\\"this is Infow\\\", \\\"k\\\", \\\"Infow\\\")\\n\\tl.WarnwWithTrace(c,\\\"this is Warnw\\\", \\\"k\\\", \\\"Warnw\\\")\\n\\tl.ErrorwWithTrace(c,\\\"this is Errorw\\\", \\\"k\\\", \\\"Errorw\\\")\\n}\\n\\n```\\n\\n\"},{\"id\":null,\"title\":\"04 | 请求校验\",\"content\":\"gin已经内置了 Validator 校验器，直接对结构体添加 tag 即可，具体规则查看可以查看 [go validator](https://juejin.cn/post/6847902214279659533)\\n\\n但是，如果参数不满足规则，将会响应返回英文等提示，不是很符合我们的需要。项目对校验提示进行了处理封装，位于 `github.com/mittacy/ego/library/gin/response/validator.go`，不需要开发者做什么配置，项目初始化时会自动初始化请求校验翻译器\\n\\n\\n\\n举个创建用户的例子，请求结构体定义如下：\\n\\n```go\\ntype CreateReq struct {\\n   Name     string `json:\\\"name\\\" binding:\\\"required,min=1,max=20\\\"`\\n   Info     string `json:\\\"info\\\" binding:\\\"required,min=1,max=100\\\"`\\n   Password string `json:\\\"password\\\" binding:\\\"required,min=1,max=20\\\"`\\n}\\n```\\n\\n我们在 api 层对请求进行解析，同时在 `github.com/mittacy/ego/library/gin/response/validator.go` 中，定义了一个方法 `ValidateErr(c *gin.Context, err error)`， json 解析后如果 err 不为空，直接调用响应即可，会对错误进行判断，如果是请求数据错误，会返回相应的错误信息；如果是其他错误，会返回 json错误\\n\\n```go\\nfunc Xxxx() {\\n    req := userValidator.CreateReq{}\\n    if err := c.ShouldBindJSON(&req); err != nil {\\n        response.ValidateErr(c, err)\\n        return\\n    }\\n\\n    // ……\\n}\\n```\"},{\"id\":null,\"title\":\"05 | 响应\",\"content\":\"### 业务错误码\\n\\n在`github.com/mittacy/ego/library/apierr` 定义了业务错误码结构以及默认的几个错误码\\n\\n\\n\\n```go\\ntype BizErr struct {\\n\\tCode int\\n\\tMsg  string\\n}\\n\\n// 服务错误定义\\nvar (\\n\\tSuccess           = &BizErr{0, \\\"成功\\\"}\\n\\tParam             = &BizErr{1, \\\"参数错误\\\"}\\n\\tDebounceIntercept = &BizErr{2, \\\"防抖拦截，此次访问无效\\\"}\\n\\tRestyHttp         = &BizErr{3, \\\"请求外部服务错误\\\"}\\n\\tUnauthorized      = &BizErr{401, \\\"未认证\\\"}\\n\\tForbidden         = &BizErr{401, \\\"权限不足\\\"}\\n\\tUnknown           = &BizErr{500, \\\"未知错误\\\"}\\n)\\n\\n// 业务错误定义格式: 大模块:中间模块:业务模块\\nvar (\\n)\\n```\\n\\n### 前后端交互\\n\\n前后端交互中，后端返回的数据必须对结构进行统一规定，方便前端对响应数据进行统一处理、过滤\\n\\n```json\\n{\\n    \\\"code\\\": 0,\\t// 业务码\\n    \\\"msg\\\": \\\"提示信息\\\",\\n    \\\"data\\\": {}\\n}\\n```\\n\\n在本项目中，封装了多个方法进行响应，编码时应该调用方法而不是自己再写响应方法，防止出现数据结构不统一的情况\\n\\n封装位置位于：`github.com/mittacy/ego/library/gin/response` 中\\n\\n\\n\\n[response](https://talkcheap.xiaoeknow.com/mittacychen/ego/library/gin/response) \\n\\n```go\\n// Custom 自定义响应\\n// httpCode http响应码\\n// apiCode 业务响应码\\n// msg 提示信息\\n// data 返回数据\\nfunc Custom(c *gin.Context, httpCode, apiCode int, msg string, data interface{}) {\\n\\tc.JSON(httpCode, gin.H{\\n\\t\\t\\\"code\\\":       apiCode,\\n\\t\\t\\\"msg\\\":        msg,\\n\\t\\t\\\"data\\\":       data,\\n\\t\\t\\\"request_id\\\": c.GetString(\\\"requestId\\\"),\\n\\t})\\n}\\n\\n// Success 成功响应\\n// data 返回数据\\nfunc Success(c *gin.Context, data interface{}) {\\n\\tCustom(c, http.StatusOK, apierr.Success.Code, \\\"success\\\", data)\\n}\\n\\n// SuccessMsg 成功响应带消息提示\\n// data 返回数据\\n// msg 提示信息\\nfunc SuccessMsg(c *gin.Context, data interface{}, msg string) {\\n\\tCustom(c, http.StatusOK, apierr.Success.Code, msg, data)\\n}\\n\\n// Fail 失败响应\\n// msg 提示信息\\nfunc Fail(c *gin.Context) {\\n\\tCustom(c, http.StatusOK, apierr.Param.Code, \\\"fail\\\", struct{}{})\\n}\\n\\n// FailMsg 带自定义信息的失败响应\\n// msg 自定义提示信息\\nfunc FailMsg(c *gin.Context, msg string) {\\n\\tCustom(c, http.StatusOK, apierr.Param.Code, msg, struct{}{})\\n}\\n\\n// FailErr 带有错误的失败响应\\n// err 错误\\nfunc FailErr(c *gin.Context, err error) {\\n\\tCustom(c, http.StatusOK, apierr.ErrCode(err), err.Error(), struct{}{})\\n}\\n\\n// Unknown 未知错误响应\\nfunc Unknown(c *gin.Context) {\\n\\tCustom(c, http.StatusInternalServerError, apierr.Unknown.Code, apierr.Unknown.Error(), struct{}{})\\n}\\n\\n// Unauthorized 未认证响应\\nfunc Unauthorized(c *gin.Context) {\\n\\tCustom(c, http.StatusUnauthorized, apierr.Unauthorized.Code, apierr.Unauthorized.Error(), struct{}{})\\n}\\n\\n// Forbidden 权限不足响应\\nfunc Forbidden(c *gin.Context) {\\n\\tCustom(c, http.StatusForbidden, apierr.Forbidden.Code, apierr.Forbidden.Error(), struct{}{})\\n}\\n\\n```\\n\\n实际开发中，经常需要进行日志记录后响应，所以这里也封装了响应与日志方法\\n\\n```go\\n// CheckErrAndLog 检查是否为指定的业务错误，记录日志并响应\\n// title 记录日志的标题\\n// sourceErr 产生的错误\\n// targetErr 可能的业务错误\\n// - 如果是这些错误，将响应错误的提示信息\\n// - 如果不是这些错误，将记录日志并响应未知错误\\nfunc CheckErrAndLog(c *gin.Context, logger *log.Logger, req interface{}, title string, sourceErr error, targetErr ...error) {\\n\\tif isErr(sourceErr, targetErr...) {\\n\\t\\tFailErr(c, sourceErr)\\n\\t\\treturn\\n\\t}\\n\\n\\tlogger.ErrorwWithTrace(c, title, \\\"req\\\", req, \\\"err\\\", sourceErr)\\n\\tif gin.Mode() == gin.ReleaseMode {\\n\\t\\tUnknown(c)\\n\\t} else {\\n\\t\\tCustom(c, http.StatusOK, 500, sourceErr.Error(), struct {}{})\\n\\t}\\n\\treturn\\n}\\n\\nfunc isErr(source error, target ...error) bool {\\n\\tfor _, v := range target {\\n\\t\\tif errors.Is(source, v) {\\n\\t\\t\\treturn true\\n\\t\\t}\\n\\t}\\n\\treturn false\\n}\\n\\n```\\n\\n比如在查询用户信息时，可以这样写：\\n\\n```go\\nfunc (ctl *User) Get(c *gin.Context) {\\n\\tid, err := strconv.ParseInt(c.Param(\\\"id\\\"), 10, 64)\\n\\tif err != nil {\\n\\t\\tresponse.ValidateErr(c, err)\\t// 参数校验失败直接调用该方法，会翻译错误并响应\\n\\t\\treturn\\n\\t}\\n\\n\\tuser, err := service.User.GetById(id)\\n\\tif err != nil {\\n        // 检查相关的业务错误，记录日志并响应\\n        response.CheckErrAndLog(c, log.New(\\\"user\\\"), req, \\\"getUser\\\", err, apierr.ErrUserNoExist)\\n\\t\\treturn\\n\\t}\\n\\n\\ttransform.User.GetUserReply(c, req, user)\\n}\\n```\\n\\n`response.CheckErrAndLog(c, ctl.logger, req, \\\"getUser\\\", err, apierr.ErrUserNoExist)` 语句将会检查错误服务返回的错误，如果是 `apierr.ErrUserNoExist` 则响应给前端：用户不存在，否则记录日志并响应给前端：未知错误\\n\\n\"}]},{\"title\":\"常用工具封装与使用\",\"articles\":[{\"id\":null,\"title\":\"01 | Mysql操作\",\"content\":\"项目在 `github.com/mittacy/ego/library/eMysql` 中封装了 [gorm](https://gorm.io/zh_CN/docs/index.html) \\n\\n在使用前，必须先初始化配置\\n\\n```go\\nvar mysqlConfigs map[string]eMysql.Conf\\n\\nfunc InitGorm() {\\n\\tmysqlConfigs = map[string]eMysql.Conf{\\n\\t\\t\\\"localhost\\\": {\\n\\t\\t\\tHost:     viper.GetString(\\\"DB_LOCALHOST_RW_HOST\\\"),\\n\\t\\t\\tPort:     viper.GetInt(\\\"DB_LOCALHOST_RW_PORT\\\"),\\n\\t\\t\\tDatabase: viper.GetString(\\\"DB_LOCALHOST_RW_DATABASE\\\"),\\n\\t\\t\\tUser:     viper.GetString(\\\"DB_LOCALHOST_RW_USERNAME\\\"),\\n\\t\\t\\tPassword: viper.GetString(\\\"DB_LOCALHOST_RW_PASSWORD\\\"),\\n\\t\\t},\\n\\t}\\n    // 设置日志名、慢日志阈值、是否忽略记录不存在错误\\n\\teMysql.InitGorm(mysqlConfigs,\\n\\t\\teMysql.WithLogName(\\\"mysql\\\"),\\n\\t\\teMysql.WithLogSlowThreshold(viper.GetDuration(\\\"GORM_SLOW_LOG_THRESHOLD\\\")),\\n\\t\\teMysql.WithLogIgnoreRecordNotFound(true))\\n}\\n```\\n\\n在结构体中引入并在初始化时给 `MysqlConfName` 赋值，使用GDB()即可获取gorm连接\\n\\n```go\\ntype User struct {\\n\\teMysql.EGorm\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tEGorm: eMysql.EGorm{\\n\\t\\t\\tMysqlConfName: \\\"localhost\\\",\\n\\t\\t}\\n\\t}\\n}\\n\\nfunc (ctl *User) GetById(c *gin.Context, id int64) (model.User, error) {\\n\\tuser := model.User{}\\n\\tif err := ctl.GDB().Where(\\\"id = ?\\\", id).First(&user).Error; err != nil {\\n\\t\\tif errors.Is(err, gorm.ErrRecordNotFound) {\\n            return model.User{}, apierr.UserNoExist\\n\\t\\t}\\n\\t\\n\\t\\treturn model.User{}, errors.WithStack(err)\\n\\t}\\n    \\n\\treturn user, nil\\n}\\n```\\n\\n强制要求只在 data 层涉及数据库的操作，并且将库错误转化为业务错误向上层抛出。\\n\\n例如，现在有一个查询指定用户的操作使用了gorm库，那么需要在 `apierr/err.go` 中定义业务错误`apierr.UserNoExist`，然后在 data 层判断错误是否为 `gorm.ErrRecordNotFound` 并转化为定义的业务错误 `apierr.UserNoExist`\\n\\n> 这样做的好处是，底层不需要强制使用哪个库，大家可以选用自己喜欢的框架，sql、sqlx、gorm、xorm……，只需要将对应的错误转化为业务错误，这样在上层 api 层只需要判断自己关心的业务错误并做相应的处理即可\\n\\n### 堆栈\\n\\n为了更方便地定位错误，我们需要在日志中记录堆栈，但 zap 本身记录的堆栈开始位置是记录日志的位置，我们需要详细到底层才能更好地定位。很遗憾 go 默认的 errors 没有带堆栈记录，我们需要引入外部工具 [errors](https://github.com/pkg/errors)\\n\\n```go\\nif err := ctl.GDB().Where(\\\"id = ?\\\", id).First(&user).Error; err != nil {\\n    if errors.Is(err, gorm.ErrRecordNotFound) {\\n        return model.User{}, apierr.UserNoExist\\t\\t// 业务错误属于可控错误，不需要堆栈\\n    }\\n\\n    return model.User{}, errors.WithStack(err)\\t\\t// 不可控错误，包裹err，从此处开始追踪堆栈\\n}\\n```\\n\\n比如上面我们查询一个用户记录，首先对结果判断错误是否是用户不存在:\\n\\n+ 如果是，则转化为我们的业务错误直接抛出\\n+ 如果不是，我们使用了 `errors.WithStack(err)` 将错误进行封装，这个错误将带有从这里开始一直到我们使用err的位置的堆栈信息\\n\\n___\\n\\n更多gorm操作请查看 [gorm官方文档](https://gorm.io/zh_CN/docs/index.html)\\n\"},{\"id\":null,\"title\":\"02 | Redis操作\",\"content\":\"项目在 `github.com/mittacy/ego/library/eRedis` 中封装了 [go-redis](https://github.com/go-redis/redis) \\n\\n在使用前，必须先初始化配置\\n\\n```go\\nvar redisConfigs map[string]eRedis.Conf\\n\\nfunc InitRedis() {\\n\\tredisConfigs = map[string]eRedis.Conf{\\n\\t\\t\\\"localhost\\\": {\\n\\t\\t\\tHost:        viper.GetString(\\\"REDIS_LOCALHOST_RW_HOST\\\"),\\n\\t\\t\\tPassword:    viper.GetString(\\\"REDIS_LOCALHOST_RW_PASSWORD\\\"),\\n\\t\\t\\tPort:        viper.GetInt(\\\"REDIS_LOCALHOST_RW_PORT\\\"),\\n\\t\\t\\tPoolSize:    viper.GetInt(\\\"REDIS_LOCALHOST_POOL_SIZE\\\"),\\n\\t\\t\\tMinIdleConn: viper.GetInt(\\\"REDIS_LOCALHOST_MIN_IDLE_CONN\\\"),\\n\\t\\t\\tIdleTimeout: viper.GetDuration(\\\"REDIS_LOCALHOST_IDLE_TIMEOUT\\\"),\\n\\t\\t},\\n\\t}\\n\\teRedis.InitRedis(redisConfigs)\\n}\\n```\\n\\n在结构体中引入并在初始化时给 `RedisConfName、RedisDB` 赋值，使用RDB()即可获取redis连接\\n\\n> *以上例子只是为了说明如何使用，一般不会查询缓存不存在就马上返回，而是先查询缓存不存在则去查询数据库，再存入缓存并返回*\\n\\n```go\\ntype User struct {\\n\\teRedis.ERedis\\n\\tcacheKeyPre string\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tERedis: eRedis.ERedis{\\n\\t\\t\\tRedisConfName: \\\"localhost\\\",\\n\\t\\t\\tRedisDB:       0,\\n\\t\\t},\\n\\t\\tcacheKeyPre: fmt.Sprintf(\\\"%s:user\\\", viper.GetString(\\\"APP_NAME\\\")),\\n\\t}\\n}\\n\\nfunc (ctl *User) GetByIdCachePre(id int64) string {\\n\\treturn fmt.Sprintf(\\\"%s:id:%d\\\", ctl.cacheKeyPre, id)\\n}\\n\\nfunc (ctl *User) GetById(c *gin.Context, id int64) (model.User, error) {\\n    if err := ctl.RDB().Set(context.Background(), \\\"name\\\", \\\"xiyangyang\\\", time.Second * 10).Err(); err != nil {\\n\\t\\treturn nil, err\\n\\t}\\n\\n\\tuserStr, err := ctl.RDB().Get(context.Background(), ctl.GetByIdCachePre(id)).Result()\\n\\tif err != nil {\\n\\t\\tif errors.Is(err, redis.Nil) {\\n            return model.User{}, apierr.UserNoExist\\n\\t\\t}\\n        return model.User{}, errors.WithStack(err)\\n\\t}\\n    \\n    // string to struct\\n\\t\\n\\treturn ...\\n}\\n```\\n\\n强制要求只在 data 层涉及数据库的操作，并且将库错误转化为业务错误向上层抛出。\\n\\n例如，现在有一个查询指定用户的操作使用了redis库，那么需要在 `apierr/err.go` 中定义业务错误`apierr.UserNoExist`，然后在 data 层判断错误是否为 `redis.Nil` 并转化为定义的业务错误 `apierr.UserNoExist`\\n\\n> 这样做的好处是，底层不需要强制使用哪个库，大家可以选用自己喜欢的框架，sql、sqlx、gorm、xorm……，只需要将对应的错误转化为业务错误，这样在上层 api 层只需要判断自己关心的业务错误并做相应的处理即可\\n\\n### 堆栈\\n\\n为了更方便地定位错误，我们需要在日志中记录堆栈，但 zap 本身记录的堆栈开始位置是记录日志的位置，我们需要详细到底层才能更好地定位。很遗憾 go 默认的 errors 没有带堆栈记录，我们需要引入外部工具 [errors](https://github.com/pkg/errors)\\n\\n```go\\nuserStr, err := ctl.RDB().Get(context.Background(), ctl.GetByIdCachePre(id)).Result()\\nif err != nil {\\n    if errors.Is(err, redis.Nil) {\\n        return model.User{}, apierr.UserNoExist\\n    }\\n    return model.User{}, errors.WithStack(err)\\n}\\n```\\n\\n比如上面我们查询一个用户记录，首先对结果判断错误是否是用户不存在:\\n\\n+ 如果是，则转化为我们的业务错误直接抛出\\n+ 如果不是，我们使用了 `errors.WithStack(err)` 将错误进行封装，这个错误将带有从这里开始一直到我们使用err的位置的堆栈信息\\n\\n\"},{\"id\":null,\"title\":\"03 | Mongo操作\",\"content\":\"项目在 `github.com/mittacy/ego/library/eMongo` 中封装了 [mongo](https://github.com/mongodb/mongo-go-driver)\\n\\n在使用前，必须先初始化配置\\n\\n```go\\nvar mongoConfigs map[string]eMongo.Conf\\n\\nfunc InitMongo() {\\n\\tmongoConfigs = map[string]eMongo.Conf{\\n\\t\\t\\\"localhost\\\": {\\n\\t\\t\\tHost:     viper.GetString(\\\"MONGO_LOCALHOST_RW_HOST\\\"),\\n\\t\\t\\tPort:     viper.GetInt(\\\"MONGO_LOCALHOST_RW_PORT\\\"),\\n\\t\\t\\tDatabase: viper.GetString(\\\"MONGO_LOCALHOST_RW_DATABASE\\\"),\\n\\t\\t\\tUser:     viper.GetString(\\\"MONGO_LOCALHOST_RW_USERNAME\\\"),\\n\\t\\t\\tPassword: viper.GetString(\\\"MONGO_LOCALHOST_RW_PASSWORD\\\"),\\n\\t\\t},\\n\\t}\\n\\n\\teMongo.Init(mongoConfigs)\\n}\\n```\\n\\n在结构体中引入并在初始化时给 `MongoConfName、CollationName` 赋值，使用MDB()/MCollection()即可获取mongo连接\\n\\n```go\\ntype User struct {\\n\\teMongo.EMongo\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tEMongo: eMongo.EMongo{\\n\\t\\t\\tMongoConfName: \\\"localhost\\\",\\n\\t\\t\\tCollationName: \\\"user\\\",\\n\\t\\t}\\n\\t}\\n}\\n\\nfunc (ctl *User) GetById(c *gin.Context, id int64) (model.User, error) {\\n\\tuser := model.User{}\\n\\tfilter := bson.D{{\\\"id\\\", id}}\\n\\tif err := ctl.MCollection().FindOne(context.Background(), filter).Decode(&user); err != nil {\\n\\t\\tif errors.Is(err, mongo.ErrNoDocuments) {\\n\\t\\t\\treturn model.User{}, apierr.UserNoExist\\n\\t\\t}\\n\\t\\treturn model.User{}, errors.WithStack(err)\\n\\t}\\n    \\n\\treturn &user, nil\\n}\\n```\\n\\n强制要求只在 data 层涉及数据库的操作，并且将库错误转化为业务错误向上层抛出。\\n\\n例如，现在有一个查询指定用户的操作使用了go-mongo库，那么需要在 `apierr/err.go` 中定义业务错误`apierr.UserNoExist`，然后在 data 层判断错误是否为 `mongo.ErrNoDocuments` 并转化为定义的业务错误 `apierr.UserNoExist`\\n\\n> 这样做的好处是，底层不需要强制使用哪个库，大家可以选用自己喜欢的框架，sql、sqlx、gorm、xorm……，只需要将对应的错误转化为业务错误，这样在上层 api 层只需要判断自己关心的业务错误并做相应的处理即可\\n\\n\\n\\n\\n\\n[eHttp](github.com/mittacy/ego/library/eHttp)\\n\\n___\\n\\n更多mongo操作请查看 [mongo文档](https://github.com/mongodb/mongo-go-driver)\\n\"},{\"id\":null,\"title\":\"04 | 外部服务请求\",\"content\":\"项目在 `github.com/mittacy/ego/library/thirdHttp` 中封装了 [resty](https://github.com/go-resty/resty) ，经常会有调用其他http服务的情况，封装了 [resty](https://github.com/go-resty/resty) 位于 `pkg/restyHttp`\\n\\n响应结构体为：\\n\\n```go\\nconst (\\n\\tCodeSuccess = 0\\n\\tCodeUnknown = 1\\n)\\n\\ntype Reply struct {\\n\\tCode int\\n\\tMsg string\\n\\tData interface{}\\n}\\n```\\n\\n提供的方法\\n\\n```go\\n// Get GET请求，返回数据为map结构\\n// @param host 域名，example: https://www.baidu.com\\n// @param uri example: /user\\n// @param timeout 超时控制  example: time.Second*5\\n// @return map[string]interface{} data结构数据\\n// @return int 返回的业务状态码\\n// @return error\\nfunc Get(host, uri string, timeout time.Duration) (map[string]interface{}, int, error) {}\\n\\n// GetParams GET请求，返回数据为map结构\\n// @param host 域名，example: https://www.baidu.com\\n// @param uri example: /user\\n// @param params 请求参数\\n// @param timeout 超时控制  example: time.Second*5\\n// @return map[string]interface{} data结构数据\\n// @return int 返回的业务状态码\\n// @return error\\nfunc GetParams(host, uri string, params map[string]string, timeout time.Duration) (map[string]interface{}, int, error) {}\\n\\n// Post POST请求\\n// @param host 域名，example: https://www.baidu.com\\n// @param uri example: /user\\n// @param body 请求体数据，struct/map/[]byte/……\\n// @param timeout 超时控制  example: time.Second*5\\n// @return map[string]interface{} data结构数据\\n// @return int 返回的业务状态码\\n// @return error\\nfunc Post(host, uri string, body interface{}, timeout time.Duration) (map[string]interface{}, int, error) {}\\n```\\n\\n调用 GET / POST 方法后即可获得data数据，data数据如果是 `map[string]interface{}`则直接返回，如果不是，则会包一层再返回\\n\\n```go\\nfunc resPackage(res Reply) map[string]interface{} {\\n\\tif v, ok := res.Data.(map[string]interface{}); ok {\\n\\t\\treturn v\\n\\t}\\n\\n\\t// 其他特殊类型包装\\n\\treturn map[string]interface{}{\\n\\t\\t\\\"data\\\": res.Data,\\n\\t}\\n}\\n```\\n\\n获得data响应数据后，可以调用 `Decode()` 解析为自己需要的对象结构\\n\\n```go\\n// Decode 响应解析，map => struct\\n// 由于 mapstructure 解析时如果结构体存在时间将无法解析成功，所以此处添加一个钩子告诉mapstructure如何解析时间\\n// @param input map数据\\n// @param result struct结构体，需要指针\\n// @param timeFormat 解析时间格式\\n//\\t默认为 []string{\\\"2006-01-02 15:04:05\\\", \\\"2006-01-02T15:04:05Z07:00\\\", \\\"2006-01-02T15:04:05.999999999Z07:00\\\"}\\n// @return error\\nfunc Decode(input interface{}, result interface{}, timeFormat ...string) error 「」\\n```\\n\\n**使用**\\n\\n```go\\ntype Tag struct {\\n\\tId      int64  `json:\\\"id\\\" mapstructure:\\\"id\\\"`\\n\\tTagName string `json:\\\"tag_name\\\" mapstructure:\\\"tag_name\\\"`\\n}\\n\\ntype Tags struct {\\n\\tCommunityTags []Tag `json:\\\"community_tags\\\" mapstructure:\\\"community_tags\\\"`\\n\\tRecentlyTags  []Tag `json:\\\"recently_tags\\\" mapstructure:\\\"recently_tags\\\"`\\n}\\n\\nfunc TestGetParams(t *testing.T) {\\n\\thost := \\\"……\\\"\\n\\turi := \\\"……\\\"\\n\\tparams := map[string]string{\\n\\t\\t\\\"type\\\":         \\\"1\\\",\\n\\t\\t\\\"app_id\\\":       \\\"appmfaz41ol6225\\\",\\n\\t\\t\\\"community_id\\\": \\\"c_60bede024a515_VnCNlkQA2383\\\",\\n\\t}\\n\\n    // 请求http服务\\n\\tres, _, err := GetParams(host, uri, params, time.Second*5)\\n\\n\\tif err != nil {\\n\\t\\tt.Error(err)\\n\\t}\\n\\n    // 解析为对应的结构体\\n\\ttags := Tags{}\\n\\tif err := Decode(res, &tags, nil); err != nil {\\n\\t\\tt.Error(err)\\n\\t}\\n\\n\\tt.Logf(\\\"%+v\\\\n\\\", tags)\\n}\\n```\\n\\n### 带上下文\\n\\n```go\\n// Get GET请求，返回数据为map结构\\n// @param host 域名，example: https://www.baidu.com\\n// @param uri example: /user\\n// @param timeout 超时控制  example: time.Second*5\\n// @return map[string]interface{} data结构数据\\n// @return int 返回的业务状态码\\n// @return error\\nfunc GetWithTrace(c context.Context, host, uri string, timeout time.Duration) (map[string]interface{}, int, error)\\n\\n// GetParams GET请求，返回数据为map结构\\n// @param host 域名，example: https://www.baidu.com\\n// @param uri example: /user\\n// @param params 请求参数\\n// @param timeout 超时控制  example: time.Second*5\\n// @return map[string]interface{} data结构数据\\n// @return int 返回的业务状态码\\n// @return error\\nfunc GetParamsWithTrace(c context.Context, host, uri string, params map[string]string, timeout time.Duration) (map[string]interface{}, int, error)\\n\\n// Post POST请求\\n// @param host 域名，example: https://www.baidu.com\\n// @param uri example: /user\\n// @param body 请求体数据，struct/map/[]byte/……\\n// @param timeout 超时控制  example: time.Second*5\\n// @return map[string]interface{} data结构数据\\n// @return int 返回的业务状态码\\n// @return error\\nfunc PostWithTrace(c context.Context, host, uri string, body interface{}, timeout time.Duration) (map[string]interface{}, int, error)\\n```\\n\\n\"},{\"id\":null,\"title\":\"05 | 并发操作\",\"content\":\"当有多个服务或者数据操作没有关联时，可以进行<u>并发调用</u>，在 `github.com/mittacy/library/errgroup` 对 `golang.org/x/sync/errgroup` 进行升级，防止panic导致的服务宕机\\n\\n```go\\nfunc Xxx() {\\n    var (\\n        userInfo model.User\\n        userFansTotal int64\\n        title string\\n    )\\n    \\n    group := errgroup.WithContext(context.Background())\\n\\n\\tgroup.Go(func(ctx context.Context) error {\\n        var err error\\n        userInfo, err = service.User.Get()\\n        if err != nil {\\n            title = \\\"查询用户信息\\\"\\n        }\\n        return err\\n\\t})\\n\\n\\tgroup.Go(func(ctx context.Context) error {\\n\\t\\tvar err error\\n        userFansTotal, err = service.Fans.GetTotal()\\n        if err != nil {\\n            title = \\\"查询用户粉丝数量\\\"\\n        }\\n        return err\\n\\t})\\n\\n\\tif err := group.Wait();err != nil {\\n        log.New(\\\"user\\\").Errorw(title, \\\"err\\\", err)\\n        return\\n\\t}\\n    \\n    return\\n}\\n```\\n\\n- GOMAXPROCS()可设置最大并发数\\n- Wait函数在所有goroutine运行结束才会返回，返回值记录了第一个发生的错误\\n\\n[errgroup](https://talkcheap.xiaoeknow.com/mittacychen/ego/library/errgroup)\\n\"},{\"id\":null,\"title\":\"06 | 定时任务\",\"content\":\"项目封装了定时任务 [cron](https://github.com/robfig/cron)\\n\\n使用 `ego tpl task 定时任务名` 即可创建定时任务模板，位于 `app/task`；然后将 NewExample() 添加到 `config/task.go->Tasks()` ，在启动时将会自动添加该定时任务\\n\\n```go\\ntype Example struct {\\n\\tlogger *log.Logger\\n}\\n\\nfunc NewExample(logger *log.Logger) *Example {\\n\\treturn &Example{logger: logger}\\n}\\n\\nfunc (t *Example) Name() string {\\n\\treturn \\\"Example\\\"\\n}\\n\\nfunc (t *Example) Spec() string {\\n\\treturn \\\"@every 10s\\\"\\n}\\n\\nfunc (t *Example) Job() cron.Job {\\n\\treturn t\\n}\\n\\nfunc (t *Example) Run() {\\n\\t// do something\\n\\tt.logger.Infow(\\\"Hello, this is the example task\\\", \\\"task\\\", t.Name())\\n}\\n```\\n\\n+ 修改 Spec() 为定时任务定时规则，[定时规则](https://pkg.go.dev/github.com/robfig/cron)\\n+ 修改 Run() 为定时运行时执行的任务\\n\"},{\"id\":null,\"title\":\"07 | 异步任务\",\"content\":\"ego封装了 [asynq](https://github.com/hibiken/asynq)，位于 `github.com/mittacy/ego/library/async`\\n\\n使用前需要进行初始化，修改配置信息：`config/async.go`\\n\\n```go\\n/ AsyncRedisClientOpt is used to create a redis client that connects\\n// to a redis server directly.\\nfunc AsyncRedisClientOpt() asynq.RedisClientOpt {\\n\\treturn asynq.RedisClientOpt{\\n\\t\\tNetwork:      viper.GetString(\\\"ASYNC_Network\\\"),\\n\\t\\tAddr:         viper.GetString(\\\"ASYNC_Addr\\\"),\\n\\t\\tUsername:     viper.GetString(\\\"ASYNC_Username\\\"),\\n\\t\\tPassword:     viper.GetString(\\\"ASYNC_Password\\\"),\\n\\t\\tDB:           viper.GetInt(\\\"ASYNC_DB\\\"),\\n\\t\\tDialTimeout:  viper.GetDuration(\\\"ASYNC_DialTimeout\\\") * time.Second,\\n\\t\\tReadTimeout:  viper.GetDuration(\\\"ASYNC_ReadTimeout\\\") * time.Second,\\n\\t\\tWriteTimeout: viper.GetDuration(\\\"ASYNC_WriteTimeout\\\") * time.Second,\\n\\t\\tPoolSize:     viper.GetInt(\\\"ASYNC_PoolSize\\\"),\\n\\t}\\n}\\n\\n// AsyncConfig specifies the server's background-task processing behavior.\\nfunc AsyncConfig() asynq.Config {\\n\\treturn asynq.Config{\\n\\t\\tConcurrency: viper.GetInt(\\\"ASYNC_Concurrency\\\"),\\n\\t\\tQueues: map[string]int{\\n\\t\\t\\t\\\"critical\\\": 6,\\n\\t\\t\\t\\\"default\\\":  3,\\n\\t\\t\\t\\\"low\\\":      1,\\n\\t\\t},\\n\\t\\tErrorHandler:        nil,\\n\\t\\tLogger:              async.NewLogger(log.New(\\\"job\\\")),\\n\\t\\tLogLevel:            asynq.InfoLevel,\\n\\t\\tShutdownTimeout:     time.Second * 10, // 关闭服务时等待等待进行中的任务\\n\\t\\tHealthCheckFunc:     nil,\\n\\t\\tHealthCheckInterval: 0,\\n\\t}\\n}\\n```\\n\\n新建异步任务时，可以使用 `ego tpl job jobName` 新建任务模板文件，文件位于`app/job`下\\n\\n+ job_payload：异步任务数据结构，向异步任务加入任务时需要调用该包\\n\\n    ```go\\n    const ExampleTypeName = \\\"example:hello\\\"\\n    \\n    // Payload 任务数据\\n    type ExamplePayload struct {\\n    \\tRequestId string\\n    }\\n    ```\\n\\n+ job_process：异步任务处理程序\\n\\n    ```go\\n    // Processor 任务处理器\\n    type ExampleProcessor struct {\\n    \\tl *log.Logger\\n    }\\n    \\n    func NewExample() *ExampleProcessor {\\n    \\treturn &ExampleProcessor{\\n    \\t\\tl: log.New(\\\"example_job\\\"),\\n    \\t}\\n    }\\n    \\n    func (processor *ExampleProcessor) ProcessTask(ctx context.Context, t *asynq.Task) error {\\n    \\tvar p job_payload.ExamplePayload\\n    \\tif err := json.Unmarshal(t.Payload(), &p); err != nil {\\n    \\t\\treturn fmt.Errorf(\\\"json.Unmarshal failed: %v: %w\\\", err, asynq.SkipRetry)\\n    \\t}\\n    \\n    \\t// call service\\n    \\t// service.Biz.Do()\\n    \\tprocessor.l.Info(\\\"do something\\\")\\n    \\n    \\treturn nil\\n    }\\n    ```\\n\\n最后，在 `config/async_config/job.go->Jobs()` 中添加任务名和任务处理，在异步任务启动时即可监听该任务\\n\"},{\"id\":null,\"title\":\"08 | DB与缓存查询封装\",\"content\":\"### 缓存方案\\n\\n首先，我们对缓存是不进行更新的，只设置过期时间，一旦DB里数据出现修改，我们就会直接删除对应的缓存，然后新的查询再进行数据缓存。\\n\\n接下来，是删除缓存的顺序：\\n\\n+ 先删除缓存，再更新数据\\n\\n    A是一个更新操作，B是一个查询操作。A先删除了缓存然后执行一些其他操作阻塞一会儿；在这期间B刚好来查询缓存发现不存在便前往DB查询数据并写入了缓存，之后A解除阻塞更新了DB。那么缓存里的数据就是脏数据，直到下一次更新操作或者缓存过期，业务的查询都将查到脏数据\\n\\n    <img src=\\\"http://static.mittacy.com/blog/202203281033949.png\\\" style=\\\"zoom:50%;\\\" />\\n\\n+ 先更新数据，再更新缓存\\n\\n    同样的，A先进行DB更新操作，随后再删除缓存的时候阻塞了；期间B刚好来查询缓存，从缓存得到的数据就是脏数据；随后A删除了缓存。后续的请求都会拿到最新数据\\n\\n    ![](http://static.mittacy.com/blog/202203281037880.png)\\n\\n方案二带来的影响更小，也更不容易发生，所以我们选择方案二\\n\\n### 缓存代码\\n\\n话不多说，故事开始\\n\\n张三接到优化<u>查询圈子总成员数</u>加缓存的任务，于是马上动工优化了一波\\n\\n+ 不加缓存的代码\\n\\n    ```go\\n    func (ctl *CommunityUser) GetCount(c *gin.Context, appId, communityId string) (int64, error) {\\n    \\tvar count int64\\n    \\tif err := ctl.GDB().Model(model.CommunityUser{}).Where(\\\"app_id = ? and community_id = ?\\\", appId, communityId).Count(&count).Error; err != nil {\\n    \\t\\treturn 0, errors.WithStack(err)\\n    \\t}\\n    \\n    \\treturn count, nil\\n    }\\n    ```\\n\\n+ 加了缓存的代码\\n\\n    ```go\\n    func (ctl *CommunityUser) GetCountWithCache(c *gin.Context, appId, communityId string) (int64, error) {\\n    \\t// 从缓存查询\\n    \\tkey := ctl.getCountCacheKey(appId, communityId)\\n    \\tcacheRes, err := ctl.RDB().Get(c, key).Result()\\n    \\tif err != nil && !errors.Is(err, redis.Nil) {\\n    \\t\\treturn 0, errors.WithStack(err)\\n    \\t}\\n        // 缓存存在，直接返回\\n    \\tif err == nil {\\n    \\t\\treturn strconv.ParseInt(cacheRes, 10, 64)\\n    \\t}\\n    \\n    \\t// 缓存不存在，从DB查询\\n    \\tvar count int64\\n    \\tif err := ctl.GDB().Model(model.CommunityUser{}).Where(\\\"app_id = ? and community_id = ?\\\", appId, communityId).Count(&count).Error; err != nil {\\n    \\t\\treturn 0, errors.WithStack(err)\\n    \\t}\\n    \\t\\n    \\t// 存入缓存\\n    \\tgo func() {\\n    \\t\\tif err = ctl.RDB().Set(c, key, count, CountExpire).Err(); err != nil {\\n    \\t\\t\\tctl.log.ErrorwWithTrace(c, \\\"查询圈子用户总数-存储缓存失败\\\", \\\"err\\\", err)\\n    \\t\\t}\\n    \\t}()\\n    \\n    \\treturn count, nil\\n    }\\n    ```\\n\\n张三写完觉得很不错，提了个紧急上线单赶紧修复，免得下周又崩了，经过多人没人几秒钟的review之后，成功通过上线。\\n\\n周五的时候，这个1.3万用户量的圈子，风雨无阻地发起了签到活动，奇迹来了，圈子不负众望，再次把核心库搞崩了。\\n\\n根据运维给出的情报，还是那个查询语句，张三看了下代码，陷入深思，感叹到：我大意了。\\n\\n### 处理并发\\n\\n不难发现，这种高并发的业务场景，如果这个复杂的查询语句需要1秒钟，同时1秒钟有10000个用户进来了，那还是有10000个查询打到了DB，还是老样子挂了，所以我们应该给查询加上并发锁，只放一个请求穿透缓存到DB去查询，其他请求则反复请求缓存，直到放过去的请求查询出数据并更新缓存即可。\\n\\n<img src=\\\"http://static.mittacy.com/blog/202203281112490.png\\\" style=\\\"zoom:60%;\\\" />\\n\\nredis的set很符合我们的需求，`set key value ex/px expire nx`：不存在的时候设置key同时设置过期时间，返回true则表示设置成功获得了锁；设置失败则表示锁被其他请求拿走了。不用担心拿了锁的请求异常导致没释放锁，毕竟锁加了过期时间，同时这也是一个原子操作。\\n\\n这是加了锁的代码：\\n\\n```go\\nfunc (ctl *CommunityUser) GetCountWithCache(c *gin.Context, appId, communityId string) (int64, error) {\\n\\t// 从缓存查询\\n\\tkey := ctl.getCountCacheKey(appId, communityId)\\n\\tcacheRes, err := ctl.RDB().Get(c, key).Result()\\n\\tif err != nil && !errors.Is(err, redis.Nil) {\\n\\t\\treturn 0, errors.WithStack(err)\\n\\t}\\n\\tif err == nil {\\n\\t\\treturn strconv.ParseInt(cacheRes, 10, 64)\\n\\t}\\n\\n\\t// 缓存不存在，获取并发锁\\n\\tlockKey := ctl.getCountLockKey(appId, communityId)\\n\\tok ,err := ctl.RDB().SetNX(c, lockKey, 1, time.Second).Result()\\n\\tif err != nil || !ok {\\n\\t\\t// 拿不到锁，每次等待50ms，尝试从redis获取缓存\\n\\t\\tfor i := 0; i < 10; i++ {\\n\\t\\t\\ttime.Sleep(time.Millisecond * 50)\\n\\t\\t\\tcount, err := ctl.RDB().Get(c, key).Int64()\\n\\t\\t\\tif err != nil && !errors.Is(err, redis.Nil) {\\n\\t\\t\\t\\treturn 0, errors.WithStack(err)\\n\\t\\t\\t}\\n\\t\\t\\tif err == nil {\\n\\t\\t\\t\\treturn count, nil\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t// 等不到缓存，直接返回错误\\n\\t\\treturn 0, errors.New(\\\"服务器压力过大\\\")\\n\\t}\\n\\t\\n\\t// 拿到锁的穿透到DB, 从DB查询数据并存入redis\\n\\tdefer func() {\\n\\t\\trecover()\\n\\t\\tctl.RDB().Del(c, lockKey)\\n\\t}()\\n\\t\\n\\tvar count int64\\n\\tif err := ctl.GDB().Model(model.CommunityUser{}).Where(\\\"app_id = ? and community_id = ?\\\", appId, communityId).Count(&count).Error; err != nil {\\n\\t\\treturn 0, errors.WithStack(err)\\n\\t}\\n\\n\\t// 存入缓存，不能并发，不然还没存好就触发了解锁操作\\n\\tif err = ctl.RDB().Set(c, key, count, time.Hour).Err(); err != nil {\\n\\t\\tlog.New(\\\"communityUser\\\").ErrorwWithTrace(c, \\\"查询圈子用户总数-存储缓存失败\\\", \\\"err\\\", err)\\n\\t}\\n\\n\\treturn count, nil\\n}\\n```\\n\\n好了，一切看起来很不错，至于能不能抗住，再说 ಡωಡ\\n\\n其实还有个小bug，注意下释放锁的逻辑：\\n\\n```go\\nctl.RDB().Del(c, lockKey)\\n```\\n\\n这里同一个业务查询的缓存锁名其实都是一样的，有这样一种情况：A请求获取锁并前往DB查询结果被阻塞住了，直到锁过期还没解除阻塞；B请求获取了锁并前往DB查询结果，还没查询完，A解除了阻塞随后把B的锁给释放了。没错，A释放了B的锁，这时候一大堆僵尸袭来，DB再次绷不住挂了……\\n\\n解决方法是给锁的值设置一个随机值，解锁的时候检查随机值是否为自己的随机值，也就是是否为自己的锁，是的话再释放。这里需要使用lua脚本去保证操作的原子性，不展开讲，我已经封装并发锁： [ego-redisLock](https://talkcheap.xiaoeknow.com/mittacychen/ego/-/blob/master/library/eRedis/redisLock.go)\\n\\n### 代码封装\\n\\n李四也接到了优化sql加缓存的需求，于是，李四以熟练的让人心疼的手速一顿操作(*复制-粘贴-改代码*)，完成了需求，但是火眼金睛goland给这段代码画上了下划线提示：重复的代码。于是，懒惰的李四不得不开始了封装，以下是封装后，业务侧调用的代码：\\n\\n+ 查询一个count\\n\\n    ```go\\n    // GetCount 查询圈子的总成员数\\n    func (ctl *CommunityUser) GetCount(c *gin.Context, appId, communityId string) (int64, error) {\\n    \\t// 1. 如何从DB查询数据\\n    \\tgetFromDB := func() (string, error) {\\n    \\t\\tvar count int64\\n    \\t\\tif err := ctl.GDB().Model(model.CommunityUser{}).Where(\\\"app_id = ? and community_id = ?\\\", \\n    \\t\\t\\tappId, communityId).Count(&count).Error; err != nil {\\n    \\t\\t\\treturn \\\"\\\", err\\n    \\t\\t}\\n    \\n    \\t\\treturn strconv.FormatInt(count, 10), nil\\n    \\t}\\n    \\n    \\t// 2. 获取并发查询控制器，传递响应配置参数\\n        res, err := eRedis.GetSet(c, ctl.RDB(), cacheKey, time.Hour, getFromDB)\\n    \\tif err != nil {\\n    \\t\\treturn 0, err\\n    \\t}\\n    \\n    \\t// 3. 结果类型转化\\n    \\treturn strconv.ParseInt(res, 10, 64)\\n    }\\n    ```\\n\\n+ 查询一个列表\\n\\n    ```go\\n    // GetRecentlyUser 查询最近加入的N个成员\\n    func (ctl *CommunityUser) GetRecentlyUser(c *gin.Context, appId, communityId string, count int) ([]model.CommunityUser, error) {\\n    \\t// 1. 如何从DB查询数据\\n    \\tgetFromDB := func() (string, error) {\\n    \\t\\tvar users []model.CommunityUser\\n    \\t\\tif err := ctl.GDB().Where(\\\"app_id = ? and community_id = ?\\\", appId, communityId).\\n    \\t\\t\\tOrder(\\\"join_time desc\\\").Limit(count).Find(&users).Error; err != nil {\\n    \\t\\t\\treturn \\\"\\\", err\\n    \\t\\t}\\n    \\n    \\t\\treturn encodeUtil.JSONMarshalString(users)\\n    \\t}\\n    \\n    \\t// 2. 获取并发查询控制器，传递响应配置参数\\n        res, err := eRedis.GetSet(c, ctl.RDB(), cacheKey, time.Hour, getFromDB)\\n    \\tif err != nil {\\n    \\t\\treturn 0, err\\n    \\t}\\n        \\n    \\t// 3. 结果类型转化\\n    \\tvar users []model.CommunityUser\\n    \\tif err := encodeUtil.JSONUnmarshalString(res, &users); err != nil {\\n    \\t\\treturn nil, err\\n    \\t}\\n    \\treturn users, nil\\n    }\\n    ```\\n\\n并发缓存查询的可选参数如下：\\n\\n+ WithLockExpire 设置并发锁过期时间，单位：秒\\n+ WithWaitCache 拿不到锁的请求，是否阻塞等待缓存\\n+ WithWaitCacheTime 拿不到锁的请求阻塞等待时间, 会同时开启WithWaitCache(true)\\n\\n\\n\\n___\\n\\n封装链接：\\n\\n1. https://talkcheap.xiaoeknow.com/mittacychen/ego/-/blob/master/library/eRedis/redisLock.go\\n2. https://talkcheap.xiaoeknow.com/mittacychen/ego/-/blob/master/library/eRedis/concurrentSelect.go\\n\\n参考文章：https://go-zero.dev/cn/redis-lock.html\\n\\n\"}]},{\"title\":\"其他\",\"articles\":[{\"id\":null,\"title\":\"工具推荐\",\"content\":\"\\n| 作用           | 工具                                                   |\\n| -------------- | ------------------------------------------------------ |\\n| 结构体转化     | [copier](https://github.com/jinzhu/copier)             |\\n| 错误堆栈等     | [errors](https://github.com/pkg/errors)                |\\n| json/sql to go | [sql_json_go](https://www.qetool.com/sql_json_go.html) |\\n\\n### 1. 请求体转化工具 copier\\n\\n不同结构体之间的转化，字段少的情况手动赋值还可以接受，如果字段过多，这也是重复性且没有意义的工作，引入 [copier](https://github.com/jinzhu/copier) 工具对结构体进行快速转化\\n\\n```go\\ntype GetReply struct {\\n\\tId        int64  `json:\\\"id\\\"`\\n\\tName      string `json:\\\"name\\\"`\\n\\tCreatedAt int64  `json:\\\"created_at\\\"`\\n\\tUpdatedAt int64  `json:\\\"updated_at\\\"`\\n}\\n\\ntype User struct {\\n\\tId        int64\\n\\tName      string\\n\\tPassword  string\\n\\tSalt      string\\n\\tGender    int8\\n\\tCreatedAt time.Time\\n\\tUpdatedAt time.Time\\n}\\n\\n// UserToReply 查询用户响应方法\\n// @param c\\n// @param user\\nfunc UserToReply(c *gin.Context, user *model.User) {\\n\\tuserReply := userValidator.GetReply{}\\n\\n\\tif err := copier.Copy(&userReply, user); err != nil {\\n\\t\\tresponse.TransformErrAndLog(c, err)\\n\\t\\treturn\\n\\t}\\n\\n\\tres := map[string]interface{}{\\n\\t\\t\\\"user\\\": userReply,\\n\\t}\\n\\tresponse.Success(c, res)\\n}\\n```\\n\\n\"}]}],\"banner\":\"http://static.mittacy.com/blog/202110111011364.jpg\",\"id\":\"1633512445750\"},{\"title\":\"gin-toy\",\"articles\":[{\"title\":\"项目架构\",\"articles\":[{\"id\":null,\"title\":\"项目架构\",\"content\":\"本项目是对 Gin 的二次封装，便于快速开发业务服务\\n\\n> 1. 这是一个基于 Go 语言、Gin 框架的 Web 项目骨架，对常用的库进行封装，开发者可以更快速搭建 Web 服务，更关注属于自己的业务\\n> 2. 项目要求 Go 版本 >= 1.17\\n> 3. 拉取本项目骨架，在此基础上就可以快速开发自己的项目\\n\\n### 1. 项目架构\\n\\n![](http://static.mittacy.com/blog/202207031759858.png)\\n\\n- middleware：全局中间件，所有路由都会经过这些中间件\\n\\n- router 层：定义路由，调用 api 层各个方法。每个路由也可以有自己的中间件\\n\\n- api层：结构包含一个数据封装 dp、一个服务处理 service\\n\\n    1. 调用 validator 层的请求结构体，解析请求参数，如果失败直接返回结果；\\n    2. 调用一个 service 服务，获得返回的数据库模型组合数据；\\n    3. 调用 data process 对service返回的数据进行处理转化为响应结构，然后响应\\n\\n- service 层：service 包含 data 或者调用其他 service\\n\\n    1. 处理各种业务逻辑\\n    2. 调用 data / 其他 service  查询或存储数据完成业务操作\\n\\n- data 层：包含db、cache、外部http调用服务等，涉及数据的查询和持久化都应该在该层实现\\n\\n    > 不管是mysql、redis、mongo、es还是调用其他服务，这些操作其实都是数据的curd，对service层来说都是数据的查询与持久化，因此这些操作都应该写在data层\\n\\n- model 层：定义数据库结构体、http远程调用响应结构体……\\n\\n> model层与validator层的区别在于：\\n>\\n> + model层定义的是数据的存储结构体，交互的对象为数据库/其他服务\\n> + validator层定义的结构体为请求与响应数据，交互的对象为http请求\\n\\n\\n### 2. 项目结构\\n\\n```shell\\n├── app\\n│   ├── api\\t\\t\\t\\t\\t# api控制层\\n│   │   └── user.go\\n│   ├── service\\t\\t\\t\\t# 服务业务逻辑层\\n│   │   ├── smodel\\t\\t\\t# 服务数据定义\\n│   │   │   └── user.go\\n│   │   └── user.go\\n│   ├── data\\t\\t\\t\\t# 数据存储与读取层\\n│   │   └── user.go\\n│   ├── model\\t\\t\\t\\t# 数据库映射结构定义\\n│   │   └── user.go\\n│   ├── dp\\t\\t\\t\\t\\t# 响应数据裁切与封装\\n│   │   └── user.go\\n│   └── validator\\t\\t\\t# 请求、响应数据结构定义\\n│       └── userVdr\\n│           └── user.go\\n├── bizerr\\t\\t\\t\\t\\t# 业务错误定义\\n│   └── code.go\\n├── bootstrap\\t\\t\\t\\t# 启动初始化工作\\n│   ├── config.go\\n│   ├── init.go\\n│   └── log.go\\n├── cmd\\t\\t\\t\\t\\t\\t# 命令工具\\n│   └── start\\n│       ├── http\\n│       │   └── http.go\\n│       └── start.go\\n├── config\\t\\t\\t\\t\\t# 配置数据\\n│   ├── mongo.go\\n│   ├── mysql.go\\n│   └── redis.go\\n├── router\\t\\t\\t\\t\\t# 路由层\\n│   └── router.go\\n├── go.mod\\n├── go.sum\\n├── main.go\\n└── utils\\t\\t\\t\\t\\t# 工具函数\\n    ├── bizUtil\\n    │   ├── ctx.go\\n    │   ├── gin.go\\n    │   └── id.go\\n    ├── randomUtil\\n    │   └── random.go\\n    └── timeUtil\\n        └── time.go\\n```\\n\\n\"}]},{\"title\":\"快速开始\",\"articles\":[{\"id\":null,\"title\":\"01 | 创建项目\",\"content\":\"### 1. 环境准备\\n\\n需要提前安装好对应的依赖环境以及工具：‌\\n\\n- 安装go环境，version >= 1.17\\n- 安装Mysql（如果需要）\\n- 安装Redis（如果需要）\\n\\n建议开启GO111MODULE以及配置\\n\\n```shell\\n$ go env -w GO111MODULE=on\\n$ go env -w GOPROXY=https://goproxy.cn,direct\\n```\\n\\n### 2. 安装\\n\\n安装 ego 命令工具\\n\\n#### go get 安装\\n\\n```shell\\n$ go get -u github.com/mittacy/gin-toy/tools/gotoy@latest\\n```\\n\\n### 3. 创建项目\\n\\n```shell\\n$ gotoy new 项目名\\n```\\n\\n### 4. 修改配置文件\\n\\n配置文件位于项目根目录 `.env.development`，修改对应的配置信息：\\n\\n```shell\\n# 服务配置\\nAPP_NAME=gin-toy-layout\\nAPP_READ_TIMEOUT=10#读等待时间,单位:秒\\nAPP_WRITE_TIMEOUT=10#写等待时间,单位:秒\\n\\n# 日志\\nLOG_PATH=./storages/logs\\nLOG_LOW_LEVEL=debug#业务日志最低级别:debug、info、warn、error\\nLOG_ENCODER_JSON=true#是否为josn日志格式\\nLog_In_Console=true#是否输出到控制台\\n```\\n\\n### 5. 启动服务\\n\\n#### 5.1 使用命令启动\\n\\n```shell\\n$ cd myProjectName\\n$ go mod download\\n$ go build -o ./server .\\n\\n# 运行HTTP服务\\n$ go run . start http -c=.env.development -e=development -p=8080\\n\\n$ curl localhost:8080/user/get?id=1\\n{\\n    \\\"code\\\": 0,\\n    \\\"data\\\": {\\n        \\\"user\\\": {\\n            \\\"id\\\": 1,\\n            \\\"name\\\": \\\"xiyangyang\\\",\\n            \\\"age\\\": 5,\\n            \\\"created_at\\\": \\\"2022-07-01 21:01:01\\\",\\n            \\\"updated_at\\\": \\\"2022-07-03 12:02:15\\\"\\n        }\\n    },\\n    \\\"msg\\\": \\\"success\\\",\\n    \\\"request_id\\\": \\\"r62c16c685b538_IsuCvd0qaQop4hxNa0\\\"\\n}\\n```\\n\\n启动配置信息：\\n\\n+ `-c` 配置文件路径\\n+ `-p` 端口号\\n+ `-e` 服务运行环境\\n    + development 开发环境\\n    + test 测试环境\\n    + production 生成环境\\n\\n#### 5.2 Docker启动\\n\\n```shell\\n$ docker build -t 镜像名 .\\n\\n# 启动http服务\\n$ docker run --restart=on-failure --name 服务名1 -d -p 宿主端口:8080 镜像名 start http -c=.env.development -e=production -p=8080\\n# 简写\\n$ docker run --restart=on-failure --name 服务名1 -d -p 宿主端口:8080 镜像名\\n\\n# 启动job异步服务\\n$ docker run --restart=on-failure --name 服务名2 -d -p 宿主端口:8080 镜像名 start job -c=.env.development -e=production\\n\\n# 启动task定时服务\\n$ docker run --restart=on-failure --name 服务名2 -d -p 宿主端口:8080 镜像名 start task -c=.env.development -e=production\\n```\\n\\n#### 5.3 使用 systemctl 启动\\n\\n以http服务为例，job、task同理\\n\\n```shell\\n# systemctl配置文件\\n$ cd /usr/lib/systemd/system\\n$ vim 服务名_http.service\\n[Unit]\\nDescription=服务名_http.service\\nAfter=network.target\\n[Service]\\nType=simple\\nEnvironment=APP_ENV=development\\nWorkingDirectory=项目根目录\\nExecStart=可执行文件路径 start http -c=.env.development -e=development -p=8080\\nRestartSec=1s\\nRestart=always\\nKillMode=process\\nUser=www\\nGroup=www\\n[Install]\\nWantedBy=multi-user.target\\n\\n# 启动服务\\n$ systemctl start 服务名_http.service\\n```\\n\\n### 项目模板\\n\\ngotoy 是通过在线 github 仓库模板，并且进行拉取创建项目，对应模板地址：‌[gin-toy-layout](https://github.com/mittacy/gin-toy-layout)\\n\\n\"},{\"id\":null,\"title\":\"02 | 业务编码\",\"content\":\"+ model 数据库结构定义\\n+ 编写API文档\\n+ validator 请求结构定义\\n+ api 接口，服务编排\\n+ service 业务逻辑处理\\n+ data 数据持久化、缓存等处理\\n+ data process 响应数据裁切、包装与响应\\n+ router 路由编写\\n+ 测试\\n+ 完善API文档\\n\\n\\n\\n以下举例：接到一个**获取用户列表**的接口需求\\n\\n### 1. model数据库结构定义\\n\\n确定好该接口涉及的数据库表，这里只涉及到user表，如果表不存在，则需要先进行创建，位于项目：`app/model/xxx.go`\\n\\n> 建议使用工具生成代码，这里推荐：https://www.qetool.com/sql_json_go.html\\n\\n```go\\npackage model\\n\\nconst (\\n\\tUserIsDeletedNo  = 0\\n\\tUserIsDeletedYes = 1\\n)\\n\\ntype User struct {\\n\\tId        int64     `json:\\\"id\\\"`\\n\\tName      string    `json:\\\"name\\\"`\\n\\tAge       int       `json:\\\"age\\\"`\\n\\tIsDeleted int8      `json:\\\"is_deleted\\\"`\\n\\tCreatedAt time.Time `json:\\\"created_at\\\"`\\n\\tUpdatedAt time.Time `json:\\\"updated_at\\\"`\\n}\\n\\nfunc (*User) TableName() string {\\n\\treturn \\\"table_name\\\"\\n}\\n```\\n\\n数据库所有的状态类字段应该定义为常量存储在 model 层，比如上面定义的 `UserDeletedNo` 和 `UserDeletedYes` 。好处是在 data 层统一使用这些变量，不需要记忆数字状态码，当数据库状态码代表的意义变更时，也不需要修改 `data` 层，只需要 model 层统一修改即可。\\n\\n**另外，如果该参数可能需要前端传参，不建议使用0、空字符串等go中各种类型的默认值，因为请求参数不传就会是类型的默认空值，只能通过指针来判断参数是否有传递，很不方便，尽量在数据库设计的时候就避免**\\n\\n### 2. 编写API文档\\n\\n在YAPI文档中添加该路由并定义请求参数和响应数据\\n\\n![](http://static.mittacy.com/blog/202112121748210.png)\\n\\n将mock的json响应数据粘贴到 YAPI 响应数据处即可生成响应结构文档\\n\\n![](http://static.mittacy.com/blog/202112121817770.png)\\n\\n生成的响应文档如下，我们可以给每个字段设置必定返回、添加备注，点击设置按钮还能设置最大、最小、枚举值等功能\\n\\n![](http://static.mittacy.com/blog/202112121818103.png)\\n\\n> 不推荐在代码中加注释后通过命令生成文档：\\n>\\n> + 不安全，如果公司没内网所有人可看到该文档\\n> + 忘记修改\\n> + 语法虽简单，但每次写还是得去找\\n> + Go每次提交API文档注释也会导致重新编译启动浪费资源\\n>\\n> 建议使用 [yapi](http://yapi.smart-xwork.cn/project/98312/interface/api)，后端开发人员可以使用 yapi编写文档并测试接口，修改测试用例的同时也就修改了文档，同时可以编写自动化测试用例，每次编写完成只需要一键即可测试接口。文档只开放给前端只读权限，安全高效\\n\\n### 3. validator 请求、响应结构定义\\n\\nvalidator 定义请求与响应结构体，每个请求体的参数必须通过定义结构体定义，在结构体中添加限制对请求参数进行校验，位于 `app/validator/xxxVdr/`\\n\\n```go\\npackage validator\\n\\ntype ListReq struct {\\n\\tPage     int `form:\\\"page\\\" binding:\\\"required,min=1\\\"`\\n\\tPageSize int `form:\\\"page_size\\\" binding:\\\"required,min=1,max=50\\\"`\\n}\\n\\ntype ListReplyUser struct {\\n\\tId   int64  `json:\\\"id\\\"`\\n\\tName string `json:\\\"name\\\"`\\n\\tAge  int    `json:\\\"age\\\"`\\n}\\n```\\n\\n同样的，响应数据也应该定义结构体进行响应，防止将不必要的字段返回给前端，比如说查询出的用户可能包含密码等敏感字段，通过我们的 reply 结构体转化后，就只剩下 `id`、`name`、`age` 四个字段\\n\\n**响应结构定义应该多包一层，比如这里给用户列表包了一层users，即使这里是获取用户详情，也建议多包一层 user代表用户信息，方便扩展增加其他信息，我们的业务API一般是面向业务而不是面向资源，往往不是获取对单一资源的操作**\\n\\n### 4. api接口\\n\\n接口层只负责请求解析、服务编排与响应，不编写业务逻辑\\n\\n```go\\nfunc (ctl *userApi) List(c *gin.Context) {\\n    // 请求参数校验与绑定\\n\\treq := userVdr.ListReq{}\\n\\tif err := c.ShouldBindQuery(&req); err != nil {\\n\\t\\tresponse.ValidateErr(c, err)\\n\\t\\treturn\\n\\t}\\n\\n    // 调用服务查询/存储数据\\n\\tdata, err := service.User.List(c, req.Page, req.PageSize)\\n\\tif err != nil {\\n\\t\\tresponse.FailCheckBizErr(c, \\\"查询记录错误\\\", err)\\n\\t\\treturn\\n\\t}\\n\\n    // 响应数据处理\\n\\tres := ctl.dp.List(c, data)\\n\\tresponse.Success(c, res)\\n}\\n```\\n\\n### 5. service 层\\n\\nservice 层涉及业务逻辑编写，比如创建用户时对用户密码的加密等操作都应该在 service 层，service 内调用 data 服务来操作数据。service 层并不关心数据如何获取、如何存储，而是通过调用 data 接口获取和存储数据。\\n\\n**service层应该尽量避免跨服务调用data，应该通过调用其他service来实现，避免直接调用data层忽略了某些必要的服务处理逻辑，应该找对应服务的负责人询问调用哪个service服务合适**\\n\\n\\n\\n首先定义service层将返回的数据组合：`app/service/smodel/xxx.go`\\n\\n```go\\ntype List struct {\\n\\tUsers []model.User\\n\\tTotal int64\\n}\\n```\\n\\n编写服务：`app/service/xxx.go`\\n\\n```go\\npackage service\\n\\n// 一般情况下service应该只引用并控制自己的data模型，需要其他服务的功能请service.Xxx调用服务而不是引入其他data模型\\n\\n// 用户服务\\nvar User userService\\n\\ntype userService struct {\\n\\tdata data.User\\n}\\n\\n// 用户翻页列表\\nfunc (ctl *userService) List(c *gin.Context, page, pageSize int) (*smodel.List, error) {\\n\\t// 查询用户列表\\n\\tusers, err := ctl.data.List(c, page, pageSize)\\n\\tif err != nil {\\n\\t\\treturn nil, errors.WithMessage(err, \\\"查询用户列表错误\\\")\\n\\t}\\n\\n\\t// 查询用户总数\\n\\ttotal, err := ctl.data.GetTotal(c)\\n\\tif err != nil {\\n\\t\\treturn nil, errors.WithMessage(err, \\\"查询用户总数错误\\\")\\n\\t}\\n\\n\\tres := &smodel.List{\\n\\t\\tUsers: users,\\n\\t\\tTotal: total,\\n\\t}\\n\\treturn res, nil\\n}\\n```\\n\\n### 6. data层\\n\\ndata 层就是数据操作层，包含持久化、缓存、外部服务调用等的操作，首先定义数据操作结构体包含 mysql 和 redis 的操作句柄，然后使用数据库连接进行相应的操作\\n\\n```go\\ntype User struct {\\n\\teMysql.EGorm\\n\\teRedis.ERedis\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tEGorm:  eMysql.EGorm{ConfName: \\\"localhost\\\"},\\n\\t\\tERedis: eRedis.ERedis{ConfName: \\\"localhost\\\", DB: 0},\\n\\t}\\n}\\n\\nfunc (ctl *User) List(c context.Context, page, pageSize int) ([]model.User, error) {\\n\\tstartIndex := (page - 1) * pageSize\\n\\n\\tvar users []model.User\\n\\tif err := ctl.GDB().Where(\\\"deleted != ?\\\", model.UserIsDeletedNo).\\n\\t\\tOffset(startIndex).Limit(pageSize).Order(\\\"created_at\\\").Find(&users).Error; err != nil {\\n\\t\\treturn nil, errors.WithStack(err)\\n\\t}\\n\\n\\treturn users, nil\\n}\\n\\nfunc (ctl *User) GetTotal(c context.Context) (int64, error) {\\n\\tvar total int64\\n\\tif err := ctl.GDB().Model(model.User{}).Where(\\\"deleted != ?\\\", model.UserIsDeletedNo).Count(&total).Error; err != nil {\\n\\t\\treturn 0, errors.WithStack(err)\\n\\t}\\n\\treturn total, nil\\n}\\n```\\n\\n### 7. dataPrcess\\n\\n不能将数据库查询出来的数据直接返回给前端，应该进行一些必要处理：裁切、组装、转化后再响应给前端\\n\\n```go\\npackage dp\\n\\ntype UserDP struct{}\\n\\nfunc NewUserDP() UserDP {\\n\\treturn UserDP{}\\n}\\n\\nfunc (ctl *UserDP) List(c *gin.Context, data *smodel.List) map[string]interface{} {\\n\\tusers := make([]userVdr.ListReplyUser, len(data.Users))\\n\\tfor i, v := range data.Users {\\n\\t\\tusers[i].Id = v.Id\\n\\t\\tusers[i].Name = v.Name\\n\\t\\tusers[i].Age = v.Age\\n\\t}\\n\\n\\treturn map[string]interface{}{\\n\\t\\t\\\"users\\\": users,\\n\\t\\t\\\"total\\\": data.Total,\\n\\t}\\n}\\n```\\n\\n### 8. router 层\\n\\n```go\\npackage router\\n\\nfunc InitRouter(r *gin.Engine) {\\n\\tg := r.Group(\\\"/api\\\")\\n\\t{\\n\\t\\tg.GET(\\\"/users\\\", api.User.List)\\n\\t}\\n}\\n```\\n\\n### 9. 测试\\n\\n至此，所有代码都完成了，开发者应该在本地自行进行测试，首先需要用到 mysql 和 redis\\n\\n在配置文件填写对应信息：\\n\\n```yaml\\n# Mysql-localhost\\nDB_LOCALHOST_RW_HOST = 127.0.0.1  # 使用docker时localhost须更改为host.docker.internal\\nDB_LOCALHOST_RW_PORT = 3306\\nDB_LOCALHOST_RW_DATABASE = blog\\nDB_LOCALHOST_RW_USERNAME = root\\nDB_LOCALHOST_RW_PASSWORD = password\\n\\n# Redis-localhost\\nREDIS_LOCALHOST_RW_HOST = 127.0.0.1\\nREDIS_LOCALHOST_RW_PASSWORD =\\nREDIS_LOCALHOST_RW_PORT = 6379\\n```\\n\\n启动服务并请求接口测试\\n\\n\\n\\n___\\n\\ngotoy工具提供模板生成功能，不需要自己编写声明，详情查看下一节 `03 | 构建工具`\"},{\"id\":null,\"title\":\"03 | 构建工具\",\"content\":\"业务编码章节中，讲到完整的业务编码流程，在 Go 中声明各种结构体、接口还是比较繁琐重复的，建议使用构建工具自动生成\\n\\n### 1. 安装\\n\\n```shell\\n$ go env\\nGOPATH=\\\"/Users/mittacy/go\\\"\\nGOROOT=\\\"/usr/local/go\\\"\\n\\n# 配置环境变量，mac如下\\n$ vim .bash_profile\\nexport GOROOT=/usr/local/go\\nexport GOPATH=/Users/mittacy/go\\nexport GOBIN=$GOPATH/bin\\nexport PATH=$PATH:$GOBIN\\n\\n$ GO111MODULE=on\\n$ GOPROXY=https://goproxy.cn/,direct\\n\\n# 安装\\n$ go get -u github.com/mittacy/gin-toy/tools/gotoy@latest\\n```\\n\\n### 2. 创建项目\\n\\n通过 gotoy 命令创建项目模板：\\n\\n```bash\\n$ gotoy new 项目名\\n```\\n\\n### 3. 代码生成\\n\\n#### 3.1 创建项目\\n\\n```shell\\n$ gotoy new 项目名\\n```\\n\\n#### 3.2 模板生成\\n\\n```shell\\n# 创建 api、validator、transform、service、data、model 代码模板\\n$ gotoy tpl api article\\n\\n# 创建 service、data、model 代码模板\\n$ gotoy tpl service article\\n\\n# 创建 data、model 代码模板\\n$ gotoy tpl data article\\n\\n# 创建 model 代码模板\\n$ gotoy tpl model article\\n```\\n\\n+ `-d` 指定注入data层的数据库类型: inject database handle:null,mysql,redis,mongo,http\\n+ `-t` 指定生成的文件目录\\n\\n\"},{\"id\":null,\"title\":\"04 | 代码示例\",\"content\":\"### 综合项目\\n\\n-  \"},{\"id\":null,\"title\":\"05 | 常见问题\",\"content\":\"### 1. new提示Permission denied\\n\\n具体参考https://www.zhihu.com/question/21402411\\n\\n如果密钥只用在github等代码库，则建议清空重新设置的方案：\\n\\n1. 清空密钥\\n\\n    ```shell\\n    $ cd ~/.ssh\\n    $ rm -rf ./*\\n    ```\\n\\n2. 重新生成密钥\\n\\n    ```shell\\n    # 设置git信息\\n    $ git config --global user.name \\\"\\\"\\n    $ git config --global user.email \\\"\\\"\\n    \\n    # 生成 ssh key，一直回车\\n    $ ssh-keygen -t rsa -C \\\"邮箱\\\"\\n    ```\\n\\n    `~/.ssh`下生成了id_rsa.pub和id_rsa,\\n\\n    将id_rsa.pub里的内容复制添加到Github、Gitlab、Gitee……个人设置的SSH Keys里即可\\n\\n\"}]},{\"title\":\"基本封装与使用\",\"articles\":[{\"id\":null,\"title\":\"01 | 配置读取\",\"content\":\"### 1. 程序启动配置\\n\\n- -c 配置文件路径\\n\\n- -p 端口号\\n\\n- -e 服务运行环境\\n\\n- - development 开发环境，会将日志同步打印到控制台\\n    - test 测试环境\\n    - production 生成环境\\n\\n```shell\\n$ go run . start http -c=.env.developement -e=developemtn -p=1028\\n```\\n\\n### 2. 配置文件读取\\n\\n配置采用 [viper](https://github.com/spf13/viper) 库，项目采用了 env 配置文件类型，项目初始化时，会根据启动命令 -c 读取env文件，将所有变量缓存在内存，同时监听配置文件，如果配置文件修改，会重新解析配置文件\\n\\n```yaml\\n# 服务配置\\nAPP_NAME=gin-toy-layout\\nAPP_READ_TIMEOUT=10#读等待时间,单位:秒\\nAPP_WRITE_TIMEOUT=10#写等待时间,单位:秒\\n\\n# 日志\\nLOG_PATH=./storages/logs\\nLOG_LOW_LEVEL=debug#业务日志最低级别:debug、info、warn、error\\nLOG_ENCODER_JSON=true#是否为josn日志格式\\nLog_In_Console=true#是否输出到控制台\\n```\\n\\n项目初始化时，会根据启动命令读取env文件路径，默认为 `./.env.development`，将所有变量缓存在内存，同时监听配置文件，如果配置文件修改，会重新解析配置文件\\n\\n需要用到配置信息时，有以下方法获取：\\n\\n+ 直接使用Viper引用即可：`viper.GetString(\\\"key\\\")`\\n\\n+ 定义结构体获取，比如定义 Mysql 结构体，则可以这样获取\\n\\n    ```go\\n    type MysqlConf struct {\\n        Host     string `mapstructure:\\\"host\\\"`\\n        Port     int    `mapstructure:\\\"port\\\"`\\n        Database string `mapstructure:\\\"database\\\"`\\n        User     string `mapstructure:\\\"user\\\"`\\n        Password string `mapstructure:\\\"password\\\"`\\n        Params   string `mapstructure:\\\"params\\\"`\\n    }\\n    \\n    var dbConfig Mysql\\n    if err := viper.UnmarshalKey(key, &dbConfig); err != nil {\\n        fmt.Println(err)\\n    }\\n    ```\\n\\n\\n更多的读取配置方法可参考 [viper官方文档](https://github.com/spf13/viper)\"},{\"id\":null,\"title\":\"02 | 日志\",\"content\":\"日志库采用了目前Go日志库速度最快的 [zap](https://github.com/uber-go/zap)，封装代码位于 `github.com/mittacy/gotoy/core/log` 中\\n\\n### 1. 全局配置函数\\n\\n日志库对外暴露了部分全局配置函数：\\n\\n+ 日志默认记录路径为项目根目录，可通过 `log.WithPath(\\\"./\\\")` 设置日志记录位置\\n+ 最低日志级别默认为DebugLevel，可通过 `log.WithLevel(log.DebugLevel)`\\n+ `log.WithLogInConsole(true/false)` 配置是否打印到控制台，默认不打印\\n+ `log.WithFields(field ...Field)` 添加全局日志字段，所有新增的日志句柄都会包含该字段\\n+ `log.WithEncoderJSON(bool)` 日志格式是否为json格式，开发环境可以设置为false，方便开发者阅读排查问题；现网建议使用 true，方便日志收集\\n\\n以上配置需要调用 `log.SetDefaultConf(log.WithLogInConsole(true))` 进行设置\\n\\n假如我们有以下配置文件：\\n\\n```yaml\\n# 日志\\nLOG_PATH = ./storage/logs\\nLOG_LOW_LEVEL = debug           # 业务日志最低级别：debug、info、warn、error\\nLOG_ENCODER_JSON = true         # 是否为josn日志格式\\nLog_In_Console = true\\t\\t\\t# 是否打印到控制台\\n```\\n\\n在初始化工作中对日志库进行配置：\\n\\n```go\\nfunc InitLog() {\\n    logPath := viper.GetString(\\\"LOG_PATH\\\")\\n\\tlogLevel := viper.GetString(\\\"LOG_LOW_LEVEL\\\")\\n\\tlogEncoderJson := viper.GetBool(\\\"LOG_ENCODER_JSON\\\")\\n\\tlogInConsole := viper.GetBool(\\\"Log_In_Console\\\")\\n\\tglobalFields := []zapcore.Field{\\n\\t\\t{\\n\\t\\t\\tKey:    \\\"module_name\\\",\\n\\t\\t\\tType:   zapcore.StringType,\\n\\t\\t\\tString: viper.GetString(\\\"APP_NAME\\\"),\\n\\t\\t},\\n\\t}\\n\\n\\tlog.SetDefaultConf(\\n\\t\\tlog.WithPath(logPath),\\n\\t\\tlog.WithTimeFormat(timeUtil.TimeFormat),\\n\\t\\tlog.WithLevel(logLevel),\\n\\t\\tlog.WithEncoderJSON(logEncoderJson),\\n\\t\\tlog.WithFields(globalFields...),\\n\\t\\tlog.WithLogInConsole(logInConsole))\\n}\\n```\\n\\n### 2. 使用\\n\\n#### 默认日志\\n\\n```go\\nfunc TestLog(t *testing.T) {\\n\\tbizLog := New(\\\"default\\\")\\n\\n\\tbizLog.Debug(\\\"this is SugarDebug\\\")\\n\\tbizLog.Info(\\\"this is SugarInfo\\\")\\n\\tbizLog.Warn(\\\"this is SugarWarn\\\")\\n\\tbizLog.Error(\\\"this is SugarError\\\")\\n\\n\\tbizLog.Debugf(\\\"this is %s\\\", \\\"Debugf\\\")\\n\\tbizLog.Infof(\\\"this is %s\\\", \\\"Infof\\\")\\n\\tbizLog.Warnf(\\\"this is %s\\\", \\\"Warn\\\")\\n\\tbizLog.Errorf(\\\"this is %s\\\", \\\"Errorf\\\")\\n\\n\\tbizLog.Debugw(\\\"this is Debugw\\\", \\\"k\\\", \\\"Debugw\\\")\\n\\tbizLog.Infow(\\\"this is Infow\\\", \\\"k\\\", \\\"Infow\\\")\\n\\tbizLog.Warnw(\\\"this is Warnw\\\", \\\"k\\\", \\\"Warnw\\\")\\n\\tbizLog.Errorw(\\\"this is Errorw\\\", \\\"k\\\", \\\"Errorw\\\")\\n}\\n```\\n\\n在默认日志文件`default.log` 中将会写相应日志信息\\n\\n#### 自定义日志文件\\n\\n```go\\n// New 创建新日志文件句柄，使用默认配置\\n// @param name 日志名\\n// @param options 日志配置，将覆盖默认配置\\n// @return *Logger\\nfunc New(name string, options ...ConfigOption) *Logger {}\\n```\\n\\noptions为自定义配置信息，有如下配置可选：\\n\\n+ WithPath 设置日志路径, 修改后，新建的日志将会是新配置，已经建立的日志配置不变\\n+ WithLevel 设置服务记录的最低日志级别\\n+ WithLogInConsole 是否输出到控制台\\n+ WithFields 添加全局日志的新字段, 新建的日志将会是新配置，已经建立的日志配置不变\\n+ WithEncoderJSON 是否设置为json格式日志\\n+ WithTimeFormat 设置时间格式\\n+ WithPreName 设置日志前缀\\n+ WithRequestIdKey 设置请求上下文请求id键名，记录日志时，将从上下文中取请求id并记录\\n\\n### 3. 日志追踪\\n\\n```go\\nfunc TestWithRequestTrace(t *testing.T) {\\n\\tk := \\\"request_id\\\"\\n\\tc := context.WithValue(context.Background(), k, \\\"r61f0ed0d70098_Zw8R1aoyl4tGeB4HMV\\\")\\n\\n\\t// 告知log如何从上下文哪个键名获取请求id\\n\\tSetDefaultConf(WithRequestIdKey(k))\\n\\n\\tl := New(\\\"trace\\\")\\n\\tl.DebugWithTrace(c,\\\"this is SugarDebug\\\")\\n\\tl.InfoWithTrace(c,\\\"this is SugarInfo\\\")\\n\\tl.WarnWithTrace(c,\\\"this is SugarWarn\\\")\\n\\tl.ErrorWithTrace(c,\\\"this is SugarError\\\")\\n\\n\\tl.DebugfWithTrace(c,\\\"this is %s\\\", \\\"Debugf\\\")\\n\\tl.InfofWithTrace(c,\\\"this is %s\\\", \\\"Infof\\\")\\n\\tl.WarnfWithTrace(c,\\\"this is %s\\\", \\\"Warn\\\")\\n\\tl.ErrorfWithTrace(c,\\\"this is %s\\\", \\\"Errorf\\\")\\n\\n\\tl.DebugwWithTrace(c,\\\"this is Debugw\\\", \\\"k\\\", \\\"Debugw\\\")\\n\\tl.InfowWithTrace(c,\\\"this is Infow\\\", \\\"k\\\", \\\"Infow\\\")\\n\\tl.WarnwWithTrace(c,\\\"this is Warnw\\\", \\\"k\\\", \\\"Warnw\\\")\\n\\tl.ErrorwWithTrace(c,\\\"this is Errorw\\\", \\\"k\\\", \\\"Errorw\\\")\\n}\\n\\n```\\n\\n\"},{\"id\":null,\"title\":\"03 | 请求校验与响应\",\"content\":\"### 1. 请求校验\\n\\ngin已经内置了 Validator 校验器，直接对结构体添加 tag 即可，具体规则查看可以查看 [go validator](https://juejin.cn/post/6847902214279659533)\\n\\n但是，如果参数不满足规则，将会响应返回英文等提示，不是很符合我们的需要。项目对校验提示进行了处理封装，位于 `github.com/mittacy/gin-toy/core/response/validator.go`，定义了一个方法 `ValidateErr(c *gin.Context, err error)`， json 解析后如果 err 不为空，直接调用响应即可，会对错误进行判断，如果是请求数据错误，会返回相应的错误信息；如果是其他错误，会返回 json错误。\\n\\n举个创建用户的例子，请求结构体定义如下：\\n\\n```go\\ntype CreateReq struct {\\n   Name     string `json:\\\"name\\\" binding:\\\"required,min=1,max=20\\\"`\\n   Info     string `json:\\\"info\\\" binding:\\\"required,min=1,max=100\\\"`\\n   Password string `json:\\\"password\\\" binding:\\\"required,min=1,max=20\\\"`\\n}\\n```\\n\\n\\n\\n```go\\npackage api\\n\\nfunc Xxxx() {\\n    req := userValidator.CreateReq{}\\n    if err := c.ShouldBindJSON(&req); err != nil {\\n        response.ValidateErr(c, err)\\n        return\\n    }\\n\\n    // ……\\n}\\n```\\n\\n### 2. 响应\\n\\n在项目/bizerr中定义错误信息\\n\\n```go\\npackage bizerr\\n\\nimport (\\n\\t\\\"github.com/mittacy/gin-toy/core/bizerr\\\"\\n)\\n\\nvar (\\n\\t// 用户相关错误\\n\\tUserNoExists = &bizerr.BizErr{Code: 100101, Msg: \\\"用户不存在\\\"}\\n)\\n```\\n\\n前后端交互中，后端返回的数据必须对结构进行统一规定，方便前端对响应数据进行统一处理、过滤\\n\\n```go\\n{\\n    \\\"code\\\": 0,\\t// 业务码\\n    \\\"msg\\\": \\\"提示信息\\\",\\n    \\\"data\\\": {}\\n}\\n```\\n\\n在本项目中，封装了多个方法进行响应，编码时应该调用方法而不是自己再写响应方法，防止出现数据结构不统一的情况\\n\\n封装位置位于：`github.com/mittacy/gin-toy/core/response`\\n\\n实际开发中，经常需要进行日志记录后响应，所以这里也封装了响应与日志方法：\\n\\n```go\\nfunc (ctl *User) Get(c *gin.Context) {\\n\\t// 参数校验\\n    // ……\\n    \\n    // 调用\\n\\tuser, err := service.User.GetById(id)\\n\\tif err != nil {\\n        // 检查相关的业务错误，记录日志并响应\\n        response.FailCheckBizErr(c, \\\"查询记录错误\\\", err)\\n\\t\\treturn\\n\\t}\\n\\n    data := ctl.dp.GetReply(c, user)\\n    response.Success(c, data)\\n}\\n```\\n\\n将会检查错误服务返回的错误，如果是 api类型的错误，则响应给前端相应的错误提示和错误码;否则记录日志并响应给前端未知错误，同时如果是开发和测试环境，将会返回详细错误信息，否则只返回“未知错误”\\n\\n\\n\\n其他响应方法：\\n\\n```go\\n// 自定义响应\\nfunc Custom(c *gin.Context, httpCode, apiCode int, msg string, data interface{}) {\\n\\tc.JSON(httpCode, gin.H{\\n\\t\\t\\\"code\\\":       apiCode,\\n\\t\\t\\\"msg\\\":        msg,\\n\\t\\t\\\"data\\\":       data,\\n\\t\\t\\\"request_id\\\": c.GetString(\\\"requestId\\\"),\\n\\t})\\n}\\n\\n// 成功响应\\nfunc Success(c *gin.Context, data interface{}) {\\n\\tCustom(c, http.StatusOK, apierr.Success.Code, \\\"success\\\", data)\\n}\\n\\n// 成功响应带消息提示\\nfunc SuccessMsg(c *gin.Context, data interface{}, msg string) {\\n\\tCustom(c, http.StatusOK, apierr.Success.Code, msg, data)\\n}\\n\\n// 失败响应\\nfunc Fail(c *gin.Context) {\\n\\tCustom(c, http.StatusOK, apierr.Param.Code, \\\"fail\\\", struct{}{})\\n}\\n\\n// 带自定义信息的失败响应\\nfunc FailMsg(c *gin.Context, msg string) {\\n\\tCustom(c, http.StatusOK, apierr.Param.Code, msg, struct{}{})\\n}\\n\\n// 带有错误的失败响应\\nfunc FailErr(c *gin.Context, err error) {\\n\\tCustom(c, http.StatusOK, apierr.ErrCode(err), err.Error(), struct{}{})\\n}\\n\\n// 未知错误响应\\nfunc Unknown(c *gin.Context) {\\n\\tCustom(c, http.StatusInternalServerError, apierr.Unknown.Code, apierr.Unknown.Error(), struct{}{})\\n}\\n\\n// 未认证响应\\nfunc Unauthorized(c *gin.Context) {\\n\\tCustom(c, http.StatusUnauthorized, apierr.Unauthorized.Code, apierr.Unauthorized.Error(), struct{}{})\\n}\\n\\n// 权限不足响应\\nfunc Forbidden(c *gin.Context) {\\n\\tCustom(c, http.StatusForbidden, apierr.Forbidden.Code, apierr.Forbidden.Error(), struct{}{})\\n}\\n```\\n\\n\"}]},{\"title\":\"常用工具封装与使用\",\"articles\":[{\"id\":null,\"title\":\"01 | Mysql操作\",\"content\":\"项目在 `github.com/mittacy/gin-toy/core/eMysql` 中封装了 [gorm](https://gorm.io/zh_CN/docs/index.html) \\n\\n在使用前，必须先初始化配置\\n\\n```go\\nvar mysqlConfigs map[string]eMysql.MultipleConf\\n\\nfunc InitMysql() {\\n\\tmysqlConfigs = map[string]eMysql.MultipleConf{\\n\\t\\t\\\"localhost\\\": {\\n\\t\\t\\tSources: []eMysql.Conf{\\n\\t\\t\\t\\t{\\n\\t\\t\\t\\t\\tHost:     viper.GetString(\\\"MYSQL_LOCALHOST_RW_HOST\\\"),\\n\\t\\t\\t\\t\\tPort:     viper.GetInt(\\\"MYSQL_LOCALHOST_RW_PORT\\\"),\\n\\t\\t\\t\\t\\tDatabase: \\\"db_name\\\",\\n\\t\\t\\t\\t\\tUser:     viper.GetString(\\\"MYSQL_LOCALHOST_RW_USER\\\"),\\n\\t\\t\\t\\t\\tPassword: viper.GetString(\\\"MYSQL_LOCALHOST_RW_PASSWORD\\\"),\\n\\t\\t\\t\\t},\\n\\t\\t\\t},\\n\\t\\t},\\n\\t}\\n\\n\\teMysql.Init(mysqlConfigs, eMysql.WithName(\\\"mysql\\\"),\\n\\t\\teMysql.WithSlowThreshold(viper.GetDuration(\\\"GORM_SLOW_LOG_THRESHOLD\\\")),\\n\\t\\teMysql.WithIgnoreRecordNotFound(true))\\n}\\n```\\n\\n在结构体中引入并在初始化时给 `MysqlConfName` 赋值，使用GDB()即可获取gorm连接\\n\\n```go\\ntype User struct {\\n\\teMysql.EGorm\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tEGorm:  eMysql.EGorm{ConfName: \\\"localhost\\\"},\\n\\t}\\n}\\n\\nfunc (ctl *User) GetById(c *gin.Context, id int64) (*model.User, error) {\\n\\tuser := model.User{}\\n\\tif err := ctl.GDB().Where(\\\"id = ?\\\", id).First(&user).Error; err != nil {\\n\\t\\tif errors.Is(err, gorm.ErrRecordNotFound) {\\n            return nil, apierr.UserNoExist\\n\\t\\t}\\n\\t\\n\\t\\treturn nil, errors.WithStack(err)\\n\\t}\\n    \\n\\treturn user, nil\\n}\\n```\\n\\n强制要求只在 data 层涉及数据库的操作，并且将库错误转化为业务错误向上层抛出。\\n\\n例如，现在有一个查询指定用户的操作使用了gorm库，那么需要在 `apierr/err.go` 中定义业务错误`apierr.UserNoExist`，然后在 data 层判断错误是否为 `gorm.ErrRecordNotFound` 并转化为定义的业务错误 `apierr.UserNoExist`\\n\\n> 这样做的好处是，底层不需要强制使用哪个库，大家可以选用自己喜欢的框架，sql、sqlx、gorm、xorm……，只需要将对应的错误转化为业务错误，这样在上层 api 层只需要判断自己关心的业务错误并做相应的处理即可\\n\\n### 堆栈\\n\\n为了更方便地定位错误，我们需要在日志中记录堆栈，但 zap 本身记录的堆栈开始位置是记录日志的位置，我们需要详细到底层才能更好地定位。很遗憾 go 默认的 errors 没有带堆栈记录，我们需要引入外部工具 [errors](https://github.com/pkg/errors)\\n\\n```go\\nif err := ctl.GDB().Where(\\\"id = ?\\\", id).First(&user).Error; err != nil {\\n    if errors.Is(err, gorm.ErrRecordNotFound) {\\n        return nil, apierr.UserNoExist\\t\\t// 业务错误属于可控错误，不需要堆栈\\n    }\\n\\n    return nil, errors.WithStack(err)\\t\\t// 不可控错误，包裹err，从此处开始追踪堆栈\\n}\\n```\\n\\n比如上面我们查询一个用户记录，首先对结果判断错误是否是用户不存在:\\n\\n+ 如果是，则转化为我们的业务错误直接抛出\\n+ 如果不是，我们使用了 `errors.WithStack(err)` 将错误进行封装，这个错误将带有从这里开始一直到我们使用err的位置的堆栈信息\\n\\n___\\n\\n更多gorm操作请查看 [gorm官方文档](https://gorm.io/zh_CN/docs/index.html)\\n\"},{\"id\":null,\"title\":\"02 | Redis操作\",\"content\":\"项目在 `github.com/mittacy/gin-toy/core/eRedis` 中封装了 [go-redis](https://github.com/go-redis/redis) \\n\\n在使用前，必须先初始化配置\\n\\n```go\\nvar redisConfigs map[string]eRedis.Conf\\n\\nfunc InitRedis() {\\n\\tredisConfigs = map[string]eRedis.Conf{\\n\\t\\t\\\"localhost\\\": {\\n\\t\\t\\tHost:        viper.GetString(\\\"REDIS_LOCALHOST_RW_HOST\\\"),\\n\\t\\t\\tPassword:    viper.GetString(\\\"REDIS_LOCALHOST_RW_PASSWORD\\\"),\\n\\t\\t\\tPort:        viper.GetInt(\\\"REDIS_LOCALHOST_RW_PORT\\\"),\\n\\t\\t\\tPoolSize:    viper.GetInt(\\\"REDIS_LOCALHOST_POOL_SIZE\\\"),\\n\\t\\t\\tMinIdleConn: viper.GetInt(\\\"REDIS_LOCALHOST_MIN_IDLE_CONN\\\"),\\n\\t\\t\\tIdleTimeout: viper.GetDuration(\\\"REDIS_LOCALHOST_IDLE_TIMEOUT\\\"),\\n\\t\\t},\\n\\t}\\n\\n\\teRedis.Init(redisConfigs)\\n}\\n```\\n\\n在结构体中引入并在初始化时给 `ConfName、DB` 赋值，使用RDB()即可获取redis连接\\n\\n> *以上例子只是为了说明如何使用，一般不会查询缓存不存在就马上返回，而是先查询缓存不存在则去查询数据库，再存入缓存并返回*\\n\\n```go\\ntype User struct {\\n\\teRedis.ERedis\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tERedis: eRedis.ERedis{ConfName: \\\"localhost\\\", DB: 0},\\n\\t}\\n}\\n\\nfunc (ctl *User) GetById(c *gin.Context, id int64) (model.User, error) {\\n    if err := ctl.RDB().Set(context.Background(), \\\"name\\\", \\\"xiyangyang\\\", time.Second * 10).Err(); err != nil {\\n\\t\\treturn nil, err\\n\\t}\\n\\n\\tuserStr, err := ctl.RDB().Get(context.Background(), ctl.GetByIdCachePre(id)).Result()\\n\\tif err != nil {\\n\\t\\tif errors.Is(err, redis.Nil) {\\n            return model.User{}, apierr.UserNoExist\\n\\t\\t}\\n        return model.User{}, errors.WithStack(err)\\n\\t}\\n    \\n    // string to struct\\n\\t\\n\\treturn ...\\n}\\n\\nfunc (ctl *User) cacheKeyPre() string {\\n\\treturn viper.GetString(\\\"APP_NAME\\\") + \\\":user\\\"\\n}\\n\\nfunc (ctl *User) GetByIdCachePre(id int64) string {\\n    return fmt.Sprintf(\\\"%s:id:%d\\\", ctl.cacheKeyPre(), id)\\n}\\n```\\n\\n强制要求只在 data 层涉及数据库的操作，并且将库错误转化为业务错误向上层抛出。\\n\\n例如，现在有一个查询指定用户的操作使用了redis库，那么需要在 `apierr/err.go` 中定义业务错误`apierr.UserNoExist`，然后在 data 层判断错误是否为 `redis.Nil` 并转化为定义的业务错误 `apierr.UserNoExist`\\n\\n> 这样做的好处是，底层不需要强制使用哪个库，大家可以选用自己喜欢的框架，sql、sqlx、gorm、xorm……，只需要将对应的错误转化为业务错误，这样在上层 api 层只需要判断自己关心的业务错误并做相应的处理即可\\n\\n### 堆栈\\n\\n为了更方便地定位错误，我们需要在日志中记录堆栈，但 zap 本身记录的堆栈开始位置是记录日志的位置，我们需要详细到底层才能更好地定位。很遗憾 go 默认的 errors 没有带堆栈记录，我们需要引入外部工具 [errors](https://github.com/pkg/errors)\\n\\n```go\\nuserStr, err := ctl.RDB().Get(context.Background(), ctl.GetByIdCachePre(id)).Result()\\nif err != nil {\\n    if errors.Is(err, redis.Nil) {\\n        return model.User{}, apierr.UserNoExist\\n    }\\n    return model.User{}, errors.WithStack(err)\\n}\\n```\\n\\n比如上面我们查询一个用户记录，首先对结果判断错误是否是用户不存在:\\n\\n+ 如果是，则转化为我们的业务错误直接抛出\\n+ 如果不是，我们使用了 `errors.WithStack(err)` 将错误进行封装，这个错误将带有从这里开始一直到我们使用err的位置的堆栈信息\\n\\n\"},{\"id\":null,\"title\":\"03 | Mongo操作\",\"content\":\"项目在 `github.com/mittacy/gin-toy/core/eMongo` 中封装了 [mongo](https://github.com/mongodb/mongo-go-driver)\\n\\n在使用前，必须先初始化配置\\n\\n```go\\nvar mongoConfigs map[string]eMongo.Conf\\n\\nfunc InitMongo() {\\n\\tmongoConfigs = map[string]eMongo.Conf{\\n\\t\\t\\\"localhost\\\": {\\n\\t\\t\\tHost:     viper.GetString(\\\"MONGO_LOCALHOST_RW_HOST\\\"),\\n\\t\\t\\tPort:     viper.GetInt(\\\"MONGO_LOCALHOST_RW_PORT\\\"),\\n\\t\\t\\tDatabase: viper.GetString(\\\"MONGO_LOCALHOST_RW_DATABASE\\\"),\\n\\t\\t\\tUser:     viper.GetString(\\\"MONGO_LOCALHOST_RW_USERNAME\\\"),\\n\\t\\t\\tPassword: viper.GetString(\\\"MONGO_LOCALHOST_RW_PASSWORD\\\"),\\n\\t\\t},\\n\\t}\\n\\n\\teMongo.Init(mongoConfigs)\\n}\\n```\\n\\n在结构体中引入并在初始化时给 `ConfName、Collection` 赋值，使用MDB()/MCollection()即可获取mongo连接\\n\\n```go\\ntype User struct {\\n\\teMongo.EMongo\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tEMongo: eMongo.EMongo{ConfName: \\\"localhost\\\", Collection: \\\"collection_name\\\"},\\n\\t}\\n}\\n\\nfunc (ctl *User) GetById(c *gin.Context, id int64) (model.User, error) {\\n\\tuser := model.User{}\\n\\tfilter := bson.D{{\\\"id\\\", id}}\\n\\tif err := ctl.MCollection().FindOne(context.Background(), filter).Decode(&user); err != nil {\\n\\t\\tif errors.Is(err, mongo.ErrNoDocuments) {\\n\\t\\t\\treturn model.User{}, apierr.UserNoExist\\n\\t\\t}\\n\\t\\treturn model.User{}, errors.WithStack(err)\\n\\t}\\n    \\n\\treturn &user, nil\\n}\\n```\\n\\n强制要求只在 data 层涉及数据库的操作，并且将库错误转化为业务错误向上层抛出。\\n\\n例如，现在有一个查询指定用户的操作使用了go-mongo库，那么需要在 `apierr/err.go` 中定义业务错误`apierr.UserNoExist`，然后在 data 层判断错误是否为 `mongo.ErrNoDocuments` 并转化为定义的业务错误 `apierr.UserNoExist`\\n\\n> 这样做的好处是，底层不需要强制使用哪个库，大家可以选用自己喜欢的框架，sql、sqlx、gorm、xorm……，只需要将对应的错误转化为业务错误，这样在上层 api 层只需要判断自己关心的业务错误并做相应的处理即可\\n\\n___\\n\\n更多mongo操作请查看 [mongo文档](https://github.com/mongodb/mongo-go-driver)\\n\"},{\"id\":null,\"title\":\"04 | 外部服务请求\",\"content\":\"经常会有调用其他http服务的情况，项目在 `github.com/mittacy/gin-toy/core/thirdHttp` 中封装了 [resty](https://github.com/go-resty/resty) \\n\\n如果响应数据为固定格式时，比如：\\n\\n```go\\ntype Reply struct {\\n\\tCode        int\\n\\tMsg         string\\n\\tData        interface{}\\n}\\n```\\n\\n可以使用以下方法调用三方服务，将会解析Data到result变量\\n\\n```go\\nfunc (ctl *Client) Get(c context.Context, uri string, result interface{}) (int, error) {}\\n\\nfunc (ctl *Client) GetParams(c context.Context, uri string, params map[string]string, result interface{}) (int, error) {}\\n\\nfunc (ctl *Client) Post(c context.Context, uri string, body interface{}, result interface{}) (int, error) {}\\n```\\n\\n**例子**\\n\\n```go\\ntype User struct {\\n\\tclient *thirdHttp.Client\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n\\t\\tclient: thirdHttp.NewClient(viper.GetString(\\\"user_server_host\\\")),\\n\\t}\\n}\\n\\nfunc (ctl *User) Get(c context.Context) {\\n    res := model.Student{}\\n    code, err := ctl.client.Get(c, \\\"/user/get\\\", &res)\\n}\\n```\\n\\n如果响应结构是其他类型，可以在新建client时传入WithReply参数自定义响应结构:\\n\\n```json\\n// 实现响应接口\\ntype customReply struct {\\n\\tName     string `json:\\\"name\\\"`\\n\\tAge      int    `json:\\\"age\\\"`\\n\\tCode     string `json:\\\"code\\\"`\\n\\tShortMsg string `json:\\\"short_msg\\\"`\\n}\\n\\nfunc (r *customReply) GetCode() int {\\n\\treturn 0\\n}\\nfunc (r *customReply) GetMsg() string {\\n\\treturn r.ShortMsg\\n}\\nfunc (r *customReply) GetUnknownCode() int {\\n\\treturn 500\\n}\\nfunc (r *customReply) IsSuccess() bool {\\n\\treturn true\\n}\\nfunc (r *customReply) UnmarshalData(result interface{}) error {\\n\\tdecoder, err := mapstructure.NewDecoder(&mapstructure.DecoderConfig{\\n\\t\\tMetadata: nil,\\n\\t\\tDecodeHook: mapstructure.ComposeDecodeHookFunc(\\n\\t\\t\\tToTimeHookFunc([]string{\\\"2006-01-02 15:04:05\\\", time.RFC3339, time.RFC3339Nano}...)),\\n\\t\\tResult: result,\\n\\t})\\n\\tif err != nil {\\n\\t\\treturn err\\n\\t}\\n\\n\\tif err := decoder.Decode(r); err != nil {\\n\\t\\treturn err\\n\\t}\\n\\treturn err\\n}\\n\\ntype User struct {\\n\\tclient *thirdHttp.Client\\n}\\n\\nfunc NewUser() User {\\n\\treturn User{\\n    \\t// 传入自定义响应结构体\\n\\t\\tclient: thirdHttp.NewClient(\\\"user_server_host\\\"), thirdHttp.WithReply(&customReply{})),\\n\\t}\\n}\\n```\\n\\n\\n\\n当然，有时候我们内部的业务请求响应结构都是固定的结构，但是偶尔需要请求其他服务(比如腾讯、高德……)时，他们的结构真的是随心所欲不定的，那么我们可以使用以下方法，直接解析整个响应内容\\n\\n```go\\nfunc (ctl *Client) SimpleGet(c context.Context, uri string, result interface{}) error {}\\nfunc (ctl *Client) SimpleGetParams(c context.Context, uri string, params map[string]string, result interface{}) error {}\\nfunc (ctl *Client) SimplePost(c context.Context, uri string, body interface{}, result interface{}) error {}\\n```\\n\\n\"},{\"id\":null,\"title\":\"05 | 并发操作\",\"content\":\"当有多个服务或者数据操作没有关联时，可以进行<u>并发调用</u>，在 [errgroup](https://github.com/mittacy/gin-toy/core/errgroup) 对 `golang.org/x/sync/errgroup` 进行升级，防止panic导致的服务宕机\\n\\n```go\\nfunc Xxx() error {\\n    var (\\n        userInfo model.User\\n        userFansTotal int64\\n        errMsg string\\n    )\\n    \\n    group := errgroup.WithContext(context.Background())\\n\\n\\tgroup.Go(func(ctx context.Context) error {\\n        var err error\\n        userInfo, err = service.User.Get()\\n        if err != nil {\\n            errMsg = \\\"查询用户信息\\\"\\n        }\\n        return err\\n\\t})\\n\\n\\tgroup.Go(func(ctx context.Context) error {\\n\\t\\tvar err error\\n        userFansTotal, err = service.Fans.GetTotal()\\n        if err != nil {\\n            errMsg = \\\"查询用户粉丝数量\\\"\\n        }\\n        return err\\n\\t})\\n\\n\\tif err := group.Wait();err != nil {\\n        return errors.WithMessage(err, errMsg)\\n\\t}\\n    \\n    return nil\\n}\\n```\\n\\n- GOMAXPROCS()可设置最大并发数\\n- Wait函数在所有goroutine运行结束才会返回，返回值记录了第一个发生的错误\\n\\n\"},{\"id\":null,\"title\":\"06 | DB与缓存查询封装\",\"content\":\"### 缓存方案\\n\\n首先，我们对缓存是不进行更新的，只设置过期时间，一旦DB里数据出现修改，我们就会直接删除对应的缓存，然后新的查询再进行数据缓存。\\n\\n接下来，是删除缓存的顺序：\\n\\n+ 先删除缓存，再更新数据\\n\\n    A是一个更新操作，B是一个查询操作。A先删除了缓存然后执行一些其他操作阻塞一会儿；在这期间B刚好来查询缓存发现不存在便前往DB查询数据并写入了缓存，之后A解除阻塞更新了DB。那么缓存里的数据就是脏数据，直到下一次更新操作或者缓存过期，业务的查询都将查到脏数据\\n\\n    <img src=\\\"http://static.mittacy.com/blog/202203281033949.png\\\" style=\\\"zoom:50%;\\\" />\\n\\n+ 先更新数据，再更新缓存\\n\\n    同样的，A先进行DB更新操作，随后再删除缓存的时候阻塞了；期间B刚好来查询缓存，从缓存得到的数据就是脏数据；随后A删除了缓存。后续的请求都会拿到最新数据\\n\\n    ![](http://static.mittacy.com/blog/202203281037880.png)\\n\\n方案二带来的影响更小，也更不容易发生，所以我们选择方案二\\n\\n### 缓存代码\\n\\n话不多说，故事开始\\n\\n张三接到优化<u>查询总成员数</u>加缓存的任务，于是马上动工优化了一波\\n\\n+ 不加缓存的代码\\n\\n    ```go\\n    func (ctl *CommunityUser) GetCount(c *gin.Context, appId, communityId string) (int64, error) {\\n    \\tvar count int64\\n    \\tif err := ctl.GDB().Model(model.CommunityUser{}).Where(\\\"app_id = ? and community_id = ?\\\", appId, communityId).Count(&count).Error; err != nil {\\n    \\t\\treturn 0, errors.WithStack(err)\\n    \\t}\\n    \\n    \\treturn count, nil\\n    }\\n    ```\\n\\n+ 加了缓存的代码\\n\\n    ```go\\n    func (ctl *CommunityUser) GetCountWithCache(c *gin.Context, appId, communityId string) (int64, error) {\\n    \\t// 从缓存查询\\n    \\tkey := ctl.getCountCacheKey(appId, communityId)\\n    \\tcacheRes, err := ctl.RDB().Get(c, key).Result()\\n    \\tif err != nil && !errors.Is(err, redis.Nil) {\\n    \\t\\treturn 0, errors.WithStack(err)\\n    \\t}\\n        // 缓存存在，直接返回\\n    \\tif err == nil {\\n    \\t\\treturn strconv.ParseInt(cacheRes, 10, 64)\\n    \\t}\\n    \\n    \\t// 缓存不存在，从DB查询\\n    \\tvar count int64\\n    \\tif err := ctl.GDB().Model(model.CommunityUser{}).Where(\\\"app_id = ? and community_id = ?\\\", appId, communityId).Count(&count).Error; err != nil {\\n    \\t\\treturn 0, errors.WithStack(err)\\n    \\t}\\n    \\t\\n    \\t// 存入缓存\\n    \\tgo func() {\\n    \\t\\tif err = ctl.RDB().Set(c, key, count, CountExpire).Err(); err != nil {\\n    \\t\\t\\tctl.log.ErrorwWithTrace(c, \\\"查询圈子用户总数-存储缓存失败\\\", \\\"err\\\", err)\\n    \\t\\t}\\n    \\t}()\\n    \\n    \\treturn count, nil\\n    }\\n    ```\\n\\n张三写完觉得很不错，提了个紧急上线单赶紧修复，免得下周又崩了，经过多人没人几秒钟的review之后，成功通过上线。\\n\\n周五的时候，这个1.3万用户量的圈子，风雨无阻地发起了签到活动，奇迹来了，圈子不负众望，再次把核心库搞崩了。\\n\\n根据运维给出的情报，还是那个查询语句，张三看了下代码，陷入深思，感叹到：我大意了。\\n\\n### 处理并发\\n\\n不难发现，这种高并发的业务场景，如果这个复杂的查询语句需要1秒钟，同时1秒钟有10000个用户进来了，那还是有10000个查询打到了DB，还是老样子挂了，所以我们应该给查询加上并发锁，只放一个请求穿透缓存到DB去查询，其他请求则反复请求缓存，直到放过去的请求查询出数据并更新缓存即可。\\n\\n<img src=\\\"http://static.mittacy.com/blog/202203281112490.png\\\" style=\\\"zoom:60%;\\\" />\\n\\nredis的set很符合我们的需求，`set key value ex/px expire nx`：不存在的时候设置key同时设置过期时间，返回true则表示设置成功获得了锁；设置失败则表示锁被其他请求拿走了。不用担心拿了锁的请求异常导致没释放锁，毕竟锁加了过期时间，同时这也是一个原子操作。\\n\\n这是加了锁的代码：\\n\\n```go\\nfunc (ctl *CommunityUser) GetCountWithCache(c *gin.Context, appId, communityId string) (int64, error) {\\n\\t// 从缓存查询\\n\\tkey := ctl.getCountCacheKey(appId, communityId)\\n\\tcacheRes, err := ctl.RDB().Get(c, key).Result()\\n\\tif err != nil && !errors.Is(err, redis.Nil) {\\n\\t\\treturn 0, errors.WithStack(err)\\n\\t}\\n\\tif err == nil {\\n\\t\\treturn strconv.ParseInt(cacheRes, 10, 64)\\n\\t}\\n\\n\\t// 缓存不存在，获取并发锁\\n\\tlockKey := ctl.getCountLockKey(appId, communityId)\\n\\tok ,err := ctl.RDB().SetNX(c, lockKey, 1, time.Second).Result()\\n\\tif err != nil || !ok {\\n\\t\\t// 拿不到锁，每次等待50ms，尝试从redis获取缓存\\n\\t\\tfor i := 0; i < 10; i++ {\\n\\t\\t\\ttime.Sleep(time.Millisecond * 50)\\n\\t\\t\\tcount, err := ctl.RDB().Get(c, key).Int64()\\n\\t\\t\\tif err != nil && !errors.Is(err, redis.Nil) {\\n\\t\\t\\t\\treturn 0, errors.WithStack(err)\\n\\t\\t\\t}\\n\\t\\t\\tif err == nil {\\n\\t\\t\\t\\treturn count, nil\\n\\t\\t\\t}\\n\\t\\t}\\n\\t\\t// 等不到缓存，直接返回错误\\n\\t\\treturn 0, errors.New(\\\"服务器压力过大\\\")\\n\\t}\\n\\t\\n\\t// 拿到锁的穿透到DB, 从DB查询数据并存入redis\\n\\tdefer func() {\\n\\t\\trecover()\\n\\t\\tctl.RDB().Del(c, lockKey)\\n\\t}()\\n\\t\\n\\tvar count int64\\n\\tif err := ctl.GDB().Model(model.CommunityUser{}).Where(\\\"app_id = ? and community_id = ?\\\", appId, communityId).Count(&count).Error; err != nil {\\n\\t\\treturn 0, errors.WithStack(err)\\n\\t}\\n\\n\\t// 存入缓存，不能并发，不然还没存好就触发了解锁操作\\n\\tif err = ctl.RDB().Set(c, key, count, time.Hour).Err(); err != nil {\\n\\t\\tlog.New(\\\"communityUser\\\").ErrorwWithTrace(c, \\\"查询圈子用户总数-存储缓存失败\\\", \\\"err\\\", err)\\n\\t}\\n\\n\\treturn count, nil\\n}\\n```\\n\\n好了，一切看起来很不错，至于能不能抗住，再说 ಡωಡ\\n\\n其实还有个小bug，注意下释放锁的逻辑：\\n\\n```go\\nctl.RDB().Del(c, lockKey)\\n```\\n\\n这里同一个业务查询的缓存锁名其实都是一样的，有这样一种情况：A请求获取锁并前往DB查询结果被阻塞住了，直到锁过期还没解除阻塞；B请求获取了锁并前往DB查询结果，还没查询完，A解除了阻塞随后把B的锁给释放了。没错，A释放了B的锁，这时候一大堆僵尸袭来，DB再次绷不住挂了……\\n\\n解决方法是给锁的值设置一个随机值，解锁的时候检查随机值是否为自己的随机值，也就是是否为自己的锁，是的话再释放。这里需要使用lua脚本去保证操作的原子性，不展开讲，我已经封装并发锁： [ego-redisLock](https://github.com/mittacy/gin-toy/tree/master/core/eRedis/redisLock.go)\\n\\n### 代码封装\\n\\n李四也接到了优化sql加缓存的需求，于是，李四以熟练的让人心疼的手速一顿操作(*复制-粘贴-改代码*)，完成了需求，但是火眼金睛goland给这段代码画上了下划线提示：重复的代码。于是，懒惰的李四不得不开始了封装，以下是封装后，业务侧调用的代码：\\n\\n+ 查询一个count\\n\\n    ```go\\n    // GetCount 查询圈子的总成员数\\n    func (ctl *CommunityUser) GetCount(c *gin.Context, appId, communityId string) (int64, error) {\\n    \\t// 1. 如何从DB查询数据\\n    \\tgetFromDB := func() (string, error) {\\n    \\t\\tvar count int64\\n    \\t\\tif err := ctl.GDB().Model(model.CommunityUser{}).Where(\\\"app_id = ? and community_id = ?\\\", \\n    \\t\\t\\tappId, communityId).Count(&count).Error; err != nil {\\n    \\t\\t\\treturn \\\"\\\", err\\n    \\t\\t}\\n    \\n    \\t\\treturn strconv.FormatInt(count, 10), nil\\n    \\t}\\n    \\n    \\t// 2. 获取并发查询控制器，传递响应配置参数\\n        res, err := eRedis.GetSet(c, ctl.RDB(), cacheKey, time.Hour, getFromDB)\\n    \\tif err != nil {\\n    \\t\\treturn 0, err\\n    \\t}\\n    \\n    \\t// 3. 结果类型转化\\n    \\treturn strconv.ParseInt(res, 10, 64)\\n    }\\n    ```\\n\\n+ 查询一个列表\\n\\n    ```go\\n    // GetRecentlyUser 查询最近加入的N个成员\\n    func (ctl *CommunityUser) GetRecentlyUser(c *gin.Context, appId, communityId string, count int) ([]model.CommunityUser, error) {\\n    \\t// 1. 如何从DB查询数据\\n    \\tgetFromDB := func() (string, error) {\\n    \\t\\tvar users []model.CommunityUser\\n    \\t\\tif err := ctl.GDB().Where(\\\"app_id = ? and community_id = ?\\\", appId, communityId).\\n    \\t\\t\\tOrder(\\\"join_time desc\\\").Limit(count).Find(&users).Error; err != nil {\\n    \\t\\t\\treturn \\\"\\\", err\\n    \\t\\t}\\n    \\n    \\t\\treturn encodeUtil.JSONMarshalString(users)\\n    \\t}\\n    \\n    \\t// 2. 获取并发查询控制器，传递响应配置参数\\n        res, err := eRedis.GetSet(c, ctl.RDB(), cacheKey, time.Hour, getFromDB)\\n    \\tif err != nil {\\n    \\t\\treturn 0, err\\n    \\t}\\n        \\n    \\t// 3. 结果类型转化\\n    \\tvar users []model.CommunityUser\\n    \\tif err := encodeUtil.JSONUnmarshalString(res, &users); err != nil {\\n    \\t\\treturn nil, err\\n    \\t}\\n    \\treturn users, nil\\n    }\\n    ```\\n\\n并发缓存查询的可选参数如下：\\n\\n+ WithLockExpire 设置并发锁过期时间，单位：秒\\n+ WithWaitCache 拿不到锁的请求，是否阻塞等待缓存\\n+ WithWaitCacheTime 拿不到锁的请求阻塞等待时间, 会同时开启WithWaitCache(true)\\n\\n\\n\\n___\\n\\n封装链接：\\n\\n1. https://github.com/mittacy/gin-toy/tree/master/core/eRedis/redisLock.go\\n2. https://github.com/mittacy/gin-toy/tree/master/core/eRedis/concurrentSelect.go\\n\\n参考文章：https://go-zero.dev/cn/redis-lock.html\\n\\n\"}]},{\"title\":\"其他\",\"articles\":[{\"id\":null,\"title\":\"工具推荐\",\"content\":\"- sql/json 转化为 go结构体：[sql_json_go](https://www.qetool.com/sql_json_go.html)\\n- 结构体转化：[copier](https://github.com/jinzhu/copier)\\n\"}]}],\"banner\":\"http://static.mittacy.com/blog/202110111011364.jpg\",\"id\":\"1624512335520\"},];\n      export default arr;","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"back-top\",style:(_vm.style),on:{\"click\":_vm.backTop}},[_c('icon',{attrs:{\"icon\":\"icon-rocket\"}})],1)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","\n\n\n\n\n\n\nimport { Vue, Component, Prop } from 'vue-property-decorator';\nimport Icon from '@commonComponents/Icon.vue';\nimport { scrollTop } from '@utils/index';\n\n@Component({\n  name: 'BackTop',\n  components: {\n    Icon,\n  },\n})\nexport default class extends Vue {\n  @Prop({ type: Number, default: 30 }) private bottom!: number;\n  @Prop({ type: Number, default: 30 }) private right!: number;\n  @Prop({ type: Number, default: 1200 }) private duration!: number;\n\n  private get style(): { bottom: string, right: string } {\n    return {\n      bottom: `${this.bottom}px`,\n      right: `${this.right}px`,\n    };\n  }\n\n  private backTop(): void {\n    const top = document.documentElement.scrollTop || document.body.scrollTop;\n    scrollTop(top, 0, this.duration);\n  }\n}\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/ts-loader/index.js??ref--13-3!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./BackTop.vue?vue&type=script&lang=ts&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/ts-loader/index.js??ref--13-3!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./BackTop.vue?vue&type=script&lang=ts&\"","import { render, staticRenderFns } from \"./BackTop.vue?vue&type=template&id=0bd95e97&scoped=true&\"\nimport script from \"./BackTop.vue?vue&type=script&lang=ts&\"\nexport * from \"./BackTop.vue?vue&type=script&lang=ts&\"\nimport style0 from \"./BackTop.vue?vue&type=style&index=0&id=0bd95e97&lang=less&scoped=true&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"0bd95e97\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('header',{staticClass:\"nav-wrapper\"},[_c('div',{staticClass:\"nav\"},[_c('div',{staticClass:\"nav-actions\"},_vm._l((_vm.menu),function(menuItem){return _c('router-link',{key:menuItem.route,staticClass:\"nav-action-link\",attrs:{\"to\":{\n          name: menuItem.route,\n        }}},[_c('div',{class:['nav-action-wrapper', _vm.currentRoute === menuItem.route && 'nav-action-wrapper_selected']},[_c('span',[_vm._v(_vm._s(menuItem.title))])])])}),1)])])}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport { Vue, Component, Prop } from 'vue-property-decorator';\nimport { MenuItem } from '@/types/app';\nimport Icon from '@commonComponents/Icon.vue';\n\n@Component({\n  name: 'AppNav',\n  components: {\n    Icon,\n  },\n})\nexport default class extends Vue {\n  @Prop({ type: Array, default: () => ([]) })\n  private menu!: Array<MenuItem>;\n\n  private get currentRoute(): string {\n    return this.$route.name || '';\n  }\n}\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/ts-loader/index.js??ref--13-3!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./AppNav.vue?vue&type=script&lang=ts&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/ts-loader/index.js??ref--13-3!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./AppNav.vue?vue&type=script&lang=ts&\"","import { render, staticRenderFns } from \"./AppNav.vue?vue&type=template&id=5130d6a6&scoped=true&\"\nimport script from \"./AppNav.vue?vue&type=script&lang=ts&\"\nexport * from \"./AppNav.vue?vue&type=script&lang=ts&\"\nimport style0 from \"./AppNav.vue?vue&type=style&index=0&id=5130d6a6&lang=less&scoped=true&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"5130d6a6\",\n  null\n  \n)\n\nexport default component.exports","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"footer\"},[_c('section',{staticClass:\"footer-section\"},[_vm._v(\"©\"+_vm._s(_vm.year)+\" \"+_vm._s(_vm.website.title)+\". All rights reserved\")]),_vm._l((_vm.footers),function(footerItem,index){return _c('section',{key:index,staticClass:\"footer-section\"},[(typeof footerItem === 'string')?_c('span',[_vm._v(_vm._s(footerItem))]):_c('a',{attrs:{\"href\":footerItem.link,\"target\":\"_blank\",\"rel\":\"noopener noreferrer\"}},[_vm._v(_vm._s(footerItem.label))])])})],2)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport { Vue, Component, InjectReactive } from 'vue-property-decorator';\nimport { Website, Footer } from '@/types/app';\n\n@Component({\n  name: 'AppFooter',\n})\nexport default class extends Vue {\n  @InjectReactive('website') private website!: Website;\n\n  @InjectReactive('footers') private footers!: Array<Footer>;\n\n  private get year(): number {\n    return (new Date()).getFullYear();\n  }\n}\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/ts-loader/index.js??ref--13-3!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./AppFooter.vue?vue&type=script&lang=ts&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/ts-loader/index.js??ref--13-3!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./AppFooter.vue?vue&type=script&lang=ts&\"","import { render, staticRenderFns } from \"./AppFooter.vue?vue&type=template&id=d3bc3b42&scoped=true&\"\nimport script from \"./AppFooter.vue?vue&type=script&lang=ts&\"\nexport * from \"./AppFooter.vue?vue&type=script&lang=ts&\"\nimport style0 from \"./AppFooter.vue?vue&type=style&index=0&id=d3bc3b42&lang=less&scoped=true&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"d3bc3b42\",\n  null\n  \n)\n\nexport default component.exports","\n\n\n\n\n\n\n\n\n\n\n\n\n\nimport { Vue, Component, ProvideReactive } from 'vue-property-decorator';\nimport articles from './y_system_articles';\nimport columns from './y_system_columns';\nimport { MenuItem, Website } from '@/types/app';\nimport { UserInfo as TypeUserInfo } from '@/types/userInfo';\nimport { Article, Articles, Categories } from '@/types/article';\nimport { Columns } from '@/types/columns';\nimport RouteName from '@router/routerName';\nimport BackTop from '@commonComponents/BackTop.vue';\nimport AppNav from '@components/AppNav.vue';\nimport AppFooter from '@components/AppFooter.vue';\nimport { parse } from '@utils/index';\n\n@Component({\n  name: 'App',\n  components: {\n    BackTop,\n    AppNav,\n    AppFooter,\n  },\n})\nexport default class extends Vue {\n  @ProvideReactive('userInfo')\n  private userInfo: TypeUserInfo = {\n    name: '',\n    description: '',\n    avatar: '',\n    links: [],\n  };\n\n  @ProvideReactive('articles')\n  private articles: Articles = [];\n\n  @ProvideReactive('categories')\n  private categories: Categories = [];\n\n  @ProvideReactive('columns')\n  private columns: Columns = [];\n\n  @ProvideReactive('footers')\n  private footers: Array<string> = [];\n\n  @ProvideReactive('website')\n  private website: Website = {\n    title: '',\n    description: '',\n  };\n\n  private get menu(): Array<MenuItem> {\n    const menu: Array<MenuItem> = [\n      { title: '首页', route: RouteName.HOME },\n    ];\n\n    if (this.columns?.length) {\n      menu.push({ title: '专栏', route: RouteName.COLUMNS });\n    }\n\n    return menu;\n  }\n\n  private init(): void {\n    const {\n      VUE_APP_INFO_USERINFO,\n      VUE_APP_INFO_WEBSITE,\n      VUE_APP_INFO_FOOTERS,\n    } = process.env;\n\n    // 网站信息\n    this.website = parse(this.website, VUE_APP_INFO_WEBSITE);\n    // 用户资料\n    this.userInfo = parse(this.userInfo, VUE_APP_INFO_USERINFO);\n    // 文章\n    this.articles = (articles as Articles).sort((before: Article, after: Article) => {\n      const beforeDate = new Date(before.createTime);\n      const afterDate = new Date(after.createTime);\n\n      return afterDate.getTime() - beforeDate.getTime();\n    });\n    // 分类\n    this.categories = Array.from(new Set(['全部'].concat(this.articles.map((article) => article.category))));\n    // 专栏\n    this.columns = columns as Columns;\n    // 底部信息\n    this.footers = parse(this.footers, VUE_APP_INFO_FOOTERS);\n  }\n\n  private created(): void {\n    this.init();\n  }\n}\n","import mod from \"-!../node_modules/cache-loader/dist/cjs.js??ref--13-0!../node_modules/thread-loader/dist/cjs.js!../node_modules/babel-loader/lib/index.js!../node_modules/ts-loader/index.js??ref--13-3!../node_modules/cache-loader/dist/cjs.js??ref--0-0!../node_modules/vue-loader/lib/index.js??vue-loader-options!./App.vue?vue&type=script&lang=ts&\"; export default mod; export * from \"-!../node_modules/cache-loader/dist/cjs.js??ref--13-0!../node_modules/thread-loader/dist/cjs.js!../node_modules/babel-loader/lib/index.js!../node_modules/ts-loader/index.js??ref--13-3!../node_modules/cache-loader/dist/cjs.js??ref--0-0!../node_modules/vue-loader/lib/index.js??vue-loader-options!./App.vue?vue&type=script&lang=ts&\"","import { render, staticRenderFns } from \"./App.vue?vue&type=template&id=1190dd40&scoped=true&\"\nimport script from \"./App.vue?vue&type=script&lang=ts&\"\nexport * from \"./App.vue?vue&type=script&lang=ts&\"\nimport style0 from \"./App.vue?vue&type=style&index=0&id=1190dd40&lang=less&scoped=true&\"\n\n\n/* normalize component */\nimport normalizer from \"!../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"1190dd40\",\n  null\n  \n)\n\nexport default component.exports","import Vue from 'vue';\nimport VueRouter, { RouteConfig } from 'vue-router';\nimport RouteName from './routerName';\n\nVue.use(VueRouter);\n\nexport default () => {\n  const routes: Array<RouteConfig> = [\n    {\n      name: RouteName.HOME,\n      path: '/',\n      component: () => import('@pages/Home/index.vue'),\n      meta: {\n        title(context: Vue) {\n          return (context as any).website.title;\n        },\n      },\n    },\n    {\n      name: RouteName.ARTICLE,\n      path: '/article/:id',\n      component: () => import('@pages/Article/index.vue'),\n      meta: {\n        title(context: Vue) {\n          return (context as any).title;\n        },\n      },\n    },\n    {\n      name: RouteName.COLUMNS,\n      path: '/columns',\n      component: () => import('@pages/Columns/index.vue'),\n      meta: {\n        title: '专栏',\n      },\n    },\n    {\n      name: RouteName.COLUMN,\n      path: '/column/:columnId',\n      component: () => import('@pages/Column/index.vue'),\n      meta: {\n        title(context: Vue) {\n          return (context as any).title;\n        },\n      },\n    },\n    {\n      name: RouteName.NOTFOUND,\n      path: '*',\n      component: () => import('@pages/NotFound/index.vue'),\n    },\n  ];\n\n  const router = new VueRouter({\n    mode: 'history',\n    base: process.env.BASE_URL,\n    routes,\n    scrollBehavior() {\n      return {\n        x: 0,\n        y: 0,\n      };\n    },\n  });\n\n  return {\n    router,\n  };\n};\n","import { Script } from '@/types/app';\nimport { parse } from '@utils/index';\nimport { isServerRender, isProduction } from '@utils/is';\n\nfunction scriptsRegister(): void {\n  if (isServerRender || isProduction) {\n    return;\n  }\n\n  const { VUE_APP_INFO_SCRIPTS = '[]' } = process.env;\n  const scriptNames = parse([], VUE_APP_INFO_SCRIPTS);\n\n  scriptNames.forEach((scriptInfo: Script) => {\n    const path = typeof scriptInfo === 'string' ? `/scripts/${scriptInfo}` : `/scripts/${scriptInfo.src}`;\n    const script: HTMLScriptElement = document.createElement('script');\n    script.src = path;\n\n    if (typeof scriptInfo !== 'string' && scriptInfo.asyncType) {\n      script[scriptInfo.asyncType] = true;\n    }\n\n    document.body.appendChild(script);\n  });\n}\n\nscriptsRegister();\n","import Vue from 'vue';\nimport App from '@/App.vue';\nimport createRouter from '@router/index';\n\nimport '@plugins/cssRegister';\nimport '@plugins/scriptsRegister';\n\nVue.config.productionTip = false;\n\nexport default () => {\n  // router\n  const { router } = createRouter();\n\n  // app\n  const app = new Vue({\n    router,\n    render: (h) => h(App),\n  });\n\n  return {\n    app,\n    router,\n  };\n};\n","import createApp from './createApp';\n\nconst { app } = createApp();\n\napp.$mount('#app');\n","export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--10-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--10-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--10-oneOf-1-2!../../node_modules/less-loader/dist/cjs.js??ref--10-oneOf-1-3!../../node_modules/style-resources-loader/lib/index.js??ref--10-oneOf-1-4!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./AppFooter.vue?vue&type=style&index=0&id=d3bc3b42&lang=less&scoped=true&\"","export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--10-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--10-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--10-oneOf-1-2!../../node_modules/less-loader/dist/cjs.js??ref--10-oneOf-1-3!../../node_modules/style-resources-loader/lib/index.js??ref--10-oneOf-1-4!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./AppNav.vue?vue&type=style&index=0&id=5130d6a6&lang=less&scoped=true&\"","export * from \"-!../node_modules/mini-css-extract-plugin/dist/loader.js??ref--10-oneOf-1-0!../node_modules/css-loader/dist/cjs.js??ref--10-oneOf-1-1!../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../node_modules/postcss-loader/src/index.js??ref--10-oneOf-1-2!../node_modules/less-loader/dist/cjs.js??ref--10-oneOf-1-3!../node_modules/style-resources-loader/lib/index.js??ref--10-oneOf-1-4!../node_modules/cache-loader/dist/cjs.js??ref--0-0!../node_modules/vue-loader/lib/index.js??vue-loader-options!./App.vue?vue&type=style&index=0&id=1190dd40&lang=less&scoped=true&\"","export const isServerRender = process.env.VUE_APP_BUILD_TYPE === 'server';\n\nexport const isProduction = process.env.NODE_ENV !== 'development';\n","export function parse<T>(target: T, str: string): T {\n  try {\n    return JSON.parse(str);\n  } catch (err) {\n    return target;\n  }\n}\n\nexport function getType(variable: any): string {\n  return Object.prototype.toString.call(variable).match(/\\[object (.*)\\]/)?.[1] || '';\n}\n\nexport function scrollTop(from: number = 0, to: number, duration: number = 500, endCallback?: () => void) {\n  const diff = Math.abs(from - to);\n  const step = Math.ceil(diff / duration * 50);\n\n  function scroll(start: number, end: number, step: number) {\n    if (start === end) {\n      if (endCallback) {\n        endCallback();\n      }\n\n      return;\n    }\n\n    let d = (start + step > end) ? end : start + step;\n\n    if (start > end) {\n      d = (start - step < end) ? end : start - step;\n    }\n\n    window.scrollTo(d, d);\n    window.requestAnimationFrame(() => scroll(d, end, step));\n  }\n\n  scroll(from, to, step);\n}\n\nexport function setMeta(name: string, content: string): void {\n  const head = document.getElementsByTagName('head');\n  const metaArr = document.getElementsByTagName('meta');\n\n  for (const meta of metaArr) {\n    const metaName = meta.getAttribute('name');\n    const metaContent = meta.getAttribute('content');\n    if (name === metaName && content === metaContent) {\n      return;\n    }\n  }\n\n  const meta = document.createElement('meta');\n  meta.name = name;\n  meta.content = content;\n  head[0]?.appendChild(meta);\n}\n\nexport function setLocalStorage(key: string, value: any): void {\n  if (window?.localStorage) {\n    window.localStorage.setItem(key, value);\n  }\n}\n\nexport function getLocalStorage(key: string): string {\n  if (window?.localStorage) {\n    return window.localStorage.getItem(key) || '';\n  }\n\n  return '';\n}\n\nexport function isExist(val: any): boolean {\n  return val !== undefined && val !== null;\n}\n\nexport function validator(arr: Array<unknown>): (val: unknown) => boolean {\n  return (val: unknown) => {\n    const result = arr.includes(val);\n\n    if (!result) {\n      // tslint:disable\n      console.warn(`props 必须为 ${arr.join(', ')} 中的其中一个!`);\n    }\n\n    return result;\n  };\n}\n","enum RouteName {\n  HOME = 'Home',\n  COLUMNS = 'Columns',\n  COLUMN = 'Column',\n  ARTICLE = 'Article',\n  NOTFOUND = 'NotFound',\n}\n\nexport default RouteName;\n","export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--10-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--10-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--10-oneOf-1-2!../../node_modules/less-loader/dist/cjs.js??ref--10-oneOf-1-3!../../node_modules/style-resources-loader/lib/index.js??ref--10-oneOf-1-4!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./BackTop.vue?vue&type=style&index=0&id=0bd95e97&lang=less&scoped=true&\"","export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--10-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--10-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--10-oneOf-1-2!../../node_modules/less-loader/dist/cjs.js??ref--10-oneOf-1-3!../../node_modules/style-resources-loader/lib/index.js??ref--10-oneOf-1-4!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Icon.vue?vue&type=style&index=0&id=ca6c9938&lang=less&scoped=true&\""],"sourceRoot":""}